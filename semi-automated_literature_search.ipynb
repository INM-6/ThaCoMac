{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96a329a8-d411-429f-a9d3-8ed95a517c2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import internal .py files\n",
    "import file_path_management as fpath\n",
    "import public_library as plib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "099606bd-fea9-49db-884c-a047de5621f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# all the file paths in file_path_management.py\n",
    "# project_folder\n",
    "# gs_poten_urls\n",
    "# wos_poten_urls\n",
    "# pubmed_pmc_poten_urls\n",
    "# eupmc_poten_urls\n",
    "# path_poten_csv\n",
    "# path_related_urls\n",
    "# path_related_csv\n",
    "# pdf_folder_path\n",
    "# seed_paper_urls\n",
    "# connec_db_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37eb8cd1-594b-4af8-aff3-cc6a9c91b488",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import packages\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import random\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed2a1fb-4380-4179-bbdf-8192056b8b4c",
   "metadata": {},
   "source": [
    "In the next cell, we present all parameters that might have an effect on the search results, including:<br>\n",
    "1. searching keyword lexicon\n",
    "2. academic databases\n",
    "3. initial urls when searching academic databases\n",
    "4. seed paper list for spanning citations\n",
    "5. conenctome database\n",
    "6. seaching queries of the connectome database\n",
    "7. on-topic keyword lexicon\n",
    "8. weights of on-topic keywords when calculating relatedness of a literature\n",
    "9. ChatGPT queries for relatedness of topic\n",
    "10. meta categories when extracting information of related literature\n",
    "11. keywords for searching meta categories\n",
    "12. ChatGPT queries for extracting information of meta categories of related literature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b6b2882-23e5-4670-8359-3d7367e1107b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "\n",
    "# searching keyword lexicon\n",
    "search_kws_lexicon = \"macaque AND (thalamus OR thalamocortical OR thalamo-cortical)\" # in all fields\n",
    "\n",
    "# academic databases\n",
    "# Google Scholar: \"https://scholar.google.com/\"\n",
    "# 78300 results\n",
    "# Web of Science: \"https://www.webofscience.com/wos/woscc/advanced-search\" # can be exported to excel file\n",
    "# 961 results\n",
    "# PubMed Central PMC: \"https://pubmed.ncbi.nlm.nih.gov/advanced/\" # can be exported to .csv file and abstract.txt file\n",
    "# 2448 results\n",
    "# Europe PMC = \"https://europepmc.org/advancesearch\" # can be exported to .csv file or abstract and full open access file .xml\n",
    "# 5129 results\n",
    "acad_dbs = [\"Google Scholar\", \"Web of Science\", \"PubMed_Central_PMC\", \"Europe_PMC\"]\n",
    "\n",
    "# initial urls for specified searching keyword lexicon and all academic databases\n",
    "init_urls = {\n",
    "    \"gs\": \"https://scholar.google.com/scholar?start=0&q=macaque+thalamus+OR+thalamocortical+OR+thalamo-cortical&hl=en&as_sdt=1,5\",\n",
    "    \"wos\": \"https://www.webofscience.com/wos/woscc/summary/79530a3c-47d5-4dd0-9b7d-b1d92fd11882-98d8472a/relevance/1\",\n",
    "    \"pubmed\": \"https://pubmed.ncbi.nlm.nih.gov/?term=(((thalamus)%20OR%20(thalamocortical))%20OR%20(thalamo-cortical))%20AND%20(macaque)&sort=&page=1\",\n",
    "    \"eupmc\": \"https://europepmc.org/search?query=%28%22macaque%22%20AND%20%28%22thalamus%22%20OR%20%22thalamocortical%22%20OR%20%22thalamo-cortical%22%29%20%29%20AND%20%28LANG%3A%22eng%22%20OR%20LANG%3A%22en%22%20OR%20LANG%3A%22us%22%29&page=1\"\n",
    "}\n",
    "\n",
    "# seed papers specification\n",
    "seed_papers = []\n",
    "\n",
    "# connectome database and queries specification\n",
    "# we search the CoCoMac\n",
    "connec_db = \"\"\n",
    "connec_db_quries = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b8ee718e-e776-44d4-ba81-7f24ef51c866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google Scholar searched 78300 results dispalyed in 7830 pages.\n",
      "Searching Google Scholar complated!\n"
     ]
    }
   ],
   "source": [
    "def search_google_scholar(init_url):\n",
    "    # create a .txt file to record the urls of google scholar search results, clear the file if already exists\n",
    "    f = open(fpath.gs_poten_urls, \"w\")\n",
    "    f.truncate()\n",
    "    f.close()\n",
    "\n",
    "    # request the first page and extract the number of pages of the search results\n",
    "    first_page = init_url\n",
    "    response = requests.get(first_page, headers = plib.headers)\n",
    "    soup = BeautifulSoup(response.content,\"lxml\")\n",
    "    # print(soup)\n",
    "    num_results_str_list = soup.select(\"div\", {\"class\": \"gs_ab_mdw\"})\n",
    "    for item in num_results_str_list:\n",
    "        if \"results\" in item.get_text():\n",
    "            num_results_str = item.get_text().split()\n",
    "    num_results_str = num_results_str[1]\n",
    "    # print(num_results_str)\n",
    "    # print(int(num_results_str))\n",
    "    num_results = int(re.sub(r\"[^\\w\\s]\", \"\", num_results_str))\n",
    "    pages = int(num_results/10)\n",
    "    print(\"Google Scholar searched \" + str(num_results) + \" results\" + \" dispalyed in \" + str(pages) + \" pages.\")\n",
    "    \n",
    "    # iterate all pages and record the results\n",
    "    # pages = 5\n",
    "    for page in range(pages):\n",
    "        time.sleep(random.randint(1, 10))\n",
    "        start = page * 10\n",
    "        # google scholar\n",
    "        page_url = init_url.split(\"?start=\")[0] + \"?start=\" + str(start) + \"&q=\" + init_url.split(\"?start=\")[1].split(\"&q=\")[1]\n",
    "        # print(page_url)\n",
    "        # search a page\n",
    "        response = requests.get(page_url, headers = headers)\n",
    "        soup = BeautifulSoup(response.content,\"lxml\")\n",
    "        # print(soup)\n",
    "        # print(soup.select(\"[data-lid]\")) \n",
    "        for item in soup.select(\"[data-lid]\"):\n",
    "            # print(item)\n",
    "            add_url = item.select(\"h3\")[0].select(\"a\", href = True)[0][\"href\"]\n",
    "            # print(add_url)\n",
    "            try: \n",
    "                with open(fpath.gs_poten_urls, \"a\") as url_file:\n",
    "                    # append text at the end of file\n",
    "                    url_file.write(f\"{add_url}\\n\")\n",
    "            except Exception as e: \n",
    "                print(\"Error when trying to write in google_scholar_poten_urls.txt\")\n",
    "                raise e\n",
    "    print(\"Searching Google Scholar complated!\")\n",
    "\n",
    "def search_webofscience(init_url, headers):\n",
    "    print(\"Searching Web of Science complated!\")\n",
    "\n",
    "def search_PubMed_Central_PMC(iinit_url, headers):\n",
    "    print(\"Searching PubMedd Central PMC complated!\")\n",
    "\n",
    "def search_Europe_PMC(init_url, headers):\n",
    "    print(\"Searching Europe PMC complated!\")\n",
    "\n",
    "# --------------------start of test code--------------------\n",
    "init_url = \"https://scholar.google.com/scholar?start=0&q=macaque+thalamus+OR+thalamocortical+OR+thalamo-cortical&hl=en&as_sdt=1,5\"\n",
    "headers = plib.headers\n",
    "search_google_scholar(init_url)\n",
    "# ---------------------end of test code---------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8b492a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_PubMed_Central_PMC(init_url, headers):\n",
    "    print(\"Searching PubMedd Central PMC complated!\")\n",
    "\n",
    "# --------------------start of test code--------------------\n",
    "# test code\n",
    "# ---------------------end of test code---------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ab5590d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_Europe_PMC(init_url, headers):\n",
    "    print(\"Searching Europe PMC complated!\")\n",
    "\n",
    "# --------------------start of test code--------------------\n",
    "# test code\n",
    "# ---------------------end of test code---------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72ddc49e-446e-4c4b-a8a7-a79b1335039d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# search academic databases, record the urls as a line in a .txt file from the webpages\n",
    "def search_acad_dbs(acad_dbs, init_urls, headers, proxy):\n",
    "    for acad_db in acad_dbs:\n",
    "        if acad_db == \"Google Scholar\":\n",
    "            print(\"Searching Google Scholar...\")\n",
    "            search_google_scholar(init_urls[\"gs\"], headers)\n",
    "        elif acad_db == \"Web of Science\":\n",
    "            print(\"Searching Web of Science...\")\n",
    "            search_webofscience(init_urls[\"wos\"], headers)\n",
    "        elif acad_db == \"PubMed_Central_PMC\":\n",
    "            print(\"Searching PubMed Central PMC...\")\n",
    "            search_PubMed_Central_PMC(init_urls[\"pubmed\"], headers)\n",
    "        elif acad_db == \"Europe_PMC\":\n",
    "            print(\"Searching Europe PMC...\")\n",
    "            search_Europe_PMC(init_urls[\"pubmed\"], headers)\n",
    "        else:\n",
    "            print(\"The specified academic database: \" + acad_db + \" is not supported by this function.\")\n",
    "            print(\"Plese choose one of the following databases:\",)\n",
    "            for db in [\"Google Scholar\", \"Web of Science\", \"PubMed_Central_PMC\", \"Europe_PMC\"]:\n",
    "                print(db)\n",
    "\n",
    "def span_citations(seed_papers, num_span_time, headers, proxy):\n",
    "    None\n",
    "    \n",
    "def search_conne_db(connec_db, connec_db_quries):\n",
    "    None\n",
    "\n",
    "# --------------------start of test code--------------------\n",
    "# test code\n",
    "# ---------------------end of test code---------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e23fec62-fd3a-49c4-987c-143a20f524f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_search_results():\n",
    "    # process gs_poten_urls\n",
    "    with open(fpath.gs_poten_urls, \"r\") as file:\n",
    "        lines = []\n",
    "        for line in file:\n",
    "            print(line)\n",
    "            line = line.strip()\n",
    "            lines.append(line)\n",
    "    print(len(lines))\n",
    "    doi_list = []\n",
    "    for url in lines:\n",
    "        response = requests.get(url, headers = plib.headers)\n",
    "        soup = BeautifulSoup(response.content,\"lxml\")\n",
    "        # print(soup)\n",
    "        num_results_str = soup.select(\"a\", href = True)\n",
    "        for href in num_results_str:\n",
    "            if \"//doi.org/\" in href:\n",
    "                doi_list.append(href)\n",
    "    doi_df = pd.DataFrame({\"DOI\": doi_list})\n",
    "    plib.clear_file(fpath.path_poten_csv)\n",
    "    doi_df.to_csv(fpath.path_poten_csv, index=False)\n",
    "    \n",
    "    # process wos_poten_urls\n",
    "    doi_df = pd.read_csv(fpath.wos_poten_urls, sep=\";\")\n",
    "    # print(doi_df.columns)\n",
    "    # print(doi_df.head())\n",
    "    doi_df = doi_df[[\"DOI\"]]\n",
    "    doi_df.to_csv(fpath.path_poten_csv, mode=\"a\", index=False, header=False)\n",
    "    \n",
    "    # process pubmed_pmc_poten_urls\n",
    "    doi_df = pd.read_csv(fpath.pubmed_pmc_poten_urls)\n",
    "    doi_df = doi_df[[\"DOI\"]]\n",
    "    doi_df.to_csv(fpath.path_poten_csv, mode=\"a\", index=False, header=False)\n",
    "    \n",
    "    # process eupmc_poten_urls\n",
    "    doi_df = pd.read_csv(fpath.eupmc_poten_urls)\n",
    "    doi_df = doi_df[[\"DOI\"]]\n",
    "    doi_df.to_csv(fpath.path_poten_csv, mode=\"a\", index=False, header=False)\n",
    "    \n",
    "    # eliminate duplicates\n",
    "    doi_df = pd.read_csv(fpath.path_poten_csv)\n",
    "    print(len(doi_df))\n",
    "    doi_df = doi_df.drop_duplicates(subset = \"DOI\")\n",
    "    print(len(doi_df))\n",
    "    doi_df.to_csv(fpath.path_poten_csv, index=False)\n",
    "    # end of merge_search_results\n",
    "\n",
    "# --------------------start of test code--------------------\n",
    "# test code\n",
    "# ---------------------end of test code---------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9df256b-106e-4d5d-847e-b068fbade613",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# main program\n",
    "# first we need to search all related literature that might include data or information of thalamocortical connections\n",
    "# search for potentially related literature using the listed 3 methods\n",
    "\n",
    "# # method 1: search acdemic databases using keywords\n",
    "# search_acad_dbs(acad_dbs, init_urls, plib.headers, plib.proxy)\n",
    "\n",
    "# # method 2: spanning citations of seed papers\n",
    "# span_citations(seed_papers, num_span_time, headers, proxy)\n",
    "\n",
    "# # method 3: search existing connectome databases\n",
    "# search_conne_db(connec_db, connec_db_quries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8379912b-0688-4d9e-8641-50753f32a54e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "8538\n",
      "7058\n"
     ]
    }
   ],
   "source": [
    "# merge all search results\n",
    "merge_search_results(headers)\n",
    "\n",
    "# send .PDF publication of all potential related literatures to ChatPDF.con and ask for relatedness \n",
    "# then record the answer to the list_of_potential_related_literature.csv as well\n",
    "# ChatPDF_relatedness(path_urls, chatpdf_related_queries)\n",
    "\n",
    "# now we have a list of potential related literature and the information about relatedness \n",
    "# stored in the file \"list_of_potential_related_literature.csv\"\n",
    "# now we may perform a automatic filtering and manual filtering of the literature\n",
    "\n",
    "# automatic filtering\n",
    "#auto_filter(path_potential)\n",
    "\n",
    "# manual filtering\n",
    "# manual_filter(path_potential, path_related_urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c754a0f-82ec-4c2c-b949-f06ab46d5d25",
   "metadata": {},
   "source": [
    "This is the end of semi-automated literature search."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bf1484-5217-4a14-9c48-ff176f46d57b",
   "metadata": {},
   "source": [
    "Now we have a list of actually related literature stored in list_of_related_literature.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f23abd-ef1d-44b0-8658-3ce0bc705bbd",
   "metadata": {},
   "source": [
    "Next step: we perform a information search on the list of related literature\n",
    "We have a list of actually related literature at the moment, now we need to extract information we need from the literature. We intend to achieve this with a combination of automated searching and manual extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d00a5cd2-5c93-4fa2-ada2-138b94cee0a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# some test code, should comment-out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e4813f66-c983-4ecd-979a-3de2c97c5a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test the redirect of the urls\n",
    "# headers = {\"User-Agent\":\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_2) AppleWebKit/601.3.9 (KHTML, like Gecko) Version/9.0.2 Safari/601.3.9\"}\n",
    "\n",
    "# response_pdf = requests.get(\"https://doi.org/10.1016/j.neuron.2020.01.005\", allow_redirects=True, headers = headers)\n",
    "# print(response_pdf.history)\n",
    "# print(response_pdf.url)\n",
    "# response_pdf_1 = requests.get(\"https://linkinghub.elsevier.com/retrieve/pii/S0896627320300052\", allow_redirects=True, headers = headers)\n",
    "# print(response_pdf_1.history)\n",
    "# print(response_pdf_1.url)\n",
    "\n",
    "\n",
    "# response_pdf = requests.get(\"https://onlinelibrary.wiley.com/doi/10.1111/ejn.13910\", headers = headers)\n",
    "# soup_pdf = BeautifulSoup(response_pdf.content,\"lxml\")\n",
    "# print(soup_pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a8d39c9c-623c-4e2c-b0b4-a44d79b96f88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import re\n",
    "# if \"//doi.org/\" in \"https://doi.org/10.1016/0165-0173(96)00003-3\":\n",
    "#     print(\"yes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "40067374-c25b-40f8-ba36-8405a24e9a90",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# test extract doi from url\n",
    "with open(fpath.gs_poten_urls, \"r\") as file:\n",
    "    lines = []\n",
    "    for line in file:\n",
    "        print(line)\n",
    "        line = line.strip()\n",
    "        lines.append(line)\n",
    "print(len(lines))\n",
    "doi_list = []\n",
    "for url in lines:\n",
    "    response = requests.get(url, headers = headers)\n",
    "    soup = BeautifulSoup(response.content,\"lxml\")\n",
    "    # print(soup)\n",
    "    num_results_str = soup.select(\"a\", href = True)\n",
    "    print(num_results_str)\n",
    "    for href in num_results_str:\n",
    "        if \"//doi.org/\" in href[\"href\"]:\n",
    "            doi_list.append(href[\"href\"])\n",
    "            print(href[\"href\"])\n",
    "        else:\n",
    "            print(\"Ops! Did't find DOI on this page!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f15ed5-64f4-489f-97a6-242bccfa7c69",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Ops! Did't find DOI on this page!\n"
     ]
    }
   ],
   "source": [
    "# find DOI\n",
    "# this link does not have \"DOI\" in href form but text from\n",
    "url = \"https://www.jneurosci.org/content/28/43/11042.short\"\n",
    "# url = \"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2613515/\"\n",
    "response = requests.get(url, headers = plib.headers)\n",
    "soup = BeautifulSoup(response.content,\"lxml\")\n",
    "# print(soup)\n",
    "doi_list = []\n",
    "num_results_str = soup.select(\"a\", href = True)\n",
    "# print(num_results_str)\n",
    "for item in num_results_str:\n",
    "    if \"//doi.org/\" in item[\"href\"]:\n",
    "        print(item[\"href\"])\n",
    "        doi_list.append(item[\"href\"].split(\"//doi.org/\")[1])\n",
    "\n",
    "print(doi_list)\n",
    "        \n",
    "if len(doi_list) == 0:\n",
    "    print(\"Ops! Did't find DOI on this page!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79686627-676e-4eec-bad4-dd64cbffd90b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test redirect when access the doi link\n",
    "from elsapy.elsdoc import FullDoc, AbsDoc\n",
    "from elsapy.elsclient import ElsClient\n",
    "import json\n",
    "headers = {\n",
    "    \"User-Agent\":\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_2) AppleWebKit/601.3.9 (KHTML, like Gecko) Version/9.0.2 Safari/601.3.9\", \n",
    "    \"X-ELS-APIKEY\": \"310946e6e005957982c2c9cad6833ad3\",\n",
    "    \"Accept\": \"application/pdf\",\n",
    "    \"X-ELS-Insttoken\": \"instToken\",\n",
    "    \"view\": \"FULL\"\n",
    "} \n",
    "# url = \"https://www.jneurosci.org/content/28/43/11042.short\"\n",
    " #url = \"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2613515/\"\n",
    "\n",
    "# Journal of Neurophysiology\n",
    "# url = \"https://doi.org/10.1152/jn.2001.85.1.219\"\n",
    "# url = \"https://journals.physiology.org/doi/10.1152/jn.2001.85.1.219\"\n",
    "\n",
    "# science direct\n",
    "# url = \"https://doi.org/10.1016/j.biopsych.2004.10.014\"\n",
    "# url = \"https://linkinghub.elsevier.com/retrieve/pii/S0006322304010947\"\n",
    "# url = \"https://www.sciencedirect.com/science/article/pii/S0006322304010947?via%3Dihub\"\n",
    "url = \"https://api.elsevier.com/content/article/doi/{10.1016/j.biopsych.2004.10.014}\"\n",
    "\n",
    "# response = requests.get(url, headers = headers)\n",
    "# soup = BeautifulSoup(response.content,\"lxml\")\n",
    "# print(soup)\n",
    "# print(response.history)\n",
    "# print(response.url)\n",
    "# # Load configuration\n",
    "# con_file = open(\"config.json\")\n",
    "# config = json.load(con_file)\n",
    "# con_file.close()\n",
    "\n",
    "# response = requests.get(url, headers = headers)\n",
    "# print(response)\n",
    "\n",
    "# ## Initialize client\n",
    "# client = ElsClient(config[\"apikey\"])\n",
    "\n",
    "# ## ScienceDirect (full-text) document example using DOI\n",
    "# doi_doc = FullDoc(doi = \"10.1016/j.biopsych.2004.10.014\")\n",
    "# print(doi_doc)\n",
    "# if doi_doc.read(client):\n",
    "#     print (\"doi_doc.title: \", doi_doc.title)\n",
    "#     doi_doc.write(\"doi_doc\")   \n",
    "# else:\n",
    "#     print (\"Read document failed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd81a715-ee56-4f75-a193-08d92c9fcd48",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "MINI REVIEWpublished: 02 December 2015doi: 10.3389/fncir.2015.00079Vestibular Interactions in theThalamusRajiv Wijesinghe1,Dario A. Protti2andAaron J. Camp1*1Sensory Systems and Integration Laboratory, Sydney Medical School, Discipline of Biomedical Science, University ofSydney, Sydney, NSW, Australia,2Vision Laboratory, Sydney Medical School, Discipline of Physiology, University of Sydney,Sydney, NSW, AustraliaEdited by:W. Martin Usrey,University of California, Davis, USAReviewed by:Elizabeth Quinlan,University of Maryland College Park,USAMarianne Dieterich,Ludwig-Maximilians-University,Germany*Correspondence:Aaron J. Campaaron.camp@sydney.edu.auReceived: 28 August 2015Accepted: 10 November 2015Published: 02 December 2015Citation:Wijesinghe R, Protti DA and Camp AJ(2015) Vestibular Interactions inthe Thalamus.Front. Neural Circuits 9:79.doi: 10.3389/fncir.2015.00079It has long been known that the vast majority of all information en route to the cerebralcortex must ﬁrst pass through the thalamus. The long held view that the thalamusserves as a simple hi ﬁdelity relay station for sensory information to the cortex, however,has over recent years been dispelled. Indeed, multiple projections from the vestibularnuclei to thalamic nuclei (including the ventrobasal nuclei, and the geniculate bodies)-regions typically associated with other modalities- have been described. Further, somethalamic neurons have been shown to respond to stimuli presented from across sensorymodalities. For example, neurons in the rat anterodorsal and laterodorsal nuclei of thethalamus respond to visual, vestibular, proprioceptive and somatosensory stimuli andintegrate this information to compute heading within the environment. Together, theseﬁndings imply that the thalamus serves crucial integrative functions, at least in regardto vestibular processing, beyond that imparted by a “simple” relay. In this mini reviewwe outline the vestibular inputs to the thalamus and provide some clinical context forvestibular interactions in the thalamus. We then focus on how vestibular inputs interactwith other sensory systems and discuss the multisensory integration properties of thethalamus.Keywords: vestibular, thalamus, LGN, multisensory integration, vestibular nucleiINTRODUCTIONThe vestibular system differs from the other primary sensory systems in a number offundamental ways. Most sensory systems are organized in a linear fashion, where peripheralorgan fibers project primarily through a modality-specific thalamic nucleus (for exampleLGN for the visual system, MGN for the auditory system) and only then onto theirrespective cortical or subcortical targets. These ordered projections through the thalamuscreate a sensory map that closely matches that created in the periphery, and this tends tobe maintained by downstream thalamocortical projections [for review, see Jones (1985)].Abbreviations: CL, Centrolateral Nucleus; CM, Centromedian Nucleus; IL, Interlaminar Nuclei; IVN, InferiorVestibular Nucleus; LGN, Lateral Geniculate Nucleus; LVN, Lateral Vestibular Nucleus; LP, Lateral Posterior Nucleus;LD, Lateral Dorsal Nucleus; MGN, Medial Geniculate Nucleus; MVN, Medial Vestibular Nucleus; PNF, ParafascicularNucleus; SpVN, spinal (descending) vestibular Nucleus; SuVN, Superior Vestibular Nucleus; VA, VentroanteriorNucleus; VI, Ventral Intermediate Nucleus; VL, Ventrolateral Nucleus; VP, Ventral Posterior Nucleus; VPL, VentralPosterior Lateral Nucleus; VPM, Ventral Posterior Medial Nucleus.Frontiers in Neural Circuits | www.frontiersin.org 1 December 2015 | Volume 9 | Article 79\n"
     ]
    }
   ],
   "source": [
    "# test pdf to text\n",
    "from PyPDF2 import PdfReader\n",
    "  \n",
    "# creating a pdf reader object\n",
    "reader = PdfReader(\"/Users/didihou/Downloads/fncir-09-00079.pdf\")\n",
    "  \n",
    "# printing number of pages in pdf file\n",
    "print(len(reader.pages))\n",
    "  \n",
    "# getting a specific page from the pdf file\n",
    "page = reader.pages[0]\n",
    "  \n",
    "# extracting text from page\n",
    "text = \"\".join(page.extract_text().splitlines())\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efb22af-4181-4ec0-af99-34d50e8a0c5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
