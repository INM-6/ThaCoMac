{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> 3. Download full text (pdf/json) </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # list all pdf source\n",
    "# input_path = fpath.poten_litera_litera_db\n",
    "# df = pd.read_csv(input_path, header=None, sep=',')\n",
    "# df.columns = [\"INDEX\", \"DOI\", \"PMID\", \"PMCID\", \"FULL_TEXT_URL\", \"FULL_TEXT_SOURCE\", \"PDF_URL\", \"PDF_SOURCE\", \"TITLE\", \"ABSTRACT\", \"KEYWORDS\"]\n",
    "# pdf_source_set = set(df['PDF_SOURCE'].tolist())\n",
    "# print(pdf_source_set)\n",
    "# # {'www.ahajournals.org', 'anatomypubs.onlinelibrary.wiley.com', 'citeseerx.ist.psu.edu', 'www.nature.com', \n",
    "# # 'iovs.arvojournals.org', 'www.microbiologyresearch.org', 'nyaspubs.onlinelibrary.wiley.com', 'ahuman.org', \n",
    "# # 'karger.com', 'www.imrpress.com', 'www.researchsquare.com', 'link.springer.com', 'www.ijpp.com', \n",
    "# # 'europepmc.org', nan, 'www.cell.com', 'www.bu.edu', 'www.ncbi.nlm.nih.gov', 'jamanetwork.com', \n",
    "# # 'www.thieme-connect.de', 'www.science.org', 'physoc.onlinelibrary.wiley.com', 'deepblue.lib.umich.edu', \n",
    "# # 'bpb-us-e1.wpmucdn.com', 'www.researchgate.net', 'ieeexplore.ieee.org', 'zsp.com.pk', 'journals.biologists.com', \n",
    "# # 'journals.aps.org', 'papers.ssrn.com', 'academic.oup.com', 'onlinelibrary.wiley.com', 'www.hifo.uzh.ch', \n",
    "# # 'royalsocietypublishing.org', 'www.biorxiv.org', 'www.ingentaconnect.com', 'ujms.net', 'enpubs.faculty.ucdavis.edu', \n",
    "# # 'ajp.psychiatryonline.org', 'n.neurology.org', 'www.annualreviews.org', 'ruor.uottawa.ca', 'neuro.psychiatryonline.org', \n",
    "# # 'www.jstage.jst.go.jp', 'synapse.koreamed.org', 'journals.physiology.org', 'linkinghub.elsevier.com', \n",
    "# # 'www.tandfonline.com', 'www.jneurosci.org', 'analyticalsciencejournals.onlinelibrary.wiley.com', 'pubs.asahq.org', \n",
    "# # 'thejns.org', 'biomedical-engineering-online.biomedcentral.com', 'journals.sagepub.com', 'direct.mit.edu', \n",
    "# # 'pubs.acs.org', 'pharmrev.aspetjournals.org', 'journals.lww.com', 'jnm.snmjournals.org', 'jpet.aspetjournals.org', \n",
    "# # 'movementdisorders.onlinelibrary.wiley.com'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # list the pdf_source and prepare the test code for downloading the pdfs\n",
    "# pdf_source_set = [\n",
    "#     'www.ahajournals.org', 'wiley.com', 'citeseerx.ist.psu.edu', 'www.nature.com', \n",
    "#     'iovs.arvojournals.org', 'www.microbiologyresearch.org', 'ahuman.org', \n",
    "#     'karger.com', 'www.imrpress.com', 'www.researchsquare.com', 'link.springer.com', 'www.ijpp.com', \n",
    "#     'europepmc.org', 'www.cell.com', 'www.bu.edu', 'www.ncbi.nlm.nih.gov', 'jamanetwork.com', \n",
    "#     'www.thieme-connect.de', 'www.science.org', 'deepblue.lib.umich.edu', \n",
    "#     'bpb-us-e1.wpmucdn.com', 'www.researchgate.net', 'ieeexplore.ieee.org', 'zsp.com.pk', 'journals.biologists.com', \n",
    "#     'journals.aps.org', 'papers.ssrn.com', 'academic.oup.com', 'www.hifo.uzh.ch', \n",
    "#     'royalsocietypublishing.org', 'www.biorxiv.org', 'www.ingentaconnect.com', 'ujms.net', 'enpubs.faculty.ucdavis.edu', \n",
    "#     'psychiatryonline.org', 'n.neurology.org', 'www.annualreviews.org', 'ruor.uottawa.ca', \n",
    "#     'www.jstage.jst.go.jp', 'synapse.koreamed.org', 'journals.physiology.org', 'linkinghub.elsevier.com', \n",
    "#     'www.tandfonline.com', 'www.jneurosci.org', 'pubs.asahq.org', \n",
    "#     'thejns.org', 'biomedcentral.com', 'journals.sagepub.com', 'direct.mit.edu', \n",
    "#     'pubs.acs.org', 'aspetjournals.org', 'journals.lww.com', 'jnm.snmjournals.org'\n",
    "# ]\n",
    "\n",
    "# input_path = fpath.poten_litera_litera_db\n",
    "# df = pd.read_csv(input_path, header=None, sep=',')\n",
    "# df.columns = [\"INDEX\", \"DOI\", \"PMID\", \"PMCID\", \"FULL_TEXT_URL\", \"FULL_TEXT_SOURCE\", \"PDF_URL\", \"PDF_SOURCE\", \"TITLE\", \"ABSTRACT\", \"KEYWORDS\"]\n",
    "# for website in pdf_source_set:\n",
    "#     for ind in df.index:\n",
    "#         if df.at[ind, \"PDF_SOURCE\"] != df.at[ind, \"PDF_SOURCE\"]:\n",
    "#             continue\n",
    "#         if website in df.at[ind, \"PDF_SOURCE\"]:\n",
    "#             print(\"# \" + website)\n",
    "#             print(\"\\\"\" + df.at[ind, \"PDF_URL\"] + \"\\\"\")\n",
    "#             break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_path = fpath.poten_litera_litera_db\n",
    "# df = pd.read_csv(input_path, header=None, sep=',')\n",
    "# print(df.shape)\n",
    "# print(df.head(5))\n",
    "# # (10776, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # download pdfs and jsons, rename them to build a database\n",
    "# input_path = fpath.poten_litera_db\n",
    "# pdf_folder = fpath.pdf_folder\n",
    "# download_pdf(input_path, pdf_folder, 0, 10776)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # list the articles whose pdfs are not downloaded, and manually download them if possible\n",
    "# input_path = fpath.poten_litera_db\n",
    "# df = pd.read_csv(input_path, header=None, sep=',')\n",
    "# df.columns = df_col.db_columns\n",
    "\n",
    "# pdf_folder = fpath.pdf_folder\n",
    "\n",
    "# for ind in df.index:\n",
    "#     index = int(df.at[ind, \"INDEX\"])\n",
    "#     pdf_file_name = str(index) + \".pdf\"\n",
    "#     json_file_name = str(index) + \".json\"\n",
    "#     pdf_path = os.path.join(pdf_folder, pdf_file_name)\n",
    "#     json_path = os.path.join(pdf_folder, json_file_name)\n",
    "\n",
    "#     # if full text is not available/downloaded, print the info\n",
    "#     if (not os.path.exists(json_path)) and (not os.path.exists(pdf_path)):\n",
    "#         print(df.at[ind, \"INDEX\"], df.at[ind, \"DOI\"], df.at[ind, \"PMID\"], df.at[ind, \"PMCID\"])\n",
    "#         print(df.at[ind, \"TITLE\"])\n",
    "#         print(df.at[ind, \"FULL_TEXT_URL\"], df.at[ind, \"FULL_TEXT_SOURCE\"])\n",
    "#         print(df.at[ind, \"PDF_URL\"], df.at[ind, \"PDF_SOURCE\"])\n",
    "#         print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the downloaded pdfs and jsons\n",
    "def test_pdf(pdf_path):       \n",
    "    # opens the file for reading\n",
    "    with open(pdf_path, 'rb') as p:\n",
    "        txt = (p.readlines())\n",
    "\n",
    "    actual_line = len(txt)\n",
    "    \n",
    "    for i, x in enumerate(txt[::-1]):\n",
    "        if b'%%EOF' in x:\n",
    "            actual_line = len(txt)-i\n",
    "            # print(f'EOF found at line position {-i} = actual {actual_line}, with value {x}')\n",
    "            break\n",
    "    \n",
    "    if actual_line != len(txt):\n",
    "        # get the new list terminating correctly\n",
    "        txtx = txt[:actual_line]\n",
    "\n",
    "        # write to new pdf\n",
    "        with open(pdf_path, 'wb') as f:\n",
    "            f.writelines(txtx)\n",
    "        f.close()\n",
    "\n",
    "    fixed_pdf = PyPDF2.PdfReader(pdf_path)\n",
    "\n",
    "    page_max = len(fixed_pdf.pages)\n",
    "\n",
    "    if page_max < 5:\n",
    "        print(page_max)\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "# --------------------start of test code--------------------\n",
    "# input_path = fpath.poten_litera_db\n",
    "# df = pd.read_csv(input_path, header=None, sep=',')\n",
    "# df.columns = [\"INDEX\", \"DOI\", \"PMID\", \"PMCID\", \"FULL_TEXT_URL\", \"FULL_TEXT_SOURCE\", \"PDF_URL\", \"PDF_SOURCE\", \"TITLE\", \"ABSTRACT\", \"KEYWORDS\"]\n",
    "\n",
    "# pdf_folder = fpath.pdf_folder\n",
    "\n",
    "# start = 0\n",
    "# end = 10776\n",
    "\n",
    "# for ind in range(start, end):\n",
    "    # index = str(int(df.at[ind, \"INDEX\"]))\n",
    "    # pdf_file_name = str(index) + \".pdf\"\n",
    "    # json_file_name = str(index) + \".json\"\n",
    "    # pdf_path = os.path.join(pdf_folder, pdf_file_name)\n",
    "    # json_path = os.path.join(pdf_folder, json_file_name)\n",
    "\n",
    "    # try:\n",
    "    #     if os.path.exists(json_path):\n",
    "    #         print(ind, index)\n",
    "    #         continue\n",
    "    #     elif os.path.exists(pdf_path):\n",
    "    #         if test_pdf(pdf_path):\n",
    "    #             print(ind, index)\n",
    "    #         else:\n",
    "    #             print(\"\\n\")\n",
    "    #             print(\"PDF LEGNTH < 3\")\n",
    "    #             print(df.at[ind, \"INDEX\"], df.at[ind, \"DOI\"], df.at[ind, \"PMID\"], df.at[ind, \"PMCID\"])\n",
    "    #             print(df.at[ind, \"FULL_TEXT_URL\"], df.at[ind, \"FULL_TEXT_SOURCE\"])\n",
    "    #             print(df.at[ind, \"PDF_URL\"], df.at[ind, \"PDF_SOURCE\"])\n",
    "    #             print(ind, index)\n",
    "    #             print(\"\\n\")\n",
    "    #     else:\n",
    "    #         print(\"\\n\")\n",
    "    #         print(\"PDF NOT AVAILABLE\")\n",
    "    #         print(df.at[ind, \"INDEX\"], df.at[ind, \"DOI\"], df.at[ind, \"PMID\"], df.at[ind, \"PMCID\"])\n",
    "    #         print(df.at[ind, \"FULL_TEXT_URL\"], df.at[ind, \"FULL_TEXT_SOURCE\"])\n",
    "    #         print(df.at[ind, \"PDF_URL\"], df.at[ind, \"PDF_SOURCE\"])\n",
    "    #         print(ind, index)\n",
    "    #         print(\"\\n\")\n",
    "    # except:\n",
    "    #     print(\"\\n\")\n",
    "    #     print(\"PDF Corrupted\")\n",
    "    #     print(df.at[ind, \"INDEX\"], df.at[ind, \"DOI\"], df.at[ind, \"PMID\"], df.at[ind, \"PMCID\"])\n",
    "    #     print(df.at[ind, \"FULL_TEXT_URL\"], df.at[ind, \"FULL_TEXT_SOURCE\"])\n",
    "    #     print(df.at[ind, \"PDF_URL\"], df.at[ind, \"PDF_SOURCE\"])\n",
    "    #     print(ind, index)\n",
    "    #     print(\"\\n\")\n",
    "# ---------------------end of test code---------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # copy the relevant and not relevant pdfs and jsons from \"pdfs\" to repective folders \"relevant_pdfs\" and \"not_relevant_pdfs\"\n",
    "# test_path = fpath.poten_litera_testing_set_300_read_index_corrected\n",
    "# destination1 = \"/media/hou/DIDIHOU/relevant_pdfs\"\n",
    "# destination2 = \"/media/hou/DIDIHOU/not_relevant_pdfs\"\n",
    "\n",
    "# df_test = pd.read_csv(test_path, header=0, sep=',')\n",
    "# df_test.columns = [\"INDEX\", \"DOI\", \"PMID\", \"PMCID\", \"FULL_TEXT_URL\", \"FULL_TEXT_SOURCE\", \"PDF_URL\", \"PDF_SOURCE\", \"TITLE\", \"ABSTRACT\", \"KEYWORDS\", \"RELEVANT\"]\n",
    "\n",
    "# for ind in df_test.index:\n",
    "#     index = df_test.at[ind, \"INDEX\"]\n",
    "#     if df_test.at[ind, \"RELEVANT\"] == \"YES\": # relevant\n",
    "#         flag = False\n",
    "#         print(ind, index)\n",
    "        \n",
    "#         json_path = os.path.join(fpath.pdf_folder, str(index) + \".json\")\n",
    "#         pdf_path = os.path.join(fpath.pdf_folder, str(index) + \".pdf\")\n",
    "        \n",
    "#         if os.path.exist(json_path):\n",
    "#             shutil.copy(json_path, destination1)\n",
    "#             flag = True\n",
    "#         if os.path.exist(pdf_path):\n",
    "#             shutil.copy(pdf_path, destination1)\n",
    "#             flag = True\n",
    "        \n",
    "#         if not flag:\n",
    "#             print(\"No file found for index: \", index)\n",
    "#     else: # not relevant\n",
    "#         json_path = os.path.join(fpath.pdf_folder, str(index) + \".json\")\n",
    "#         pdf_path = os.path.join(fpath.pdf_folder, str(index) + \".pdf\")\n",
    "\n",
    "#         if os.path.exist(json_path):\n",
    "#             shutil.copy(json_path, destination2)\n",
    "#         if os.path.exist(pdf_path):\n",
    "#             shutil.copy(pdf_path, destination2)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
