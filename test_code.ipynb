{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-06 00:55:50 Didis-MacBook-Pro.local metapub.config[6773] WARNING NCBI_API_KEY was not set.\n"
     ]
    }
   ],
   "source": [
    "# import internal modules\n",
    "import file_path_management as fpath\n",
    "import public_library as plib\n",
    "import extract_info\n",
    "import parameters as params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import csv\n",
    "import pandas as pd\n",
    "import PyPDF2\n",
    "import requests\n",
    "import time\n",
    "import os\n",
    "import random\n",
    "from requests.auth import HTTPProxyAuth\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.firefox import GeckoDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.firefox import GeckoDriverManager\n",
    "from selenium.webdriver.firefox.service import Service\n",
    "from selenium.common.exceptions import TimeoutException, WebDriverException, NoSuchElementException\n",
    "import os\n",
    "import re\n",
    "from lxml import etree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract text from given .pdf file\n",
    "def pdf2text(pdf_path, text_path, page_start, page_end):\n",
    "    try:\n",
    "        # creating a pdf reader object\n",
    "        reader = PyPDF2.PdfReader(pdf_path)\n",
    "        \n",
    "        # printing number of pages in pdf file\n",
    "        page_max = len(reader.pages)\n",
    "        \n",
    "        # getting a specific page from the pdf file\n",
    "        text = \"\"\n",
    "        \n",
    "        for i in range(page_start, page_end + 1):\n",
    "            # print(i)\n",
    "            page = reader.pages[i]\n",
    "            text = text + \"\".join(page.extract_text().splitlines())\n",
    "\n",
    "        with open(text_path, \"w\") as f:\n",
    "            f.write(text)\n",
    "        f.close()\n",
    "\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "# --------------------start of test code--------------------\n",
    "# ind = 1\n",
    "# pdf_file_name = str(index) + \".pdf\"\n",
    "# pdf_folder = fpath.litera_pdf_folder\n",
    "# pdf_path = os.path.join(pdf_folder, pdf_file_name)\n",
    "\n",
    "# text_folder_path = fpath.litera_text_folder\n",
    "# text_file_name = pdf_file_name.split(\".pdf\")[0] + \".txt\"\n",
    "# text_path = os.path.join(text_folder_path, text_file_name)\n",
    "\n",
    "# start_page = 0\n",
    "# end_page = 1\n",
    "# if not pdf2text(pdf_path, text_path, start_page, end_page):\n",
    "#     print(\"Error: pdf2text() failed\")\n",
    "# ---------------------end of test code---------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download pdf to specified folder given pdf_url and ind\n",
    "def download_pdf(pdf_url, pdf_folder):  \n",
    "    url = pdf_url\n",
    "    if url != url:\n",
    "        raise Exception(\"pdf_url is np.nan\")\n",
    "    else:\n",
    "        source = url.split(\"://\")[1].split(\"/\")[0]\n",
    "    \n",
    "    # pdf_path = os.path.join(pdf_folder, file_name)\n",
    "      \n",
    "    # get the pdf content\n",
    "    # options = webdriver.ChromeOptions()\n",
    "    # options.add_experimental_option('prefs', {\n",
    "    # \"download.default_directory\": pdf_folder, #Change default directory for downloads\n",
    "    # \"download.prompt_for_download\": False, #To auto download the file\n",
    "    # \"download.directory_upgrade\": True,\n",
    "    # \"download.open_pdf_in_system_reader\": False,\n",
    "    # \"plugins.always_open_pdf_externally\": True #It will not show PDF directly in chrome\n",
    "    # })\n",
    "    # driver = webdriver.Chrome(options=options)\n",
    "    # # response = driver.get(pdf_url)\n",
    "    # driver.navigate().to(url)\n",
    "    # time.sleep(5)\n",
    "    if source == \"www.sciencedirect.com\":\n",
    "        os.environ['WDM_LOG'] = '0'\n",
    "        options = Options()\n",
    "        options.add_argument('--headless')\n",
    "        driver = webdriver.Chrome()\n",
    "        driver.get(url)\n",
    "        element = WebDriverWait(driver, 30).until(EC.element_to_be_clickable((By.XPATH, \"//li[@class='ViewPDF']/a\")))\n",
    "        element.click()\n",
    "        time.sleep(10)\n",
    "    else: \n",
    "        options = webdriver.ChromeOptions()\n",
    "        options.add_experimental_option('prefs', {\n",
    "        \"download.default_directory\": pdf_folder, #Change default directory for downloads\n",
    "        \"download.prompt_for_download\": False, #To auto download the file\n",
    "        \"download.directory_upgrade\": True,\n",
    "        \"plugins.always_open_pdf_externally\": True #It will not show PDF directly in chrome\n",
    "        })\n",
    "        driver = webdriver.Chrome(options=options)\n",
    "        response = driver.get(url)\n",
    "        time.sleep(10)\n",
    "    driver.close()\n",
    "\n",
    "    # try:\n",
    "    #     with open(pdf_path, 'wb') as pdf_object:\n",
    "    #         pdf_object.write(response.content)\n",
    "    #         driver.close()\n",
    "    #         return True\n",
    "    # except:\n",
    "    #     print(f'Failed downloading PDF:', url)\n",
    "    #     driver.close()\n",
    "    #     # print(f'HTTP response status code: {response.status_code}')\n",
    "    #     return False\n",
    "# --------------------start of test code--------------------\n",
    "# # pdf_url = 'https://www.sciencedirect.com/science/article/pii/S0896627320300052/pdfft?md5=3f0648c6385e6fae3a5a73b053903014&pid=1-s2.0-S0896627320300052-main.pdf'\n",
    "# # pdf_url = \"https://www.sciencedirect.com/science/article/pii/S1053811909013299?via%3Dihub\"\n",
    "# # pdf_url = \"https://linkinghub.elsevier.com/retrieve/pii/S1053811909013299\"\n",
    "# # pdf_url = \"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1181753/pdf/jphysiol00456-0559.pdf\"\n",
    "# pdf_url = \"https://www.sciencedirect.com/science/article/pii/S0896627320300052?via%3Dihub\"\n",
    "\n",
    "# # wiley.com\n",
    "# # pdf_url = \"https://onlinelibrary.wiley.com/doi/pdf/10.1002/cne.903130106\"\n",
    "# # pdf_url = \"https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/cne.903130106\"\n",
    "# # pdf_url = \"https://onlinelibrary.wiley.com/doi/pdf/10.1002/cne.902770204\"\n",
    "# # pdf_url = \"https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/cne.902770204\"\n",
    "# # pdf_url = \"https://onlinelibrary.wiley.com/doi/pdf/10.1002/cne.902970309\"\n",
    "# # pdf_url = \"https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/cne.902970309\"\n",
    "\n",
    "# # physiology.org\n",
    "# # pdf_url = \"https://journals.physiology.org/doi/pdf/10.1152/jn.2001.85.1.219\"\n",
    "\n",
    "# # springer.com\n",
    "# # pdf_url = \"https://link.springer.com/content/pdf/10.1007/BF00236173.pdf\"\n",
    "\n",
    "# # cell.com\n",
    "# # pdf_url = \"https://www.cell.com/neuron/pdf/S0896-6273(09)00170-6.pdf\"\n",
    "\n",
    "# # jneurosci.org\n",
    "# # pdf_url = \"https://www.jneurosci.org/content/jneuro/22/18/8117.full.pdf\"\n",
    "# # pdf_url, code = plib.get_final_redirected_url(pdf_url)\n",
    "# # print(pdf_url)\n",
    "# ind = 10\n",
    "# file_name = str(ind) + \".pdf\"\n",
    "# pdf_folder = fpath.litera_pdf_folder\n",
    "# download_pdf(pdf_url, pdf_folder)\n",
    "# # rename_pdf(file_name, pdf_folder, time_to_wait=60)\n",
    "# ---------------------end of test code---------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_from_www_ncbi_nlm_nih_gov(url, ind, pdf_folder):\n",
    "    try:\n",
    "        file_name = str(ind) + \".pdf\"\n",
    "        response = requests.get(url, headers=plib.headers)\n",
    "        # response = requests.get(url, stream=True, allow_redirects=True, headers=plib.headers)\n",
    "        \n",
    "        # download the .pdf file to the pdf_file_path folder\n",
    "        # write content in pdf file\n",
    "        pdf_path = os.path.join(pdf_folder, file_name)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            with open(pdf_path, 'wb') as pdf_object:\n",
    "                pdf_object.write(response.content)\n",
    "            print(f'Successfully downloaded PDF:', ind)\n",
    "        else:\n",
    "            print(f'Failed downloading PDF:' + 'pdf_url')\n",
    "            print(f'HTTP response status code: {response.status_code}')\n",
    "    except:\n",
    "        print(f'Failed downloading PDF:' + 'pdf_url')\n",
    "# --------------------start of test code--------------------\n",
    "# pdf_url = \"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6577493/pdf/jneuro_14_5_2485.pdf\"\n",
    "# ind = 10\n",
    "# file_name = str(ind) + \".pdf\"\n",
    "# pdf_folder = \"/home/hou/myProjects/litera_pdfs\"\n",
    "# download_from_www_ncbi_nlm_nih_gov(pdf_url, ind, pdf_folder)\n",
    "# # rename_pdf(file_name, pdf_folder, time_to_wait=60)\n",
    "# ---------------------end of test code---------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def download_from_ELSEVIER(doi, file_to_save_to):\n",
    "#     url = 'http://api.elsevier.com/content/article/doi:'+doi+'?view=FULL'\n",
    "#     headers = {\n",
    "#         'X-ELS-APIKEY': \"63f58b8b10cbc1bc923011c01c6301bb\",\n",
    "#         'Accept': 'application/pdf'\n",
    "#     }\n",
    "#     r = requests.get(url, stream=True, headers=headers)\n",
    "#     if r.status_code == 200:\n",
    "#         for chunk in r.iter_content(chunk_size=1024*1024):\n",
    "#             file_to_save_to.write(chunk)\n",
    "#         return True\n",
    "\n",
    "# # doi_list = pd.read_excel('list.xls')\n",
    "# # doi_list.columns = ['DOIs']\n",
    "# count = 0\n",
    "# # for doi in doi_list['DOIs']:\n",
    "# doi = \"10.1016/0006-8993(95)01338-5\"\n",
    "# # pdf = \"10\"\n",
    "# ind = 10\n",
    "# file_name = str(ind) + \".pdf\"\n",
    "# # if not os.path.exists(f'path/{pdf}.pdf'):\n",
    "# with open(file_name, 'wb') as pdf_object:\n",
    "#     get_pdf(doi, pdf_object)\n",
    "# pdf_object.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download pdf\n",
    "def download_pdf(pdf_url, pdf_source, pdf_folder):\n",
    "    for website in params.website_pdfs:\n",
    "        func = None\n",
    "        if website in pdf_source:\n",
    "            # Get the function name by replacing \".\" with \"_\" and use globals() to call it\n",
    "            func_name = \"download_from_\" + website.replace(\".\", \"_\")\n",
    "            # print(func_name)\n",
    "            func = globals().get(func_name)\n",
    "            # print(func)\n",
    "            break\n",
    "    if func != None:\n",
    "        # print(func)\n",
    "        func(pdf_url, pdf_folder)\n",
    "    else:\n",
    "        print(\"The given url is not from a supported website: \", pdf_url)\n",
    "        raise Exception(\"Function does not exist for website:\", pdf_url)\n",
    "\n",
    "# rename downloaded pdf\n",
    "def rename_pdf(ind, pdf_folder, time_to_wait=60):\n",
    "    newname = str(ind) + \".pdf\"\n",
    "    time_counter = 0\n",
    "    filename = max([f for f in os.listdir(pdf_folder)], key=lambda xa :   os.path.getctime(os.path.join(pdf_folder,xa)))\n",
    "    while '.part' in filename:\n",
    "        time.sleep(1)\n",
    "        time_counter += 1\n",
    "        if time_counter > time_to_wait:\n",
    "            raise Exception('Waited too long for file to download')\n",
    "    filename = max([f for f in os.listdir(pdf_folder)], key=lambda xa :   os.path.getctime(os.path.join(pdf_folder,xa)))\n",
    "    os.rename(os.path.join(pdf_folder, filename), os.path.join(pdf_folder, newname))\n",
    "\n",
    "# download and rename pdf\n",
    "def download_and_rename_pdf(pdf_url, ind, pdf_folder):  \n",
    "    if pdf_url != pdf_url:\n",
    "        raise Exception(\"pdf_url is np.nan\")\n",
    "    else:\n",
    "        pdf_source = pdf_url.split(\"://\")[1].split(\"/\")[0]\n",
    "    download_pdf(pdf_url, pdf_source, pdf_folder)\n",
    "    rename_pdf(ind, pdf_folder, time_to_wait=60)\n",
    "    print(f\"Downloaded {ind}.pdf\")\n",
    "# --------------------start of test code--------------------\n",
    "# pdf_url = \"https://journals.physiology.org/doi/pdf/10.1152/jn.2001.85.1.219\"\n",
    "# ind = 10\n",
    "# pdf_folder = \"/home/hou/myProjects/litera_pdfs\"\n",
    "# download_and_rename_pdf(pdf_url, ind, pdf_folder)\n",
    "# ---------------------end of test code---------------------\n",
    "# https://journals.physiology.org/doi/10.1152/jn.2001.85.1.219"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ujms.net\n",
    "def ujms_net(url):\n",
    "    # initialize\n",
    "    info = {\n",
    "        \"doi\": np.nan,\n",
    "        \"pmid\": np.nan,\n",
    "        \"pmcid\": np.nan,\n",
    "        \"title\": np.nan,\n",
    "        \"abstract\": np.nan,\n",
    "        \"keywords\": np.nan,\n",
    "        \"pdf_link\": np.nan\n",
    "    }\n",
    "\n",
    "    # set up the webdriver\n",
    "    os.environ['WDM_LOG'] = '0'\n",
    "    options = Options()\n",
    "    options.add_argument('--headless')\n",
    "    driver = webdriver.Firefox(options=options)\n",
    "\n",
    "    # load the webpage\n",
    "    error_label = 0\n",
    "    while(error_label == 0):\n",
    "        try:\n",
    "            driver.get(url)\n",
    "            time.sleep(5)\n",
    "            error_label = 1\n",
    "        except:\n",
    "            print(\"Extracting content from:\" + url + \" failed, retrying... This might take longer than 5 minutes...\")\n",
    "            time.sleep(5*60)\n",
    "            error_label = 0\n",
    "    \n",
    "    # doi\n",
    "    try:\n",
    "        doi = driver.find_element(By.XPATH, \"//a[@class='epub-doi']\").text.split(\"doi.org/\")[1]\n",
    "        doi = doi.strip()\n",
    "    except:\n",
    "        doi = np.nan\n",
    "    if doi == doi:\n",
    "        doi = doi.lower()\n",
    "\n",
    "    # pmid, pmcid\n",
    "    pmid = np.nan\n",
    "    pmcid = np.nan\n",
    "\n",
    "    # title\n",
    "    try:\n",
    "        title = driver.find_element(By.XPATH, \"//h1[@class='citation__title']\").text\n",
    "        title = title.strip()\n",
    "    except:\n",
    "        try:\n",
    "            title = driver.find_element(By.XPATH, \"//h2[@class='citation__title']\").text\n",
    "            title = title.strip()\n",
    "        except:\n",
    "            title = np.nan\n",
    "    \n",
    "    # abstract\n",
    "    try:\n",
    "        abstract = \"\"\n",
    "        try:\n",
    "            elems = driver.find_element(By.XPATH, \"//h3[text()='Abstract' or text()='ABSTRACT' or text()='Summary' or text()='SUMMARY']\").find_element(By.XPATH, \"following-sibling::div\").find_elements(By.XPATH, 'p')\n",
    "        except:\n",
    "            elems = driver.find_element(By.XPATH, \"//h2[text()='Abstract' or text()='ABSTRACT' or text()='Summary' or text()='SUMMARY']\").find_element(By.XPATH, \"following-sibling::div\").find_elements(By.XPATH, 'p')                \n",
    "        for elem in elems:\n",
    "            abstract = abstract + elem.text + \" \"\n",
    "        abstract = abstract.strip()\n",
    "    except:\n",
    "        abstract = np.nan\n",
    "    \n",
    "    # keywords\n",
    "    keywords = np.nan\n",
    "\n",
    "    # pdf_link\n",
    "    try:\n",
    "        pdf_link = driver.find_element(By.XPATH, \"//a[@title='ePDF']\").get_attribute('href')\n",
    "        pdf_link = pdf_link.strip()\n",
    "    except:\n",
    "        pdf_link = np.nan\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "    info = {\n",
    "        \"doi\": doi,\n",
    "        \"pmid\": pmid,\n",
    "        \"pmcid\": pmcid,\n",
    "        \"title\": title,\n",
    "        \"abstract\": abstract,\n",
    "        \"keywords\": keywords,\n",
    "        \"pdf_link\": pdf_link\n",
    "    }\n",
    "\n",
    "    return info\n",
    "# --------------------start of test code--------------------\n",
    "# url = \"https://ujms.net/index.php/ujms/article/view/6812\"\n",
    "# info = ujms_net(url)\n",
    "# print(info[\"doi\"])\n",
    "# print(info[\"pmid\"])\n",
    "# print(info[\"pmcid\"])\n",
    "# print(info[\"title\"])\n",
    "# print(info[\"abstract\"])\n",
    "# print(info[\"keywords\"])\n",
    "# print(info[\"pdf_link\"])\n",
    "# ---------------------end of test code---------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# journals.biologists.com\n",
    "def journals_biologists_com(url):\n",
    "    # initialize\n",
    "    info = {\n",
    "        \"doi\": np.nan,\n",
    "        \"pmid\": np.nan,\n",
    "        \"pmcid\": np.nan,\n",
    "        \"title\": np.nan,\n",
    "        \"abstract\": np.nan,\n",
    "        \"keywords\": np.nan,\n",
    "        \"pdf_link\": np.nan\n",
    "    }\n",
    "\n",
    "    # set up the webdriver\n",
    "    os.environ['WDM_LOG'] = '0'\n",
    "    options = Options()\n",
    "    options.add_argument('--headless')\n",
    "    driver = webdriver.Firefox(options=options)\n",
    "\n",
    "    # load the webpage\n",
    "    error_label = 0\n",
    "    while(error_label == 0):\n",
    "        try:\n",
    "            driver.get(url)\n",
    "            time.sleep(5)\n",
    "            error_label = 1\n",
    "        except:\n",
    "            print(\"Extracting content from:\" + url + \" failed, retrying... This might take longer than 5 minutes...\")\n",
    "            time.sleep(5*60)\n",
    "            error_label = 0\n",
    "    \n",
    "    # doi\n",
    "    try:\n",
    "        doi = driver.find_element(By.XPATH, \"//a[@class='epub-doi']\").text.split(\"doi.org/\")[1]\n",
    "        doi = doi.strip()\n",
    "    except:\n",
    "        doi = np.nan\n",
    "    if doi == doi:\n",
    "        doi = doi.lower()\n",
    "\n",
    "    # pmid, pmcid\n",
    "    pmid = np.nan\n",
    "    pmcid = np.nan\n",
    "\n",
    "    # title\n",
    "    try:\n",
    "        title = driver.find_element(By.XPATH, \"//h1[@class='citation__title']\").text\n",
    "        title = title.strip()\n",
    "    except:\n",
    "        try:\n",
    "            title = driver.find_element(By.XPATH, \"//h2[@class='citation__title']\").text\n",
    "            title = title.strip()\n",
    "        except:\n",
    "            title = np.nan\n",
    "    \n",
    "    # abstract\n",
    "    try:\n",
    "        abstract = \"\"\n",
    "        try:\n",
    "            elems = driver.find_element(By.XPATH, \"//h3[text()='Abstract' or text()='ABSTRACT' or text()='Summary' or text()='SUMMARY']\").find_element(By.XPATH, \"following-sibling::div\").find_elements(By.XPATH, 'p')\n",
    "        except:\n",
    "            elems = driver.find_element(By.XPATH, \"//h2[text()='Abstract' or text()='ABSTRACT' or text()='Summary' or text()='SUMMARY']\").find_element(By.XPATH, \"following-sibling::div\").find_elements(By.XPATH, 'p')                \n",
    "        for elem in elems:\n",
    "            abstract = abstract + elem.text + \" \"\n",
    "        abstract = abstract.strip()\n",
    "    except:\n",
    "        abstract = np.nan\n",
    "    \n",
    "    # keywords\n",
    "    keywords = np.nan\n",
    "\n",
    "    # pdf_link\n",
    "    try:\n",
    "        pdf_link = driver.find_element(By.XPATH, \"//a[@title='ePDF']\").get_attribute('href')\n",
    "        pdf_link = pdf_link.strip()\n",
    "    except:\n",
    "        pdf_link = np.nan\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "    info = {\n",
    "        \"doi\": doi,\n",
    "        \"pmid\": pmid,\n",
    "        \"pmcid\": pmcid,\n",
    "        \"title\": title,\n",
    "        \"abstract\": abstract,\n",
    "        \"keywords\": keywords,\n",
    "        \"pdf_link\": pdf_link\n",
    "    }\n",
    "\n",
    "    return info\n",
    "# --------------------start of test code--------------------\n",
    "# url = \"https://journals.biologists.com/dmm/article/7/8/1013/197/Introduction-of-the-human-AVPR1A-gene\"\n",
    "# info = journals_biologists_com(url)\n",
    "# print(info[\"doi\"])\n",
    "# print(info[\"pmid\"])\n",
    "# print(info[\"pmcid\"])\n",
    "# print(info[\"title\"])\n",
    "# print(info[\"abstract\"])\n",
    "# print(info[\"keywords\"])\n",
    "# print(info[\"pdf_link\"])\n",
    "# ---------------------end of test code---------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# www.microbiologyresearch.org\n",
    "# wiley.com\n",
    "def wiley_com(url):\n",
    "    # initialize\n",
    "    info = {\n",
    "        \"doi\": np.nan,\n",
    "        \"pmid\": np.nan,\n",
    "        \"pmcid\": np.nan,\n",
    "        \"title\": np.nan,\n",
    "        \"abstract\": np.nan,\n",
    "        \"keywords\": np.nan,\n",
    "        \"pdf_link\": np.nan\n",
    "    }\n",
    "\n",
    "    # set up the webdriver\n",
    "    os.environ['WDM_LOG'] = '0'\n",
    "    options = Options()\n",
    "    options.add_argument('--headless')\n",
    "    driver = webdriver.Firefox(options=options)\n",
    "\n",
    "    # load the webpage\n",
    "    error_label = 0\n",
    "    while(error_label == 0):\n",
    "        try:\n",
    "            driver.get(url)\n",
    "            time.sleep(5)\n",
    "            error_label = 1\n",
    "        except:\n",
    "            print(\"Extracting content from:\" + url + \" failed, retrying... This might take longer than 5 minutes...\")\n",
    "            time.sleep(5*60)\n",
    "            error_label = 0\n",
    "    \n",
    "    # doi\n",
    "    try:\n",
    "        doi = driver.find_element(By.XPATH, \"//a[@class='epub-doi']\").text.split(\"doi.org/\")[1]\n",
    "        doi = doi.strip()\n",
    "    except:\n",
    "        doi = np.nan\n",
    "    if doi == doi:\n",
    "        doi = doi.lower()\n",
    "\n",
    "    # pmid, pmcid\n",
    "    pmid = np.nan\n",
    "    pmcid = np.nan\n",
    "\n",
    "    # title\n",
    "    try:\n",
    "        title = driver.find_element(By.XPATH, \"//h1[@class='citation__title']\").text\n",
    "        title = title.strip()\n",
    "    except:\n",
    "        try:\n",
    "            title = driver.find_element(By.XPATH, \"//h2[@class='citation__title']\").text\n",
    "            title = title.strip()\n",
    "        except:\n",
    "            title = np.nan\n",
    "    \n",
    "    # abstract\n",
    "    try:\n",
    "        abstract = \"\"\n",
    "        try:\n",
    "            elems = driver.find_element(By.XPATH, \"//h3[text()='Abstract' or text()='ABSTRACT' or text()='Summary' or text()='SUMMARY']\").find_element(By.XPATH, \"following-sibling::div\").find_elements(By.XPATH, 'p')\n",
    "        except:\n",
    "            elems = driver.find_element(By.XPATH, \"//h2[text()='Abstract' or text()='ABSTRACT' or text()='Summary' or text()='SUMMARY']\").find_element(By.XPATH, \"following-sibling::div\").find_elements(By.XPATH, 'p')                \n",
    "        for elem in elems:\n",
    "            abstract = abstract + elem.text + \" \"\n",
    "        abstract = abstract.strip()\n",
    "    except:\n",
    "        abstract = np.nan\n",
    "    \n",
    "    # keywords\n",
    "    keywords = np.nan\n",
    "\n",
    "    # pdf_link\n",
    "    try:\n",
    "        pdf_link = driver.find_element(By.XPATH, \"//a[@title='ePDF']\").get_attribute('href')\n",
    "        pdf_link = pdf_link.strip()\n",
    "    except:\n",
    "        pdf_link = np.nan\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "    info = {\n",
    "        \"doi\": doi,\n",
    "        \"pmid\": pmid,\n",
    "        \"pmcid\": pmcid,\n",
    "        \"title\": title,\n",
    "        \"abstract\": abstract,\n",
    "        \"keywords\": keywords,\n",
    "        \"pdf_link\": pdf_link\n",
    "    }\n",
    "\n",
    "    return info\n",
    "# --------------------start of test code--------------------\n",
    "# # url = \"https://onlinelibrary.wiley.com/doi/abs/10.1002/cne.901980111\"\n",
    "# url = \"https://onlinelibrary.wiley.com/doi/10.1002/cne.21155\"\n",
    "# # url = \"https://onlinelibrary.wiley.com/doi/10.1002/(SICI)1096-9861(19981019)400:2%3C271::AID-CNE8%3E3.0.CO;2-6\"\n",
    "# # url = \"https://onlinelibrary.wiley.com/doi/10.1002/cne.902360304\"\n",
    "# # url = \"https://onlinelibrary.wiley.com/doi/10.1002/cne.902820107\"\n",
    "# # url = \"https://onlinelibrary.wiley.com/doi/10.1002/(SICI)1096-9861(19990726)410:2%3C211::AID-CNE4%3E3.0.CO;2-X\"\n",
    "# # url = \"https://onlinelibrary.wiley.com/doi/10.1002/cne.902940314\"\n",
    "# # url = \"https://onlinelibrary.wiley.com/doi/10.1002/cne.901990104\"\n",
    "# # url = \"https://onlinelibrary.wiley.com/doi/10.1002/(SICI)1096-9861(19981019)400:2%3C271::AID-CNE8%3E3.0.CO;2-6\"\n",
    "# # url = \"https://onlinelibrary.wiley.com/doi/10.1002/cne.902360304\"\n",
    "# # url = \"https://onlinelibrary.wiley.com/doi/10.1002/cne.24389\"\n",
    "# # url = \"https://onlinelibrary.wiley.com/doi/10.1002/(SICI)1096-9861(19960805)371:4%3C513::AID-CNE2%3E3.0.CO;2-7\"\n",
    "# # url = \"https://nyaspubs.onlinelibrary.wiley.com/doi/full/10.1196/annals.1300.030\"\n",
    "# # url = \"https://onlinelibrary.wiley.com/doi/10.1002/cne.23436\"\n",
    "# # url = \"https://onlinelibrary.wiley.com/doi/10.1002/9780470513545.ch4\"\n",
    "# info = wiley_com(url)\n",
    "# print(info[\"doi\"])\n",
    "# print(info[\"pmid\"])\n",
    "# print(info[\"pmcid\"])\n",
    "# print(info[\"title\"])\n",
    "# print(info[\"abstract\"])\n",
    "# print(info[\"keywords\"])\n",
    "# print(info[\"pdf_link\"])\n",
    "# ---------------------end of test code---------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# journals.aps.org\n",
    "# wiley.com\n",
    "def wiley_com(url):\n",
    "    # initialize\n",
    "    info = {\n",
    "        \"doi\": np.nan,\n",
    "        \"pmid\": np.nan,\n",
    "        \"pmcid\": np.nan,\n",
    "        \"title\": np.nan,\n",
    "        \"abstract\": np.nan,\n",
    "        \"keywords\": np.nan,\n",
    "        \"pdf_link\": np.nan\n",
    "    }\n",
    "\n",
    "    # set up the webdriver\n",
    "    os.environ['WDM_LOG'] = '0'\n",
    "    options = Options()\n",
    "    options.add_argument('--headless')\n",
    "    driver = webdriver.Firefox(options=options)\n",
    "\n",
    "    # load the webpage\n",
    "    error_label = 0\n",
    "    while(error_label == 0):\n",
    "        try:\n",
    "            driver.get(url)\n",
    "            time.sleep(5)\n",
    "            error_label = 1\n",
    "        except:\n",
    "            print(\"Extracting content from:\" + url + \" failed, retrying... This might take longer than 5 minutes...\")\n",
    "            time.sleep(5*60)\n",
    "            error_label = 0\n",
    "    \n",
    "    # doi\n",
    "    try:\n",
    "        doi = driver.find_element(By.XPATH, \"//a[@class='epub-doi']\").text.split(\"doi.org/\")[1]\n",
    "        doi = doi.strip()\n",
    "    except:\n",
    "        doi = np.nan\n",
    "    if doi == doi:\n",
    "        doi = doi.lower()\n",
    "\n",
    "    # pmid, pmcid\n",
    "    pmid = np.nan\n",
    "    pmcid = np.nan\n",
    "\n",
    "    # title\n",
    "    try:\n",
    "        title = driver.find_element(By.XPATH, \"//h1[@class='citation__title']\").text\n",
    "        title = title.strip()\n",
    "    except:\n",
    "        try:\n",
    "            title = driver.find_element(By.XPATH, \"//h2[@class='citation__title']\").text\n",
    "            title = title.strip()\n",
    "        except:\n",
    "            title = np.nan\n",
    "    \n",
    "    # abstract\n",
    "    try:\n",
    "        abstract = \"\"\n",
    "        try:\n",
    "            elems = driver.find_element(By.XPATH, \"//h3[text()='Abstract' or text()='ABSTRACT' or text()='Summary' or text()='SUMMARY']\").find_element(By.XPATH, \"following-sibling::div\").find_elements(By.XPATH, 'p')\n",
    "        except:\n",
    "            elems = driver.find_element(By.XPATH, \"//h2[text()='Abstract' or text()='ABSTRACT' or text()='Summary' or text()='SUMMARY']\").find_element(By.XPATH, \"following-sibling::div\").find_elements(By.XPATH, 'p')                \n",
    "        for elem in elems:\n",
    "            abstract = abstract + elem.text + \" \"\n",
    "        abstract = abstract.strip()\n",
    "    except:\n",
    "        abstract = np.nan\n",
    "    \n",
    "    # keywords\n",
    "    keywords = np.nan\n",
    "\n",
    "    # pdf_link\n",
    "    try:\n",
    "        pdf_link = driver.find_element(By.XPATH, \"//a[@title='ePDF']\").get_attribute('href')\n",
    "        pdf_link = pdf_link.strip()\n",
    "    except:\n",
    "        pdf_link = np.nan\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "    info = {\n",
    "        \"doi\": doi,\n",
    "        \"pmid\": pmid,\n",
    "        \"pmcid\": pmcid,\n",
    "        \"title\": title,\n",
    "        \"abstract\": abstract,\n",
    "        \"keywords\": keywords,\n",
    "        \"pdf_link\": pdf_link\n",
    "    }\n",
    "\n",
    "    return info\n",
    "# --------------------start of test code--------------------\n",
    "# # url = \"https://onlinelibrary.wiley.com/doi/abs/10.1002/cne.901980111\"\n",
    "# url = \"https://onlinelibrary.wiley.com/doi/10.1002/cne.21155\"\n",
    "# # url = \"https://onlinelibrary.wiley.com/doi/10.1002/(SICI)1096-9861(19981019)400:2%3C271::AID-CNE8%3E3.0.CO;2-6\"\n",
    "# # url = \"https://onlinelibrary.wiley.com/doi/10.1002/cne.902360304\"\n",
    "# # url = \"https://onlinelibrary.wiley.com/doi/10.1002/cne.902820107\"\n",
    "# # url = \"https://onlinelibrary.wiley.com/doi/10.1002/(SICI)1096-9861(19990726)410:2%3C211::AID-CNE4%3E3.0.CO;2-X\"\n",
    "# # url = \"https://onlinelibrary.wiley.com/doi/10.1002/cne.902940314\"\n",
    "# # url = \"https://onlinelibrary.wiley.com/doi/10.1002/cne.901990104\"\n",
    "# # url = \"https://onlinelibrary.wiley.com/doi/10.1002/(SICI)1096-9861(19981019)400:2%3C271::AID-CNE8%3E3.0.CO;2-6\"\n",
    "# # url = \"https://onlinelibrary.wiley.com/doi/10.1002/cne.902360304\"\n",
    "# # url = \"https://onlinelibrary.wiley.com/doi/10.1002/cne.24389\"\n",
    "# # url = \"https://onlinelibrary.wiley.com/doi/10.1002/(SICI)1096-9861(19960805)371:4%3C513::AID-CNE2%3E3.0.CO;2-7\"\n",
    "# # url = \"https://nyaspubs.onlinelibrary.wiley.com/doi/full/10.1196/annals.1300.030\"\n",
    "# # url = \"https://onlinelibrary.wiley.com/doi/10.1002/cne.23436\"\n",
    "# # url = \"https://onlinelibrary.wiley.com/doi/10.1002/9780470513545.ch4\"\n",
    "# info = wiley_com(url)\n",
    "# print(info[\"doi\"])\n",
    "# print(info[\"pmid\"])\n",
    "# print(info[\"pmcid\"])\n",
    "# print(info[\"title\"])\n",
    "# print(info[\"abstract\"])\n",
    "# print(info[\"keywords\"])\n",
    "# print(info[\"pdf_link\"])\n",
    "# ---------------------end of test code---------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# www.imrpress.com\n",
    "# wiley.com\n",
    "def wiley_com(url):\n",
    "    # initialize\n",
    "    info = {\n",
    "        \"doi\": np.nan,\n",
    "        \"pmid\": np.nan,\n",
    "        \"pmcid\": np.nan,\n",
    "        \"title\": np.nan,\n",
    "        \"abstract\": np.nan,\n",
    "        \"keywords\": np.nan,\n",
    "        \"pdf_link\": np.nan\n",
    "    }\n",
    "\n",
    "    # set up the webdriver\n",
    "    os.environ['WDM_LOG'] = '0'\n",
    "    options = Options()\n",
    "    options.add_argument('--headless')\n",
    "    driver = webdriver.Firefox(options=options)\n",
    "\n",
    "    # load the webpage\n",
    "    error_label = 0\n",
    "    while(error_label == 0):\n",
    "        try:\n",
    "            driver.get(url)\n",
    "            time.sleep(5)\n",
    "            error_label = 1\n",
    "        except:\n",
    "            print(\"Extracting content from:\" + url + \" failed, retrying... This might take longer than 5 minutes...\")\n",
    "            time.sleep(5*60)\n",
    "            error_label = 0\n",
    "    \n",
    "    # doi\n",
    "    try:\n",
    "        doi = driver.find_element(By.XPATH, \"//a[@class='epub-doi']\").text.split(\"doi.org/\")[1]\n",
    "        doi = doi.strip()\n",
    "    except:\n",
    "        doi = np.nan\n",
    "    if doi == doi:\n",
    "        doi = doi.lower()\n",
    "\n",
    "    # pmid, pmcid\n",
    "    pmid = np.nan\n",
    "    pmcid = np.nan\n",
    "\n",
    "    # title\n",
    "    try:\n",
    "        title = driver.find_element(By.XPATH, \"//h1[@class='citation__title']\").text\n",
    "        title = title.strip()\n",
    "    except:\n",
    "        try:\n",
    "            title = driver.find_element(By.XPATH, \"//h2[@class='citation__title']\").text\n",
    "            title = title.strip()\n",
    "        except:\n",
    "            title = np.nan\n",
    "    \n",
    "    # abstract\n",
    "    try:\n",
    "        abstract = \"\"\n",
    "        try:\n",
    "            elems = driver.find_element(By.XPATH, \"//h3[text()='Abstract' or text()='ABSTRACT' or text()='Summary' or text()='SUMMARY']\").find_element(By.XPATH, \"following-sibling::div\").find_elements(By.XPATH, 'p')\n",
    "        except:\n",
    "            elems = driver.find_element(By.XPATH, \"//h2[text()='Abstract' or text()='ABSTRACT' or text()='Summary' or text()='SUMMARY']\").find_element(By.XPATH, \"following-sibling::div\").find_elements(By.XPATH, 'p')                \n",
    "        for elem in elems:\n",
    "            abstract = abstract + elem.text + \" \"\n",
    "        abstract = abstract.strip()\n",
    "    except:\n",
    "        abstract = np.nan\n",
    "    \n",
    "    # keywords\n",
    "    keywords = np.nan\n",
    "\n",
    "    # pdf_link\n",
    "    try:\n",
    "        pdf_link = driver.find_element(By.XPATH, \"//a[@title='ePDF']\").get_attribute('href')\n",
    "        pdf_link = pdf_link.strip()\n",
    "    except:\n",
    "        pdf_link = np.nan\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "    info = {\n",
    "        \"doi\": doi,\n",
    "        \"pmid\": pmid,\n",
    "        \"pmcid\": pmcid,\n",
    "        \"title\": title,\n",
    "        \"abstract\": abstract,\n",
    "        \"keywords\": keywords,\n",
    "        \"pdf_link\": pdf_link\n",
    "    }\n",
    "\n",
    "    return info\n",
    "# --------------------start of test code--------------------\n",
    "# # url = \"https://onlinelibrary.wiley.com/doi/abs/10.1002/cne.901980111\"\n",
    "# url = \"https://onlinelibrary.wiley.com/doi/10.1002/cne.21155\"\n",
    "# # url = \"https://onlinelibrary.wiley.com/doi/10.1002/(SICI)1096-9861(19981019)400:2%3C271::AID-CNE8%3E3.0.CO;2-6\"\n",
    "# # url = \"https://onlinelibrary.wiley.com/doi/10.1002/cne.902360304\"\n",
    "# # url = \"https://onlinelibrary.wiley.com/doi/10.1002/cne.902820107\"\n",
    "# # url = \"https://onlinelibrary.wiley.com/doi/10.1002/(SICI)1096-9861(19990726)410:2%3C211::AID-CNE4%3E3.0.CO;2-X\"\n",
    "# # url = \"https://onlinelibrary.wiley.com/doi/10.1002/cne.902940314\"\n",
    "# # url = \"https://onlinelibrary.wiley.com/doi/10.1002/cne.901990104\"\n",
    "# # url = \"https://onlinelibrary.wiley.com/doi/10.1002/(SICI)1096-9861(19981019)400:2%3C271::AID-CNE8%3E3.0.CO;2-6\"\n",
    "# # url = \"https://onlinelibrary.wiley.com/doi/10.1002/cne.902360304\"\n",
    "# # url = \"https://onlinelibrary.wiley.com/doi/10.1002/cne.24389\"\n",
    "# # url = \"https://onlinelibrary.wiley.com/doi/10.1002/(SICI)1096-9861(19960805)371:4%3C513::AID-CNE2%3E3.0.CO;2-7\"\n",
    "# # url = \"https://nyaspubs.onlinelibrary.wiley.com/doi/full/10.1196/annals.1300.030\"\n",
    "# # url = \"https://onlinelibrary.wiley.com/doi/10.1002/cne.23436\"\n",
    "# # url = \"https://onlinelibrary.wiley.com/doi/10.1002/9780470513545.ch4\"\n",
    "# info = wiley_com(url)\n",
    "# print(info[\"doi\"])\n",
    "# print(info[\"pmid\"])\n",
    "# print(info[\"pmcid\"])\n",
    "# print(info[\"title\"])\n",
    "# print(info[\"abstract\"])\n",
    "# print(info[\"keywords\"])\n",
    "# print(info[\"pdf_link\"])\n",
    "# ---------------------end of test code---------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# www.researchsquare.com\n",
    "# wiley.com\n",
    "def wiley_com(url):\n",
    "    # initialize\n",
    "    info = {\n",
    "        \"doi\": np.nan,\n",
    "        \"pmid\": np.nan,\n",
    "        \"pmcid\": np.nan,\n",
    "        \"title\": np.nan,\n",
    "        \"abstract\": np.nan,\n",
    "        \"keywords\": np.nan,\n",
    "        \"pdf_link\": np.nan\n",
    "    }\n",
    "\n",
    "    # set up the webdriver\n",
    "    os.environ['WDM_LOG'] = '0'\n",
    "    options = Options()\n",
    "    options.add_argument('--headless')\n",
    "    driver = webdriver.Firefox(options=options)\n",
    "\n",
    "    # load the webpage\n",
    "    error_label = 0\n",
    "    while(error_label == 0):\n",
    "        try:\n",
    "            driver.get(url)\n",
    "            time.sleep(5)\n",
    "            error_label = 1\n",
    "        except:\n",
    "            print(\"Extracting content from:\" + url + \" failed, retrying... This might take longer than 5 minutes...\")\n",
    "            time.sleep(5*60)\n",
    "            error_label = 0\n",
    "    \n",
    "    # doi\n",
    "    try:\n",
    "        doi = driver.find_element(By.XPATH, \"//a[@class='epub-doi']\").text.split(\"doi.org/\")[1]\n",
    "        doi = doi.strip()\n",
    "    except:\n",
    "        doi = np.nan\n",
    "    if doi == doi:\n",
    "        doi = doi.lower()\n",
    "\n",
    "    # pmid, pmcid\n",
    "    pmid = np.nan\n",
    "    pmcid = np.nan\n",
    "\n",
    "    # title\n",
    "    try:\n",
    "        title = driver.find_element(By.XPATH, \"//h1[@class='citation__title']\").text\n",
    "        title = title.strip()\n",
    "    except:\n",
    "        try:\n",
    "            title = driver.find_element(By.XPATH, \"//h2[@class='citation__title']\").text\n",
    "            title = title.strip()\n",
    "        except:\n",
    "            title = np.nan\n",
    "    \n",
    "    # abstract\n",
    "    try:\n",
    "        abstract = \"\"\n",
    "        try:\n",
    "            elems = driver.find_element(By.XPATH, \"//h3[text()='Abstract' or text()='ABSTRACT' or text()='Summary' or text()='SUMMARY']\").find_element(By.XPATH, \"following-sibling::div\").find_elements(By.XPATH, 'p')\n",
    "        except:\n",
    "            elems = driver.find_element(By.XPATH, \"//h2[text()='Abstract' or text()='ABSTRACT' or text()='Summary' or text()='SUMMARY']\").find_element(By.XPATH, \"following-sibling::div\").find_elements(By.XPATH, 'p')                \n",
    "        for elem in elems:\n",
    "            abstract = abstract + elem.text + \" \"\n",
    "        abstract = abstract.strip()\n",
    "    except:\n",
    "        abstract = np.nan\n",
    "    \n",
    "    # keywords\n",
    "    keywords = np.nan\n",
    "\n",
    "    # pdf_link\n",
    "    try:\n",
    "        pdf_link = driver.find_element(By.XPATH, \"//a[@title='ePDF']\").get_attribute('href')\n",
    "        pdf_link = pdf_link.strip()\n",
    "    except:\n",
    "        pdf_link = np.nan\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "    info = {\n",
    "        \"doi\": doi,\n",
    "        \"pmid\": pmid,\n",
    "        \"pmcid\": pmcid,\n",
    "        \"title\": title,\n",
    "        \"abstract\": abstract,\n",
    "        \"keywords\": keywords,\n",
    "        \"pdf_link\": pdf_link\n",
    "    }\n",
    "\n",
    "    return info\n",
    "# --------------------start of test code--------------------\n",
    "# # url = \"https://onlinelibrary.wiley.com/doi/abs/10.1002/cne.901980111\"\n",
    "# url = \"https://onlinelibrary.wiley.com/doi/10.1002/cne.21155\"\n",
    "# # url = \"https://onlinelibrary.wiley.com/doi/10.1002/(SICI)1096-9861(19981019)400:2%3C271::AID-CNE8%3E3.0.CO;2-6\"\n",
    "# # url = \"https://onlinelibrary.wiley.com/doi/10.1002/cne.902360304\"\n",
    "# # url = \"https://onlinelibrary.wiley.com/doi/10.1002/cne.902820107\"\n",
    "# # url = \"https://onlinelibrary.wiley.com/doi/10.1002/(SICI)1096-9861(19990726)410:2%3C211::AID-CNE4%3E3.0.CO;2-X\"\n",
    "# # url = \"https://onlinelibrary.wiley.com/doi/10.1002/cne.902940314\"\n",
    "# # url = \"https://onlinelibrary.wiley.com/doi/10.1002/cne.901990104\"\n",
    "# # url = \"https://onlinelibrary.wiley.com/doi/10.1002/(SICI)1096-9861(19981019)400:2%3C271::AID-CNE8%3E3.0.CO;2-6\"\n",
    "# # url = \"https://onlinelibrary.wiley.com/doi/10.1002/cne.902360304\"\n",
    "# # url = \"https://onlinelibrary.wiley.com/doi/10.1002/cne.24389\"\n",
    "# # url = \"https://onlinelibrary.wiley.com/doi/10.1002/(SICI)1096-9861(19960805)371:4%3C513::AID-CNE2%3E3.0.CO;2-7\"\n",
    "# # url = \"https://nyaspubs.onlinelibrary.wiley.com/doi/full/10.1196/annals.1300.030\"\n",
    "# # url = \"https://onlinelibrary.wiley.com/doi/10.1002/cne.23436\"\n",
    "# # url = \"https://onlinelibrary.wiley.com/doi/10.1002/9780470513545.ch4\"\n",
    "# info = wiley_com(url)\n",
    "# print(info[\"doi\"])\n",
    "# print(info[\"pmid\"])\n",
    "# print(info[\"pmcid\"])\n",
    "# print(info[\"title\"])\n",
    "# print(info[\"abstract\"])\n",
    "# print(info[\"keywords\"])\n",
    "# print(info[\"pdf_link\"])\n",
    "# ---------------------end of test code---------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ieeexplore.ieee.org\n",
    "def func_ieee_org(url):\n",
    "    os.environ['WDM_LOG'] = '0'\n",
    "    options = Options()\n",
    "    options.add_argument('--headless')\n",
    "    \n",
    "    # load the webpage\n",
    "    error_label = 0\n",
    "    while(error_label == 0):\n",
    "        try:\n",
    "            driver = webdriver.Firefox(options=options)\n",
    "            driver.get(url)\n",
    "            time.sleep(5)\n",
    "            error_label = 1\n",
    "        except:\n",
    "            print(\"Extracting content from:\" + url + \" failed, retrying... This might take longer than 5 minutes...\")\n",
    "            time.sleep(5*60)\n",
    "            error_label = 0\n",
    "    \n",
    "    try:\n",
    "        doi = driver.find_element(By.XPATH, \"//div[contains(@class, 'u-pb-1 stats-document-abstract-doi')]\").find_element(By.TAG_NAME, \"a\").text\n",
    "    except:\n",
    "        doi = np.nan\n",
    "    pmid = np.nan\n",
    "    pmcid = np.nan\n",
    "    title = np.nan\n",
    "    abstract = np.nan\n",
    "    keywords = np.nan\n",
    "    pdf_link = np.nan\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "    info = {\n",
    "        \"doi\": doi,\n",
    "        \"pmid\": pmid,\n",
    "        \"pmcid\": pmcid,\n",
    "        \"title\": title,\n",
    "        \"abstract\": abstract,\n",
    "        \"keywords\": keywords,\n",
    "        \"pdf_link\": pdf_link\n",
    "    }\n",
    "    driver.quit\n",
    "\n",
    "    return info\n",
    "# --------------------start of test code--------------------\n",
    "# url = \"https://ieeexplore.ieee.org/abstract/document/5333751\"\n",
    "# info = func_ieee_org(url)\n",
    "# print(info[\"doi\"])\n",
    "# print(info[\"pmid\"])\n",
    "# print(info[\"pmcid\"])\n",
    "# print(info[\"title\"])\n",
    "# print(info[\"abstract\"])\n",
    "# print(info[\"keywords\"])\n",
    "# print(info[\"pdf_link\"])\n",
    "# ---------------------end of test code---------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# papers.ssrn.com\n",
    "# wiley.com\n",
    "def wiley_com(url):\n",
    "    # initialize\n",
    "    info = {\n",
    "        \"doi\": np.nan,\n",
    "        \"pmid\": np.nan,\n",
    "        \"pmcid\": np.nan,\n",
    "        \"title\": np.nan,\n",
    "        \"abstract\": np.nan,\n",
    "        \"keywords\": np.nan,\n",
    "        \"pdf_link\": np.nan\n",
    "    }\n",
    "\n",
    "    # set up the webdriver\n",
    "    os.environ['WDM_LOG'] = '0'\n",
    "    options = Options()\n",
    "    options.add_argument('--headless')\n",
    "    driver = webdriver.Firefox(options=options)\n",
    "\n",
    "    # load the webpage\n",
    "    error_label = 0\n",
    "    while(error_label == 0):\n",
    "        try:\n",
    "            driver.get(url)\n",
    "            time.sleep(5)\n",
    "            error_label = 1\n",
    "        except:\n",
    "            print(\"Extracting content from:\" + url + \" failed, retrying... This might take longer than 5 minutes...\")\n",
    "            time.sleep(5*60)\n",
    "            error_label = 0\n",
    "    \n",
    "    # doi\n",
    "    try:\n",
    "        doi = driver.find_element(By.XPATH, \"//a[@class='epub-doi']\").text.split(\"doi.org/\")[1]\n",
    "        doi = doi.strip()\n",
    "    except:\n",
    "        doi = np.nan\n",
    "    if doi == doi:\n",
    "        doi = doi.lower()\n",
    "\n",
    "    # pmid, pmcid\n",
    "    pmid = np.nan\n",
    "    pmcid = np.nan\n",
    "\n",
    "    # title\n",
    "    try:\n",
    "        title = driver.find_element(By.XPATH, \"//h1[@class='citation__title']\").text\n",
    "        title = title.strip()\n",
    "    except:\n",
    "        try:\n",
    "            title = driver.find_element(By.XPATH, \"//h2[@class='citation__title']\").text\n",
    "            title = title.strip()\n",
    "        except:\n",
    "            title = np.nan\n",
    "    \n",
    "    # abstract\n",
    "    try:\n",
    "        abstract = \"\"\n",
    "        try:\n",
    "            elems = driver.find_element(By.XPATH, \"//h3[text()='Abstract' or text()='ABSTRACT' or text()='Summary' or text()='SUMMARY']\").find_element(By.XPATH, \"following-sibling::div\").find_elements(By.XPATH, 'p')\n",
    "        except:\n",
    "            elems = driver.find_element(By.XPATH, \"//h2[text()='Abstract' or text()='ABSTRACT' or text()='Summary' or text()='SUMMARY']\").find_element(By.XPATH, \"following-sibling::div\").find_elements(By.XPATH, 'p')                \n",
    "        for elem in elems:\n",
    "            abstract = abstract + elem.text + \" \"\n",
    "        abstract = abstract.strip()\n",
    "    except:\n",
    "        abstract = np.nan\n",
    "    \n",
    "    # keywords\n",
    "    keywords = np.nan\n",
    "\n",
    "    # pdf_link\n",
    "    try:\n",
    "        pdf_link = driver.find_element(By.XPATH, \"//a[@title='ePDF']\").get_attribute('href')\n",
    "        pdf_link = pdf_link.strip()\n",
    "    except:\n",
    "        pdf_link = np.nan\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "    info = {\n",
    "        \"doi\": doi,\n",
    "        \"pmid\": pmid,\n",
    "        \"pmcid\": pmcid,\n",
    "        \"title\": title,\n",
    "        \"abstract\": abstract,\n",
    "        \"keywords\": keywords,\n",
    "        \"pdf_link\": pdf_link\n",
    "    }\n",
    "\n",
    "    return info\n",
    "# --------------------start of test code--------------------\n",
    "# # url = \"https://onlinelibrary.wiley.com/doi/abs/10.1002/cne.901980111\"\n",
    "# url = \"https://onlinelibrary.wiley.com/doi/10.1002/cne.21155\"\n",
    "# # url = \"https://onlinelibrary.wiley.com/doi/10.1002/(SICI)1096-9861(19981019)400:2%3C271::AID-CNE8%3E3.0.CO;2-6\"\n",
    "# # url = \"https://onlinelibrary.wiley.com/doi/10.1002/cne.902360304\"\n",
    "# # url = \"https://onlinelibrary.wiley.com/doi/10.1002/cne.902820107\"\n",
    "# # url = \"https://onlinelibrary.wiley.com/doi/10.1002/(SICI)1096-9861(19990726)410:2%3C211::AID-CNE4%3E3.0.CO;2-X\"\n",
    "# # url = \"https://onlinelibrary.wiley.com/doi/10.1002/cne.902940314\"\n",
    "# # url = \"https://onlinelibrary.wiley.com/doi/10.1002/cne.901990104\"\n",
    "# # url = \"https://onlinelibrary.wiley.com/doi/10.1002/(SICI)1096-9861(19981019)400:2%3C271::AID-CNE8%3E3.0.CO;2-6\"\n",
    "# # url = \"https://onlinelibrary.wiley.com/doi/10.1002/cne.902360304\"\n",
    "# # url = \"https://onlinelibrary.wiley.com/doi/10.1002/cne.24389\"\n",
    "# # url = \"https://onlinelibrary.wiley.com/doi/10.1002/(SICI)1096-9861(19960805)371:4%3C513::AID-CNE2%3E3.0.CO;2-7\"\n",
    "# # url = \"https://nyaspubs.onlinelibrary.wiley.com/doi/full/10.1196/annals.1300.030\"\n",
    "# # url = \"https://onlinelibrary.wiley.com/doi/10.1002/cne.23436\"\n",
    "# # url = \"https://onlinelibrary.wiley.com/doi/10.1002/9780470513545.ch4\"\n",
    "# info = wiley_com(url)\n",
    "# print(info[\"doi\"])\n",
    "# print(info[\"pmid\"])\n",
    "# print(info[\"pmcid\"])\n",
    "# print(info[\"title\"])\n",
    "# print(info[\"abstract\"])\n",
    "# print(info[\"keywords\"])\n",
    "# print(info[\"pdf_link\"])\n",
    "# ---------------------end of test code---------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
