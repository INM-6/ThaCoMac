{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import internal .py modules\n",
    "import file_path_management as fpath\n",
    "import public_library as plib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import csv\n",
    "import pandas as pd\n",
    "import PyPDF2\n",
    "import requests\n",
    "import time\n",
    "import os\n",
    "import random\n",
    "from requests.auth import HTTPProxyAuth\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def request_wegpage(url, proxies):\n",
    "    response = requests.get(url, headers = plib.headers, proxies = proxies)\n",
    "    if response.status_code != 200:\n",
    "        # print(\"Error when requesting:\", url)\n",
    "        # print(response.status_code)\n",
    "        raise Exception(\"Your request was declined, again!\")\n",
    "    soup = BeautifulSoup(response.content, \"lxml\")\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_doi(url):\n",
    "    options = Options()\n",
    "    options.add_argument('--headless')\n",
    "    browser = webdriver.Firefox(options)\n",
    "    browser.get(url)\n",
    "    WebDriverWait(browser, 10).until(EC.element_to_be_clickable((By.XPATH, \"//p[text()='Consent']\"))).click()\n",
    "\n",
    "    # find elements containing \"doi\" or \"DOI\"\n",
    "    elements = browser.find_elements(By.XPATH, \"//*[contains(text(), 'doi')]\")\n",
    "    print(elements)\n",
    "\n",
    "    # print out the text of the elements\n",
    "    # print(element.get)\n",
    "    for element in elements:\n",
    "        print(element.text)\n",
    "        doi = elements.text\n",
    "\n",
    "    # quit the browser\n",
    "    browser.quit()\n",
    "\n",
    "    return doi\n",
    "# --------------------start of test code--------------------\n",
    "# # url = \"https://doi.org/10.1016/0166-4328(84)90039-1\"\n",
    "# # url = \"https://www.science.org/doi/abs/10.1126/science.6867739\"\n",
    "# # url = \"https://link.springer.com/article/10.1007/s004010051037\"\n",
    "# url = \"https://ajp.psychiatryonline.org/doi/abs/10.1176/appi.ajp.161.5.896\"\n",
    "# # final_url, history = plib.get_final_redirected_url(url.strip())\n",
    "# final_url = url.strip()\n",
    "# print(final_url)\n",
    "# doi = get_doi(final_url)\n",
    "# print(doi)\n",
    "# # str(doi).strip().split(\"org/\")[1].strip()\n",
    "# ---------------------end of test code---------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def nyu_edu(url):\n",
    "#     # nyu.edu\n",
    "#     content = browser_get(url)\n",
    "#     time.sleep(10)\n",
    "#     doi, pmid, pmcid, first_author, pdf_url, pdf_source = 'doi', 'pmid', 'pmcid', 'first_author', 'pdf_url', 'pdf_source'\n",
    "#     return doi, pmid, pmcid, first_author, pdf_url, pdf_source\n",
    "\n",
    "# def ucdavis_edu(url):\n",
    "#     # ucdavis.edu\n",
    "#     content = browser_get(url)\n",
    "#     time.sleep(10)\n",
    "#     doi, pmid, pmcid, first_author, pdf_url, pdf_source = 'doi', 'pmid', 'pmcid', 'first_author', 'pdf_url', 'pdf_source'\n",
    "#     return doi, pmid, pmcid, first_author, pdf_url, pdf_source\n",
    "\n",
    "# def psychiatryonline_org(url):\n",
    "#     # psychiatryonline.org\n",
    "#     content = browser_get(url)\n",
    "#     time.sleep(10)\n",
    "#     doi, pmid, pmcid, first_author, pdf_url, pdf_source = 'doi', 'pmid', 'pmcid', 'first_author', 'pdf_url', 'pdf_source'\n",
    "#     return doi, pmid, pmcid, first_author, pdf_url, pdf_source\n",
    "\n",
    "# def oup_com(url):\n",
    "#     # oup.com\n",
    "#     content = browser_get(url)\n",
    "#     time.sleep(10)\n",
    "#     doi, pmid, pmcid, first_author, pdf_url, pdf_source = 'doi', 'pmid', 'pmcid', 'first_author', 'pdf_url', 'pdf_source'\n",
    "#     return doi, pmid, pmcid, first_author, pdf_url, pdf_source\n",
    "\n",
    "# def cell_com(url):\n",
    "#     # cell.com\n",
    "#     content = browser_get(url)\n",
    "#     time.sleep(10)\n",
    "#     doi, pmid, pmcid, first_author, pdf_url, pdf_source = 'doi', 'pmid', 'pmcid', 'first_author', 'pdf_url', 'pdf_source'\n",
    "#     return doi, pmid, pmcid, first_author, pdf_url, pdf_source\n",
    "\n",
    "# def zsp_com_pk(url):\n",
    "#     # zsp.com.pk\n",
    "#     content = browser_get(url)\n",
    "#     time.sleep(10)\n",
    "#     doi, pmid, pmcid, first_author, pdf_url, pdf_source = 'doi', 'pmid', 'pmcid', 'first_author', 'pdf_url', 'pdf_source'\n",
    "#     return doi, pmid, pmcid, first_author, pdf_url, pdf_source\n",
    "\n",
    "# def researchgate_net(url):\n",
    "#     # researchgate.net\n",
    "#     content = browser_get(url)\n",
    "#     time.sleep(10)\n",
    "#     doi, pmid, pmcid, first_author, pdf_url, pdf_source = 'doi', 'pmid', 'pmcid', 'first_author', 'pdf_url', 'pdf_source'\n",
    "#     return doi, pmid, pmcid, first_author, pdf_url, pdf_source\n",
    "\n",
    "# def biorxiv_org(url):\n",
    "#     # biorxiv.org\n",
    "#     content = browser_get(url)\n",
    "#     time.sleep(10)\n",
    "#     doi, pmid, pmcid, first_author, pdf_url, pdf_source = 'doi', 'pmid', 'pmcid', 'first_author', 'pdf_url', 'pdf_source'\n",
    "#     return doi, pmid, pmcid, first_author, pdf_url, pdf_source\n",
    "\n",
    "# def psu_edu(url):\n",
    "#     # psu.edu\n",
    "#     content = browser_get(url)\n",
    "#     time.sleep(10)\n",
    "#     doi, pmid, pmcid, first_author, pdf_url, pdf_source = 'doi', 'pmid', 'pmcid', 'first_author', 'pdf_url', 'pdf_source'\n",
    "#     return doi, pmid, pmcid, first_author, pdf_url, pdf_source\n",
    "\n",
    "# def wustl_edu(url):\n",
    "#     # wustl.edu\n",
    "#     content = browser_get(url)\n",
    "#     time.sleep(10)\n",
    "#     doi, pmid, pmcid, first_author, pdf_url, pdf_source = 'doi', 'pmid', 'pmcid', 'first_author', 'pdf_url', 'pdf_source'\n",
    "#     return doi, pmid, pmcid, first_author, pdf_url, pdf_source\n",
    "\n",
    "# def tandfonline_com(url):\n",
    "#     # tandfonline.com\n",
    "#     content = browser_get(url)\n",
    "#     time.sleep(10)\n",
    "#     doi, pmid, pmcid, first_author, pdf_url, pdf_source = 'doi', 'pmid', 'pmcid', 'first_author', 'pdf_url', 'pdf_source'\n",
    "#     return doi, pmid, pmcid, first_author, pdf_url, pdf_source\n",
    "\n",
    "# def karger_com(url):\n",
    "#     # karger.com\n",
    "#     content = browser_get(url)\n",
    "#     time.sleep(10)\n",
    "#     doi, pmid, pmcid, first_author, pdf_url, pdf_source = 'doi', 'pmid', 'pmcid', 'first_author', 'pdf_url', 'pdf_source'\n",
    "#     return doi, pmid, pmcid, first_author, pdf_url, pdf_source\n",
    "\n",
    "# def sagepub_com(url):\n",
    "#     # sagepub.com\n",
    "#     content = browser_get(url)\n",
    "#     time.sleep(10)\n",
    "#     doi, pmid, pmcid, first_author, pdf_url, pdf_source = 'doi', 'pmid', 'pmcid', 'first_author', 'pdf_url', 'pdf_source'\n",
    "#     return doi, pmid, pmcid, first_author, pdf_url, pdf_source\n",
    "\n",
    "# def plos_org(url):\n",
    "#     # plos.org\n",
    "#     content = browser_get(url)\n",
    "#     time.sleep(10)\n",
    "#     doi, pmid, pmcid, first_author, pdf_url, pdf_source = 'doi', 'pmid', 'pmcid', 'first_author', 'pdf_url', 'pdf_source'\n",
    "#     return doi, pmid, pmcid, first_author, pdf_url, pdf_source\n",
    "\n",
    "# def epfl_ch(url):\n",
    "#     # epfl.ch\n",
    "#     content = browser_get(url)\n",
    "#     time.sleep(10)\n",
    "#     doi, pmid, pmcid, first_author, pdf_url, pdf_source = 'doi', 'pmid', 'pmcid', 'first_author', 'pdf_url', 'pdf_source'\n",
    "#     return doi, pmid, pmcid, first_author, pdf_url, pdf_source\n",
    "\n",
    "# def royalsocietypublishing_org(url):\n",
    "#     # royalsocietypublishing.org\n",
    "#     content = browser_get(url)\n",
    "#     time.sleep(10)\n",
    "#     doi, pmid, pmcid, first_author, pdf_url, pdf_source = 'doi', 'pmid', 'pmcid', 'first_author', 'pdf_url', 'pdf_source'\n",
    "#     return doi, pmid, pmcid, first_author, pdf_url, pdf_source\n",
    "\n",
    "# def rero_ch(url):\n",
    "#     # rero.ch\n",
    "#     content = browser_get(url)\n",
    "#     time.sleep(10)\n",
    "#     doi, pmid, pmcid, first_author, pdf_url, pdf_source = 'doi', 'pmid', 'pmcid', 'first_author', 'pdf_url', 'pdf_source'\n",
    "#     return doi, pmid, pmcid, first_author, pdf_url, pdf_source\n",
    "\n",
    "# def springer_com(url):\n",
    "#     # springer.com\n",
    "#     content = browser_get(url)\n",
    "#     time.sleep(10)\n",
    "#     doi, pmid, pmcid, first_author, pdf_url, pdf_source = 'doi', 'pmid', 'pmcid', 'first_author', 'pdf_url', 'pdf_source'\n",
    "#     return doi, pmid, pmcid, first_author, pdf_url, pdf_source\n",
    "\n",
    "# def science_org(url):\n",
    "#     # science.org\n",
    "#     content = browser_get(url)\n",
    "#     time.sleep(10)\n",
    "#     doi, pmid, pmcid, first_author, pdf_url, pdf_source = 'doi', 'pmid', 'pmcid', 'first_author', 'pdf_url', 'pdf_source'\n",
    "#     return doi, pmid, pmcid, first_author, pdf_url, pdf_source\n",
    "\n",
    "# def annualreviews_org(url):\n",
    "#     # annualreviews.org\n",
    "#     content = browser_get(url)\n",
    "#     time.sleep(10)\n",
    "#     doi, pmid, pmcid, first_author, pdf_url, pdf_source = 'doi', 'pmid', 'pmcid', 'first_author', 'pdf_url', 'pdf_source'\n",
    "#     return doi, pmid, pmcid, first_author, pdf_url, pdf_source\n",
    "\n",
    "# def duke_edu(url):\n",
    "#     # duke.edu\n",
    "#     content = browser_get(url)\n",
    "#     time.sleep(10)\n",
    "#     doi, pmid, pmcid, first_author, pdf_url, pdf_source = 'doi', 'pmid', 'pmcid', 'first_author', 'pdf_url', 'pdf_source'\n",
    "#     return doi, pmid, pmcid, first_author, pdf_url, pdf_source\n",
    "\n",
    "# def umich_edu(url):\n",
    "#     # umich.edu\n",
    "#     content = browser_get(url)\n",
    "#     time.sleep(10)\n",
    "#     doi, pmid, pmcid, first_author, pdf_url, pdf_source = 'doi', 'pmid', 'pmcid', 'first_author', 'pdf_url', 'pdf_source'\n",
    "#     return doi, pmid, pmcid, first_author, pdf_url, pdf_source\n",
    "\n",
    "# def jneurosci_org(url):\n",
    "#     # jneurosci.org\n",
    "#     content = browser_get(url)\n",
    "#     time.sleep(10)\n",
    "#     doi, pmid, pmcid, first_author, pdf_url, pdf_source = 'doi', 'pmid', 'pmcid', 'first_author', 'pdf_url', 'pdf_source'\n",
    "#     return doi, pmid, pmcid, first_author, pdf_url, pdf_source\n",
    "\n",
    "# def wiley_com(url):\n",
    "#     # wiley.com\n",
    "#     content = browser_get(url)\n",
    "#     time.sleep(10)\n",
    "#     doi, pmid, pmcid, first_author, pdf_url, pdf_source = 'doi', 'pmid', 'pmcid', 'first_author', 'pdf_url', 'pdf_source'\n",
    "#     return doi, pmid, pmcid, first_author, pdf_url, pdf_source\n",
    "\n",
    "# def physiology_org(url):\n",
    "#     # physiology.org\n",
    "#     content = browser_get(url)\n",
    "#     time.sleep(10)\n",
    "#     doi, pmid, pmcid, first_author, pdf_url, pdf_source = 'doi', 'pmid', 'pmcid', 'first_author', 'pdf_url', 'pdf_source'\n",
    "#     return doi, pmid, pmcid, first_author, pdf_url, pdf_source\n",
    "\n",
    "# def nih_gov(url):\n",
    "#     # nih.gov\n",
    "#     content = browser_get(url)\n",
    "#     time.sleep(10)\n",
    "#     doi, pmid, pmcid, first_author, pdf_url, pdf_source = 'doi', 'pmid', 'pmcid', 'first_author', 'pdf_url', 'pdf_source'\n",
    "#     return doi, pmid, pmcid, first_author, pdf_url, pdf_source\n",
    "\n",
    "# def pnas_org(url):\n",
    "#     # pnas.org\n",
    "#     content = browser_get(url)\n",
    "#     time.sleep(10)\n",
    "#     doi, pmid, pmcid, first_author, pdf_url, pdf_source = 'doi', 'pmid', 'pmcid', 'first_author', 'pdf_url', 'pdf_source'\n",
    "#     return doi, pmid, pmcid, first_author, pdf_url, pdf_source\n",
    "\n",
    "# def uzh_ch(url):\n",
    "#     # uzh.ch\n",
    "#     content = browser_get(url)\n",
    "#     time.sleep(10)\n",
    "#     doi, pmid, pmcid, first_author, pdf_url, pdf_source = 'doi', 'pmid', 'pmcid', 'first_author', 'pdf_url', 'pdf_source'\n",
    "#     return doi, pmid, pmcid, first_author, pdf_url, pdf_source\n",
    "\n",
    "# def nature_com(url):\n",
    "#     # nature.com\n",
    "#     content = browser_get(url)\n",
    "#     time.sleep(10)\n",
    "#     doi, pmid, pmcid, first_author, pdf_url, pdf_source = 'doi', 'pmid', 'pmcid', 'first_author', 'pdf_url', 'pdf_source'\n",
    "#     return doi, pmid, pmcid, first_author, pdf_url, pdf_source\n",
    "\n",
    "# def sciencedirect_com(url):\n",
    "#     # sciencedirect.com\n",
    "#     content = browser_get(url)\n",
    "#     time.sleep(10)\n",
    "#     doi, pmid, pmcid, first_author, pdf_url, pdf_source = 'doi', 'pmid', 'pmcid', 'first_author', 'pdf_url', 'pdf_source'\n",
    "#     return doi, pmid, pmcid, first_author, pdf_url, pdf_source\n",
    "\n",
    "# def udc_es(url):\n",
    "#     # udc.es\n",
    "#     content = browser_get(url)\n",
    "#     time.sleep(10)\n",
    "#     doi, pmid, pmcid, first_author, pdf_url, pdf_source = 'doi', 'pmid', 'pmcid', 'first_author', 'pdf_url', 'pdf_source'\n",
    "#     return doi, pmid, pmcid, first_author, pdf_url, pdf_source\n",
    "\n",
    "# def jordanbpeterson_com(url):\n",
    "#     # jordanbpeterson.com\n",
    "#     content = browser_get(url)\n",
    "#     time.sleep(10)\n",
    "#     doi, pmid, pmcid, first_author, pdf_url, pdf_source = 'doi', 'pmid', 'pmcid', 'first_author', 'pdf_url', 'pdf_source'\n",
    "\n",
    "# def bu_edu(url):\n",
    "#     # bu.edu\n",
    "#     content = browser_get(url)\n",
    "#     time.sleep(10)\n",
    "#     doi, pmid, pmcid, first_author, pdf_url, pdf_source = 'doi', 'pmid', 'pmcid', 'first_author', 'pdf_url', 'pdf_source'\n",
    "#     return doi, pmid, pmcid, first_author, pdf_url, pdf_source\n",
    "\n",
    "# def not_found(url):\n",
    "#     # not found\n",
    "#     content = browser_get(url)\n",
    "#     time.sleep(10)\n",
    "#     doi, pmid, pmcid, first_author, pdf_url, pdf_source = 'doi', 'pmid', 'pmcid', 'first_author', 'pdf_url', 'pdf_source'\n",
    "#     return doi, pmid, pmcid, first_author, pdf_url, pdf_source\n",
    "\n",
    "# def frontiersin_org(url):\n",
    "#     # frontiersin.org\n",
    "#     content = browser_get(url)\n",
    "#     time.sleep(10)\n",
    "#     doi, pmid, pmcid, first_author, pdf_url, pdf_source = 'doi', 'pmid', 'pmcid', 'first_author', 'pdf_url', 'pdf_source'\n",
    "#     return doi, pmid, pmcid, first_author, pdf_url, pdf_source\n",
    "\n",
    "# def ahuman_org(url):\n",
    "#     # ahuman.org\n",
    "#     content = browser_get(url)\n",
    "#     time.sleep(10)\n",
    "#     doi, pmid, pmcid, first_author, pdf_url, pdf_source = 'doi', 'pmid', 'pmcid', 'first_author', 'pdf_url', 'pdf_source'\n",
    "#     return doi, pmid, pmcid, first_author, pdf_url, pdf_source\n",
    "\n",
    "# def academia_edu(url):\n",
    "#     # academia.edu\n",
    "#     content = browser_get(url)\n",
    "#     time.sleep(10)\n",
    "#     doi, pmid, pmcid, first_author, pdf_url, pdf_source = 'doi', 'pmid', 'pmcid', 'first_author', 'pdf_url', 'pdf_source'\n",
    "#     return doi, pmid, pmcid, first_author, pdf_url, pdf_source\n",
    "\n",
    "# def ieee_org(url):\n",
    "#     # ieee.org\n",
    "#     content = browser_get(url)\n",
    "#     time.sleep(10)\n",
    "#     doi, pmid, pmcid, first_author, pdf_url, pdf_source = 'doi', 'pmid', 'pmcid', 'first_author', 'pdf_url', 'pdf_source'\n",
    "#     return doi, pmid, pmcid, first_author, pdf_url, pdf_source\n",
    "\n",
    "# def RWTH_Link(url):\n",
    "#     # RWTH-Link\n",
    "#     content = browser_get(url)\n",
    "#     time.sleep(10)\n",
    "#     doi, pmid, pmcid, first_author, pdf_url, pdf_source = 'doi', 'pmid', 'pmcid', 'first_author', 'pdf_url', 'pdf_source'\n",
    "#     return doi, pmid, pmcid, first_author, pdf_url, pdf_source\n",
    "\n",
    "# def mdpi_com(url):\n",
    "#     # mdpi.com\n",
    "#     content = browser_get(url)\n",
    "#     time.sleep(10)\n",
    "#     doi, pmid, pmcid, first_author, pdf_url, pdf_source = 'doi', 'pmid', 'pmcid', 'first_author', 'pdf_url', 'pdf_source'\n",
    "#     return doi, pmid, pmcid, first_author, pdf_url, pdf_source\n",
    "\n",
    "# def harvard_edu(url):\n",
    "#     # harvard.edu\n",
    "#     content = browser_get(url)\n",
    "#     time.sleep(10)\n",
    "#     doi, pmid, pmcid, first_author, pdf_url, pdf_source = 'doi', 'pmid', 'pmcid', 'first_author', 'pdf_url', 'pdf_source'\n",
    "#     return doi, pmid, pmcid, first_author, pdf_url, pdf_source\n",
    "\n",
    "# def stanford_edu(url):\n",
    "#     # stanford.edu\n",
    "#     content = browser_get(url)\n",
    "#     time.sleep(10)\n",
    "#     doi, pmid, pmcid, first_author, pdf_url, pdf_source = 'doi', 'pmid', 'pmcid', 'first_author', 'pdf_url', 'pdf_source'\n",
    "#     return doi, pmid, pmcid, first_author, pdf_url, pdf_source\n",
    "\n",
    "# def cambridge_org(url):\n",
    "#     # cambridge.org\n",
    "#     content = browser_get(url)\n",
    "#     time.sleep(10)\n",
    "#     doi, pmid, pmcid, first_author, pdf_url, pdf_source = 'doi', 'pmid', 'pmcid', 'first_author', 'pdf_url', 'pdf_source'\n",
    "#     return doi, pmid, pmcid, first_author, pdf_url, pdf_source\n",
    "\n",
    "# def oxford_ac_uk(url):\n",
    "#     # oxford.ac.uk\n",
    "#     content = browser_get(url)\n",
    "#     time.sleep(10)\n",
    "#     doi, pmid, pmcid, first_author, pdf_url, pdf_source = 'doi', 'pmid', 'pmcid', 'first_author', 'pdf_url', 'pdf_source'\n",
    "#     return doi, pmid, pmcid, first_author, pdf_url, pdf_source\n",
    "\n",
    "# def mit_edu(url):\n",
    "#     # mit.edu\n",
    "#     content = browser_get(url)\n",
    "#     time.sleep(10)\n",
    "#     doi, pmid, pmcid, first_author, pdf_url, pdf_source = 'doi', 'pmid', 'pmcid', 'first_author', 'pdf_url', 'pdf_source'\n",
    "#     return doi, pmid, pmcid, first_author, pdf_url, pdf_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_google_shcolar(source_path, output_path, columns):\n",
    "    print(\"Starting merging search results from Google Scholar...\")\n",
    "    df = pd.read_csv(source_path, header=None, sep=',')\n",
    "    df.columns = [\"title\", \"url\", \"full_text_url\", \"full_text_type\", \"full_text_source\"]\n",
    "    for ind in df.index:\n",
    "        # columns = [\"DOI\", \"PMID\", \"PMCID\", \"Title\", \"full_text_url\", \"full_text_source\", \"pdf_url\", \"pdf_source\"]\n",
    "        # get title\n",
    "        title = str(df[\"title\"][ind]).strip()\n",
    "        # get pmid\n",
    "        pmid = np.nan\n",
    "        # get pmcid\n",
    "        pmcid = np.nan\n",
    "\n",
    "        # get full_text_url\n",
    "        # get full_text_source\n",
    "        if str(df[\"full_text_type\"][ind]) == \"[HTML]\":\n",
    "            full_text_url, = plib.get_final_redirected_url(str(df[\"full_text_url\"][ind]).strip()).strip()\n",
    "            full_text_source = full_text_url.split(\"://\")[1].strip().split(\"/\")[0].strip()\n",
    "        elif str(df[\"full_text_type\"][ind]) == \"not found\" | \"[PDF]\" | \"UB\":\n",
    "            if str(df[\"url\"][ind]) != \"not found\":\n",
    "                full_text_url, = plib.get_final_redirected_url(str(df[\"url\"][ind]).strip()).strip()\n",
    "                full_text_source = full_text_url.split(\"://\")[1].strip().split(\"/\")[0].strip()\n",
    "            else:\n",
    "                full_text_url = np.nan\n",
    "                full_text_source = np.nan\n",
    "        else:\n",
    "            raise Exception(\"Found a full_text_type not expected!\")\n",
    "        # get pdf_url\n",
    "        # get pdf_source\n",
    "        if str(df[\"full_text_type\"][ind]) == \"[PDF]\":\n",
    "            pdf_url = str(df[\"full_text_url\"][ind])\n",
    "            pdf_source = pdf_url.split(\"://\")[1].strip().split(\"/\")[0].strip()\n",
    "        else:\n",
    "            pdf_url = np.nan\n",
    "            pdf_source = np.nan\n",
    "\n",
    "        # get DOI\n",
    "        proxies = plib.get_proxies()\n",
    "        url = full_text_url\n",
    "        doi = get_doi(url)\n",
    "        \n",
    "        # columns = [\"DOI\", \"PMID\", \"PMCID\", \"Title\", \"full_text_url\", \"full_text_source\", \"pdf_url\", \"pdf_source\"]\n",
    "        row = {\n",
    "            \"DOI\": [doi],\n",
    "            \"PMID\": [pmid],\n",
    "            \"PMCID\": [pmcid],\n",
    "            \"Title\": [str(df[\"Title\"][ind])],\n",
    "            \"full_text_url\": [full_text_url],\n",
    "            \"full_text_source\": [full_text_source],\n",
    "            \"pdf_url\": [pdf_url],\n",
    "            \"pdf_source\": [pdf_source]\n",
    "        }\n",
    "        # print(row)\n",
    "        if not plib.add_row_to_csv(output_path, row, columns):\n",
    "            print(\"Error detected when adding a row to csv!\")\n",
    "# --------------------start of test code--------------------\n",
    "# source_path = fpath.poten_litera_gs\n",
    "# output_path = fpath.poten_litera_gs_processed\n",
    "# plib.clear_file(output_path)\n",
    "\n",
    "# --------------------start of test code--------------------\n",
    "# df = pd.read_csv(source_path, header=None, sep=',')\n",
    "# df.columns = [\"title\", \"url\", \"full_text_url\", \"full_text_type\", \"full_text_source\"]\n",
    "# print(df.head(3))\n",
    "# ---------------------end of test code---------------------\n",
    "\n",
    "# --------------------start of test code--------------------\n",
    "# full_text_type = set(df['full_text_type'].tolist())\n",
    "# print(\"All full_text_type include: \",full_text_type)\n",
    "# full_text_source = set(df['full_text_source'].tolist())\n",
    "# print(\"All full_text_source include: \", full_text_source)\n",
    "# ---------------------end of test code---------------------\n",
    "\n",
    "# --------------------start of test code--------------------\n",
    "# # [\"title\", \"url\", \"full_text_url\", \"full_text_type\", \"full_text_source\"]\n",
    "# print(df[\"title\"].str.contains('not found').sum())\n",
    "# print(df[\"url\"].str.contains('not found').sum())\n",
    "# print(df[\"full_text_url\"].str.contains('not found').sum())\n",
    "# print(df[\"full_text_type\"].str.contains('not found').sum())\n",
    "# print(df[\"full_text_source\"].str.contains('not found').sum())\n",
    "# # \n",
    "# # title, url don't contain np.nan\n",
    "# # full_text_url, full_text_type, full_text_source contain np.nan\n",
    "# # we need to fill in what are missing\n",
    "# ---------------------end of test code---------------------\n",
    "\n",
    "# --------------------start of test code--------------------\n",
    "# merge_google_shcolar(source_path, output_path, columns)\n",
    "# ---------------------end of test code---------------------\n",
    "\n",
    "# --------------------start of test code--------------------\n",
    "# df = pd.read_csv(output_path, header=None, sep=',')\n",
    "# print(df.head(3))\n",
    "# ---------------------end of test code---------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import metapub\n",
    "pmid = \"35851953\"\n",
    "# doi = \"10.1113/JP282626\"\n",
    "doi = \"10.1111/ejn.13910\"\n",
    "pmid, pmcid = plib.doi2pmid(str(doi).strip())\n",
    "print(pmid)\n",
    "print(pmcid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from selenium import webdriver\n",
    "# from webdriver_manager.firefox import GeckoDriverManager\n",
    "# from selenium.webdriver.support.ui import WebDriverWait\n",
    "# from selenium.webdriver.support import expected_conditions as EC\n",
    "# from selenium.webdriver.common.by import By\n",
    "# from selenium.webdriver.firefox.service import Service\n",
    "# from selenium.common.exceptions import TimeoutException, WebDriverException, NoSuchElementException\n",
    "\n",
    "# options = Options()\n",
    "# options.add_argument('--headless')\n",
    "# driver = webdriver.Firefox(service=Service(GeckoDriverManager().install()))\n",
    "# # driver = webdriver.Firefox(GeckoDriverManager().install())\n",
    "# driver.get(\"https://www.pmid2cite.com/doi-to-pmid-converter\")\n",
    "# WebDriverWait(driver, 15).until(EC.element_to_be_clickable((By.XPATH, \"//p[text()='Consent']\"))).click()\n",
    "# doi = \"10.1113/JP282626\"\n",
    "# try:\n",
    "#     # print(str(doi))\n",
    "#     WebDriverWait(driver, 15).until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"#formInput\"))).send_keys(str(doi).strip())\n",
    "# except TimeoutException:\n",
    "#     print(\"Waiting for clicking consent timeout\")\n",
    "# try:\n",
    "#     # driver.find_element(By.XPATH, \"/html/body/div[5]/div[2]/form/button\").click()\n",
    "#     # EC.presence_of_element_located(By.XPATH, \"/html/body/div[5]/div[2]/form/button\")\n",
    "#     WebDriverWait(driver, 15).until(EC.element_to_be_clickable((By.XPATH, \"/html/body/div[1]/div[2]/form/button\"))).click()\n",
    "# except TimeoutException:\n",
    "#     print(\"Waiting for clicking button timeout\")\n",
    "# try:\n",
    "#     WebDriverWait(driver, 30).until(EC.visibility_of_all_elements_located((By.XPATH, \"/html/body/div[7]/div[3]/p[1]/span[2]/a\")))\n",
    "# except TimeoutException:\n",
    "#     print(\"Waiting for getting PMID timeout\")\n",
    "#     my_elem = driver.find_element(By.XPATH, \"button[aria-label='Leaving from']\").text\n",
    "#     res = my_elem.text\n",
    "#     pmid = res\n",
    "\n",
    "#     pmid = np.nan\n",
    "# print(pmid)\n",
    "\n",
    "# driver.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
