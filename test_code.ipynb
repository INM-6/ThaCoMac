{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import csv\n",
    "import pandas as pd\n",
    "import PyPDF2\n",
    "import requests\n",
    "import time\n",
    "import os\n",
    "import random\n",
    "from requests.auth import HTTPProxyAuth\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.firefox import GeckoDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.firefox import GeckoDriverManager\n",
    "from selenium.webdriver.firefox.service import Service\n",
    "from selenium.common.exceptions import TimeoutException, WebDriverException, NoSuchElementException\n",
    "import os\n",
    "import re\n",
    "from lxml import etree\n",
    "from nltk import ngrams\n",
    "import json\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-03 16:04:01 GM01X680 metapub.config[49163] WARNING NCBI_API_KEY was not set.\n"
     ]
    }
   ],
   "source": [
    "# import internal modules\n",
    "import file_path_management as fpath\n",
    "import public_library as plib\n",
    "import extract_info\n",
    "import parameters as params\n",
    "import download_and_process_pdf as dpp\n",
    "import dataframe_columns as df_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # scan the rows in the test 1000 csv file and print the full_text_url and pdf_url of the papers that have no pdf_url\n",
    "# input_path = fpath.poten_litera_testing_set_1000_text_extract_and_count\n",
    "# df = pd.read_csv(input_path, header=0, sep=',')\n",
    "# columns = [\n",
    "#     \"INDEX\", \"DOI\", \"PMID\", \"PMCID\", \"FULL_TEXT_URL\", \"PDF_URL\", \n",
    "#     \"TITLE\", \"TEXT_TAK\", \"TEXT_500\"\n",
    "# ]\n",
    "# columns = columns + df_col.text_columns_to_add # add keyword group text\n",
    "# columns = columns + df_col.count_columns_to_add # add keyword group count\n",
    "# columns_to_add = [\"TT?(Y/N/MB/NA)\", \"MACAQUE?(Y/N/MB/NA)\", \"TC_OR_CT?(Y/N/MB/NA)\", \"RELEVANT?(Y/N/MB/NA)\", \"READ_BY(A/D/R)\", \"COMMENT\"] # add columns for documenting labels\n",
    "# columns = columns + columns_to_add\n",
    "# df.columns = columns\n",
    "\n",
    "# for ind in df.index:\n",
    "#     index = df.at[ind, \"INDEX\"]\n",
    "#     full_text_url = df.at[ind, \"FULL_TEXT_URL\"]\n",
    "#     pdf_url = df.at[ind, \"PDF_URL\"]\n",
    "#     relevant = df.at[ind, \"RELEVANT?(Y/N/MB/NA)\"]\n",
    "    \n",
    "#     line_number_in_csv = ind + 2\n",
    "#     print(\"Line number:\", line_number_in_csv, \"INDEX:\", index)\n",
    "#     print(\"ind: \", ind, )\n",
    "#     print(\"full_text_url: \", full_text_url)\n",
    "#     print(\"pdf_url: \", pdf_url)\n",
    "#     print(\"relevant: \", relevant)\n",
    "#     print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import networkx as nx\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# A = pd.read_csv('./datasets/macaque_corticoCortical_adjacency.csv', index_col=0)\n",
    "\n",
    "# # Create non-directed graph\n",
    "# G = nx.convert_matrix.from_pandas_adjacency(A, create_using=nx.Graph)\n",
    "\n",
    "# # print(G.nodes)\n",
    "\n",
    "# # pos = nx.spring_layout(G, seed=24)\n",
    "# # nx.draw_networkx(G, pos, with_labels=False, node_size=0, edge_cmap='Greys', width=0.1, alpha=0.5)\n",
    "\n",
    "# # # ALl this just to make the nodes certain colors\n",
    "# # macaque_regions = ['Visual', 'Temporal', 'Parietal', 'Somatosensory', 'Auditory',\n",
    "# #                    'Motor', 'Prefrontal', 'Frontal', 'Orbitofrontal']\n",
    "# # colors = ['#4c6ef5', '#228be6', '#15aabf', '#12b886', '#40c057', '#82c91e', '#fab005', '#fd7e14']\n",
    "# # for region, c in zip(macaque_regions, colors):\n",
    "# #     # subset = subset = macaque.get_areas_in_regions(region)\n",
    "# #     subset = get_areas_in_regions(region)\n",
    "# #     nodes = []\n",
    "# #     for node in subset:\n",
    "# #         if node in G.nodes:\n",
    "# #             nodes.append(node)\n",
    "# #     nx.draw_networkx_nodes(G, pos, nodelist=nodes, node_color=c, node_size=30, alpha=0.8, label=region)\n",
    "\n",
    "# # # Create labels on top\n",
    "# # nx.draw_networkx(G, pos, with_labels=True, node_size=0, width=0, alpha=1, font_size=7)\n",
    "\n",
    "# # plt.legend(frameon=False, loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "# # plt.savefig('Cortico_cortical_connectivity_macaque.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # To show the adjacency matrix\n",
    "# plt.imshow(A)\n",
    "# plt.yticks(range(len(A.columns)), A.columns, fontsize=7)\n",
    "# plt.ylabel('Source areas', fontsize=10)\n",
    "# plt.xticks(range(len(A.columns)), A.columns, rotation=90, fontsize=7)\n",
    "# plt.xlabel('Target areas', fontsize=10)\n",
    "# plt.colorbar()\n",
    "\n",
    "# # plt.subplots_adjust(bottom=0.1)\n",
    "# plt.savefig('Cortico_cortical_connectivity_heatmap_macaque.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "\n",
    "# # Data\n",
    "# labels1 = ['Google Scholar', 'Web of Science', 'PubMed', 'Europe PMC']\n",
    "# sizes1 = [980, 1993, 2612, 9178]\n",
    "# labels2 = ['Full text not available', 'Full text available']\n",
    "# sizes2 = [226, 10550]\n",
    "\n",
    "# # Custom function to format the label\n",
    "# def func(pct, allvalues): \n",
    "#     absolute = int(pct / 100.*np.sum(allvalues)) \n",
    "#     return \"{:.1f}%\\n({:d} )\".format(pct, absolute)\n",
    "\n",
    "# # Cold color palette\n",
    "# colors1 = ['#85C1E9', '#3498DB', '#2874A6', '#1B4F72']\n",
    "# colors2 = ['#AED6F1', '#2E86C1']\n",
    "\n",
    "# # Plotting\n",
    "# fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 7))  # 1 row, 2 columns\n",
    "\n",
    "# # Font sizes\n",
    "# title_fontsize = 16\n",
    "# label_fontsize = 15\n",
    "# autopct_fontsize = 10\n",
    "\n",
    "# # First pie chart\n",
    "# ax1.pie(sizes1, labels=labels1, autopct=lambda pct: func(pct, sizes1), \n",
    "#         startangle=90, colors=colors1, textprops={'fontsize': label_fontsize})\n",
    "# ax1.set_title(\"A\", loc='left', fontsize=title_fontsize)\n",
    "# ax1.axis('equal')\n",
    "\n",
    "# # Second pie chart\n",
    "# ax2.pie(sizes2, labels=labels2, autopct=lambda pct: func(pct, sizes2), \n",
    "#         startangle=90, colors=colors2, textprops={'fontsize': label_fontsize})\n",
    "# ax2.set_title(\"B\", loc='left', fontsize=title_fontsize)\n",
    "# ax2.axis('equal')\n",
    "\n",
    "# # Show both pie charts side by side\n",
    "# plt.tight_layout()  # Adjusts the space between the two plots for better visualization\n",
    "# plt.show()\n",
    "\n",
    "# # Save figure\n",
    "# fig.savefig('pie_chart.png', dpi=300, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scan the rows in the test 1000 csv file and print the full_text_url and pdf_url of the papers that have no pdf_url\n",
    "input_path = fpath.poten_litera_testing_set_1000_text_extract_and_count\n",
    "output_path = fpath.poten_litera_testing_set_1000_labeled\n",
    "# clear the file\n",
    "plib.clear_file(output_path)\n",
    "\n",
    "df = pd.read_csv(input_path, header=0, sep=',')\n",
    "columns = [\n",
    "    \"INDEX\", \"DOI\", \"PMID\", \"PMCID\", \"FULL_TEXT_URL\", \"PDF_URL\", \n",
    "    \"TITLE\", \"TEXT_TAK\", \"TEXT_500\"\n",
    "]\n",
    "columns = columns + df_col.text_columns_to_add # add keyword group text\n",
    "columns = columns + df_col.count_columns_to_add # add keyword group count\n",
    "columns_to_add = [\"TT?(Y/N/MB/NA)\", \"MACAQUE?(Y/N/MB/NA)\", \"TC_OR_CT?(Y/N/MB/NA)\", \"RELEVANT?(Y/N/MB/NA)\", \"READ_BY(A/D/R)\", \"COMMENT\"] # add columns for documenting labels\n",
    "columns = columns + columns_to_add\n",
    "df.columns = columns\n",
    "\n",
    "\n",
    "# select only the columns INDEX, DOI and PMID and save the dataframe as a csv file\n",
    "df = df[[\"INDEX\", \"DOI\", \"PMID\", \"PMCID\", \"RELEVANT?(Y/N/MB/NA)\"]]\n",
    "df.to_csv(output_path, index=False, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
