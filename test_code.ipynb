{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-31 22:18:39 Didis-MacBook-Pro.local metapub.config[791] WARNING NCBI_API_KEY was not set.\n"
     ]
    }
   ],
   "source": [
    "# import internal .py modules\n",
    "import file_path_management as fpath\n",
    "import public_library as plib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import csv\n",
    "import pandas as pd\n",
    "import PyPDF2\n",
    "import requests\n",
    "import time\n",
    "import os\n",
    "import random\n",
    "from requests.auth import HTTPProxyAuth\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.firefox import GeckoDriverManager\n",
    "from selenium.webdriver.firefox.service import Service\n",
    "from selenium.common.exceptions import TimeoutException, WebDriverException, NoSuchElementException\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_google_shcolar(source_path, output_path, columns):\n",
    "    print(\"Starting merging search results from Google Scholar...\")\n",
    "\n",
    "    df = pd.read_csv(source_path, header=None, sep=',')\n",
    "    df.columns = [\"title\", \"url\", \"full_text_url\", \"full_text_type\", \"full_text_source\"]\n",
    "\n",
    "    for ind in df.index:\n",
    "        # if a row doesn't have url or title, then skip and drop this row\n",
    "        if (df[\"title\"][ind] != df[\"title\"][ind]) or (df[\"url\"][ind] != df[\"url\"][ind]):\n",
    "            continue\n",
    "\n",
    "        # get DOI\n",
    "        doi = np.nan\n",
    "\n",
    "        # get pmid from DOI\n",
    "        pmid = plib.doi2pmid(doi)\n",
    "\n",
    "        # get pmcid from pmid\n",
    "        pmcid = np.nan\n",
    "\n",
    "        # get full_text_url, full_text_source\n",
    "        if str(df[\"full_text_type\"][ind]) == \"[HTML]\":\n",
    "            full_text_url, = plib.get_final_redirected_url(str(df[\"full_text_url\"][ind]).strip()).strip()\n",
    "            full_text_source = full_text_url.split(\"://\")[1].strip().split(\"/\")[0].strip()\n",
    "        elif str(df[\"full_text_type\"][ind]) == \"not found\" | \"[PDF]\" | \"UB\":\n",
    "            if str(df[\"url\"][ind]) != \"not found\":\n",
    "                full_text_url, = plib.get_final_redirected_url(str(df[\"url\"][ind]).strip()).strip()\n",
    "                full_text_source = full_text_url.split(\"://\")[1].strip().split(\"/\")[0].strip()\n",
    "            else:\n",
    "                full_text_url = np.nan\n",
    "                full_text_source = np.nan\n",
    "        else:\n",
    "            raise Exception(\"Found a full_text_type not expected!\")\n",
    "        \n",
    "        # get pdf_url, pdf_source\n",
    "        if str(df[\"full_text_type\"][ind]) == \"[PDF]\":\n",
    "            pdf_url = str(df[\"full_text_url\"][ind])\n",
    "            pdf_source = pdf_url.split(\"://\")[1].strip().split(\"/\")[0].strip()\n",
    "        else:\n",
    "            pdf_url = np.nan\n",
    "            pdf_source = np.nan\n",
    "        \n",
    "        # columns = [\"DOI\", \"PMID\", \"PMCID\", \"Title\", \"full_text_url\", \"full_text_source\", \"pdf_url\", \"pdf_source\"]\n",
    "        row = {\n",
    "            \"DOI\": [doi],\n",
    "            \"PMID\": [pmid],\n",
    "            \"PMCID\": [pmcid],\n",
    "            \"Title\": [str(df[\"title\"][ind]).strip()],\n",
    "            \"full_text_url\": [full_text_url],\n",
    "            \"full_text_source\": [full_text_source],\n",
    "            \"pdf_url\": [pdf_url],\n",
    "            \"pdf_source\": [pdf_source]\n",
    "        }\n",
    "        # print(row)\n",
    "\n",
    "        if not plib.add_row_to_csv(output_path, row, columns):\n",
    "            print(\"Error detected when adding a row to csv!\")\n",
    "        \n",
    "        print(ind)\n",
    "# --------------------start of test code--------------------\n",
    "# source_path = fpath.poten_litera_gs\n",
    "# output_path = fpath.poten_litera_gs_processed\n",
    "# plib.clear_file(output_path)\n",
    "# ---------------------end of test code---------------------\n",
    "\n",
    "# --------------------start of test code--------------------\n",
    "# df = pd.read_csv(source_path, header=None, sep=',')\n",
    "# df.columns = [\"title\", \"url\", \"full_text_url\", \"full_text_type\", \"full_text_source\"]\n",
    "# print(df.head(3))\n",
    "# ---------------------end of test code---------------------\n",
    "\n",
    "# --------------------start of test code--------------------\n",
    "# full_text_type = set(df['full_text_type'].tolist())\n",
    "# print(full_text_type)\n",
    "# # {'[HTML]', nan, '[PDF]', 'UB'}\n",
    "# full_text_source = set(df['full_text_source'].tolist())\n",
    "# print(full_text_source)\n",
    "# # {'RWTH-Link', 'ijpp.com', 'nih.gov', 'sciencedirect.com', 'koreamed.org', 'biomedcentral.com', \n",
    "# # 'ekja.org', 'harvard.edu', 'bu.edu', 'europepmc.org', 'lww.com', 'ieee.org', 'oup.com', 'mcgill.ca', \n",
    "# # 'uottawa.ca', 'plos.org', 'ahajournals.org', 'cell.com', 'sonar.ch', 'core.ac.uk', 'mdpi.com', \n",
    "# # nan, 'wiley.com', 'nature.com', 'uzh.ch', 'elifesciences.org', 'nyu.edu', 'karger.com', \n",
    "# # 'academia.edu', 'psychiatryonline.org', 'tandfonline.com', 'jordanbpeterson.com', 'duke.edu', \n",
    "# # 'science.org', 'pnas.org', 'umich.edu', 'springer.com', 'unav.edu', 'jst.go.jp', 'bmj.com', \n",
    "# # 'researchgate.net', 'eneuro.org', 'annualreviews.org', 'northwestern.edu', 'rero.ch', \n",
    "# # 'zsp.com.pk', 'epfl.ch', 'jneurosci.org', 'mirasmart.com', 'sagepub.com', 'ahuman.org', \n",
    "# # 'psu.edu', 'frontiersin.org', 'scholarpedia.org', 'jpn.ca', 'udc.es', 'biorxiv.org', 'physiology.org', \n",
    "# # 'royalsocietypublishing.org', 'escholarship.org', 'wustl.edu', 'ucdavis.edu', 'asahq.org'}\n",
    "# ---------------------end of test code---------------------\n",
    "\n",
    "# --------------------start of test code--------------------\n",
    "# [\"title\", \"url\", \"full_text_url\", \"full_text_type\", \"full_text_source\"]\n",
    "# print(df[\"title\"].isnull().any().any())\n",
    "# print(df[\"url\"].isnull().any().any())\n",
    "# print(df[\"full_text_url\"].isnull().any().any())\n",
    "# print(df[\"full_text_type\"].isnull().any().any())\n",
    "# print(df[\"full_text_source\"].isnull().any().any())\n",
    "# # # True, True, True, True, True\n",
    "# # # title, url, full_text_url, full_text_type, full_text_source contain np.nan\n",
    "# # # we need to fill in what are missing\n",
    "# ---------------------end of test code---------------------\n",
    "\n",
    "# --------------------start of test code--------------------\n",
    "# preprocess_google_shcolar(source_path, output_path, columns)\n",
    "# ---------------------end of test code---------------------\n",
    "\n",
    "# --------------------start of test code--------------------\n",
    "# df = pd.read_csv(output_path, header=None, sep=',')\n",
    "# print(df.head(3))\n",
    "# ---------------------end of test code---------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
