{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dea1cce5-4f07-4bd7-8ca3-5f6fa51254d0",
   "metadata": {},
   "source": [
    "Automatic filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28e51706-2334-49bb-8c1e-4939b52c60b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import internal .py files\n",
    "import file_path_management as fpath\n",
    "import public_library as plib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad5a61c5-f8c6-418a-b450-cdea0378ddab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22d9559b-7ccd-48b5-9bd0-422f6d7c7644",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "\n",
    "# on-topic keyword lexicon\n",
    "on_topic_kws = ['thalamocortical', 'thalamo-cortical', 'corticothalamic', 'cortico-thalamic',\n",
    "                'tracing', 'tracer', 'tract tracing', 'tract-tracing', 'axonal tracing', 'neural tracing', 'anatomical tracing', 'anatomical neural tracing',\n",
    "                'connection', 'projection', 'connectivity', 'connectome', \n",
    "                'thalamus', 'cortex', 'thalamic', 'cortical']\n",
    "\n",
    "related_kws_weights = {'tracing': 100000, 'tracer': 100000, 'tract tracing': 100000, 'tract-tracing': 100000, 'axonal tracing': 100000, 'neural tracing': 100000, 'anatomical tracing': 100000, 'anatomical neural tracing': 100000,\n",
    "                       'thalamocortical': 1000, 'thalamo-cortical': 1000, 'corticothalamic': 1000, 'cortico-thalamic': 1000,\n",
    "                       'connection': 10, 'projection': 10, 'connectivity': 10, 'connectome': 10, \n",
    "                       'thalamus': 1, 'cortex': 1, 'thalamic': 1, 'cortical': 1}\n",
    "\n",
    "# ChatGPT, queries for relatedness of topic\n",
    "ChatGPT_related_queries = ['Does the given text include information of thalamocotical connection?',\n",
    "                           'Does this paper provide data of thalamocotical connection?',\n",
    "                           'Does the given text include information of connection between thalamus and cortex?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce32f7b8-96b7-4f5c-a2da-3ff931cdeaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the number of times that certain on-topic keyword appear in a given text\n",
    "def count_keyword(text: str, keyword: str) -> int:\n",
    "    # print(text)\n",
    "    # remove spaces before and after the text and split the string by word\n",
    "    text = text.strip().split(\" \")\n",
    "    word_count = 0\n",
    "    for word in text:\n",
    "        # print(word)\n",
    "        if word == keyword:\n",
    "            word_count += 1\n",
    "    return word_count\n",
    "\n",
    "\n",
    "# # test code: count_keyword(text: str, keyword: str) -> int\n",
    "# text = 'This apple 6i7s very tasty？、  2but th&e banana is not delicious at all.6'\n",
    "# keyword = 'is'\n",
    "# count = count_keyword(text, keyword)\n",
    "# print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72f568c7-f872-4889-a914-e9ef4edef453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the information to list_of_potential_related_literature.csv\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b488729c-2e38-43e8-bba2-d81126f38847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the number of times all on-topic keywords appear in the text (title, abstract, keywords and so on)\n",
    "# extracted from the given url\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "\n",
    "def count_freq_from_liter(url, on_topic_kws):\n",
    "    print(url)\n",
    "    # access the url by web scraping\n",
    "    headers = {'User-Agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_2) AppleWebKit/601.3.9 (KHTML, like Gecko) Version/9.0.2 Safari/601.3.9'} \n",
    "    response = requests.get(url, headers = headers)\n",
    "    soup = BeautifulSoup(response.content,'lxml')\n",
    "    print(len(soup))\n",
    "    \n",
    "    # extract DOI\n",
    "    # print(soup.find_all(\"a\", {'class': 'id-link'}, href = True)[1]['href'])\n",
    "    doi = soup.find_all(\"a\", {'class': 'id-link'}, href = True)[1]['href']\n",
    "    \n",
    "    # extract title\n",
    "    title = soup.select('h1')[0].get_text().strip()\n",
    "    title = re.sub(' +', ' ', title).capitalize()\n",
    "    \n",
    "\n",
    "#     # extract PDF link if exists\n",
    "#     print(doi)\n",
    "#     response_pdf = requests.get(doi, headers = headers)\n",
    "#     print(response_pdf.url)\n",
    "#     pdf_page_link = response_pdf.url\n",
    "        \n",
    "#     pdf_page = soup.find_all(\"a\", {'class':'link-item dialog-focus'}, href = True)[0]['href']\n",
    "    \n",
    "#     # print(pdf_page_link)\n",
    "#     pdf_page = requests.get(pdf_page_link, headers = headers)\n",
    "#     soup_pdf = BeautifulSoup(pdf_page.content,'lxml')\n",
    "#     print(len(soup_pdf.find_all(\"a\", href = True)))\n",
    "#     pdf_link = soup_pdf.find_all(\"a\", href = True)[0]['href']\n",
    "    \n",
    "    \n",
    "#     print(pdf_link)\n",
    "#     pdf_link = 'https://www.ncbi.nlm.nih.gov' + pdf_link\n",
    "\n",
    "    # extract title, abstract, keywords, introduction from the returned html file\n",
    "    # count keywords from abstract + keywords\n",
    "    abs_kws = soup.find_all(\"div\", {'class': 'abstract'})[0].get_text()\n",
    "    abs_kws = abs_kws.strip()\n",
    "    abs_kws = re.sub(' +', ' ', abs_kws)\n",
    "    text = title + ' ' + abs_kws\n",
    "    text = re.sub(r\"[^a-zA-Z' ']\",\"\",text).lower()\n",
    "    \n",
    "    # record the information into json\n",
    "    info_json = {}\n",
    "    info_json['DOI'] = doi,\n",
    "    info_json['url'] = url,\n",
    "    info_json['title'] = title\n",
    "    # info_json['pdf_link'] = pdf_link\n",
    "    # count the on-topic keywords or calculate the frequency\n",
    "    for i in range(len(on_topic_kws)):\n",
    "        word_count = count_keyword(text, on_topic_kws[i])\n",
    "        info_json[on_topic_kws[i]] = word_count\n",
    "    return info_json\n",
    "\n",
    "\n",
    "# test code: \n",
    "# url = 'https://pubmed.ncbi.nlm.nih.gov/32053769/'\n",
    "# pdf_folder_path = '/Users/didihou/myProjects/liter_pdfs'\n",
    "# info_json_ele = count_freq_from_liter(url, on_topic_kws)\n",
    "# file_name = 'test.pdf'\n",
    "# download_pdf_file(info_json_ele['pdf_link'], pdf_folder_path, file_name)\n",
    "# print(info_json_ele)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81563c9e-1a9c-44fc-ad44-bc3210d9f8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download pdf to specified folder given pdf_url and file name\n",
    "import os\n",
    "\n",
    "\n",
    "def download_pdf(pdf_url: str, pdf_folder_path: str, file_name: str) -> bool:    \n",
    "    response = requests.get(pdf_url, stream=True, headers = plib.headers)\n",
    "    \n",
    "    # download the .pdf file to the pdf_file_path folder\n",
    "    # write content in pdf file\n",
    "    pdf_path = os.path.join(pdf_folder_path, file_name + '.pdf')\n",
    "    if response.status_code == 200:\n",
    "        with open(pdf_path, 'wb') as pdf_object:\n",
    "            pdf_object.write(response.content)\n",
    "            # print(f'{file_name} was successfully saved!')\n",
    "            return True\n",
    "    else:\n",
    "        print(f'Failed downloading PDF:' + 'pdf_url')\n",
    "        print(f'HTTP response status code: {response.status_code}')\n",
    "        return False\n",
    "\n",
    "    \n",
    "# # test code: download_pdf(pdf_url: str, pdf_folder_path: str, file_name: str) -> bool\n",
    "# pdf_url = 'https://www.sciencedirect.com/science/article/pii/S0896627320300052/pdfft?md5=3f0648c6385e6fae3a5a73b053903014&pid=1-s2.0-S0896627320300052-main.pdf'\n",
    "# file_name = 'test_pdf'\n",
    "# download_pdf(pdf_url, pdf_folder_path, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "93f93d7d-bbbc-4afe-94f7-f12cca267a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scan each url in list_of_literature_urls.txt and record information and download pdf\n",
    "def scan_record_download(path_urls, on_topic_kws, pdf_folder_path):\n",
    "    columns = ['DOI', 'url', 'title'] + on_topic_kws\n",
    "    file_index = 0\n",
    "    with open(path_urls, 'r') as url_file:\n",
    "        for url in url_file:\n",
    "            # print(url)\n",
    "            info_json = {}\n",
    "            info_json = count_freq_from_liter(url.strip(), on_topic_kws)\n",
    "            fpath.add_row_to_csv(fpath.poten_litera_csv, info_json, columns)\n",
    "            # download_pdf_file(info_json['pdf_link'], pdf_folder_path, str(file_index))\n",
    "            file_index += 1\n",
    "\n",
    "\n",
    "# # test code: scan_record_download(path_urls, on_topic_kws, pdf_folder_path)\n",
    "# scan_record_download(path_urls, on_topic_kws, pdf_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4eb134-7b9b-4ae4-8b45-74dcd1ddb96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the results to fpath.poten_litera_csv\n",
    "# DOI PMID PMCID Authors Title Abstract Keywords full_text_links pdf_link"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
