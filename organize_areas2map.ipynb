{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_name = \"120_Rouiller_2004\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "1\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# read data from json file\n",
    "fn = os.path.join('.', 'metadata_extraction', 'literature_metadata.json')\n",
    "with open(fn, 'r') as f:\n",
    "    data = f.read()\n",
    "    \n",
    "# parse json data\n",
    "json_data = json.loads(data)\n",
    "\n",
    "# iterate the keys in the json data, find the element contains the pdf name\n",
    "flag_found = False\n",
    "for key in json_data.keys():\n",
    "    # print(key)\n",
    "    if pdf_name in key:\n",
    "        flag_found = True\n",
    "        article_data = json_data[key]\n",
    "        break\n",
    "if flag_found == False:\n",
    "    raise Exception(\"pdf name not found\")\n",
    "\n",
    "# read DOI_URL, Title, Injection and Labeling from article_data\n",
    "DOI_URL = article_data[\"Article_Info\"][\"DOI-URL\"]\n",
    "Title = article_data[\"Article_Info\"][\"Title\"]\n",
    "Injection_and_Labeling = article_data[\"Injection_and_Labeling\"]\n",
    "\n",
    "# iterate the elements in injection_labeled_data, find all injection sites and labeled sites\n",
    "injection_sites = []\n",
    "labeled_sites = []\n",
    "for injection in Injection_and_Labeling:\n",
    "    injection_sites.append(injection[\"Injection\"][\"InjectionSite_by_Author\"])\n",
    "    for labeled_site in injection[\"LabeledSites\"]:\n",
    "        labeled_sites.append(labeled_site[\"LabeledSite_by_Author\"])\n",
    "\n",
    "# remove the duplicates in injection_sites\n",
    "injection_sites = list(dict.fromkeys(injection_sites))\n",
    "    \n",
    "# remove the duplicates in labeled_sites and rank the labeled_site arphabetically\n",
    "labeled_sites = list(dict.fromkeys(labeled_sites))\n",
    "labeled_sites.sort()\n",
    "\n",
    "# find sites that appear in both injection_sites and labeled_sites\n",
    "both_sites = list(set(injection_sites) & set(labeled_sites))\n",
    "\n",
    "# remove sites that appear in injection sites from labeled sites\n",
    "for site in both_sites:\n",
    "    if site in labeled_sites:\n",
    "        labeled_sites.remove(site)\n",
    "        \n",
    "# merge the injection_sites and labeled_sites\n",
    "list_of_sites = injection_sites + labeled_sites\n",
    "        \n",
    "# merge all elements in the list and seperate by \\n into a string and write back to txt file\n",
    "fn = os.path.join('.', 'metadata_extraction', pdf_name, '.txt')\n",
    "with open('areas_to_map.txt', 'w') as f:\n",
    "    f.write('\\n'.join(list_of_sites))\n",
    "    \n",
    "print(\"Number of sites:\", len(list_of_sites))\n",
    "print(\"Number of injection sites:\", len(injection_sites))\n",
    "print(\"Number of labeled sites:\", len(labeled_sites))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the data into csv file\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "csv_columns = ['Area name', 'Area name explained', 'Area type (Injection site/Labeled site/Both sites)', 'Relation (part of/same as/sum of)', 'Mapped area name', 'Mapping confidence (high/medium/low)', 'Mapping references', 'Mapped by (D/R/A)', 'Comment', 'Figures', 'PRs']\n",
    "\n",
    "fn = os.path.join('.', 'mapping', pdf_name + '.csv')\n",
    "data_frame = pd.read_csv(fn, header=None, sep=\"\\t\")\n",
    "\n",
    "data_frame.columns = csv_columns\n",
    "\n",
    "# the element of first row and second columns is assigned DOI_URL\n",
    "data_frame.iloc[0, 1] = DOI_URL\n",
    "data_frame.iloc[1, 1] = Title\n",
    "\n",
    "for i in range(len(list_of_sites)):\n",
    "    row = i + 10\n",
    "    data_frame.loc[row, 'Area name'] = list_of_sites[i]\n",
    "    data_frame.loc[row, 'Mapped by (D/R/A)'] = 'D'\n",
    "    if list_of_sites[i] in both_sites:\n",
    "        data_frame.loc[row, 'Area type (Injection site/Labeled site/Both sites)'] = 'Both sites'\n",
    "    elif list_of_sites[i] in injection_sites:\n",
    "        data_frame.loc[row, 'Area type (Injection site/Labeled site/Both sites)'] = 'Injection site'\n",
    "    elif list_of_sites[i] in labeled_sites:\n",
    "        data_frame.loc[row, 'Area type (Injection site/Labeled site/Both sites)'] = 'Labeled site'\n",
    "    else:\n",
    "        raise Exception(\"The site:\", site, \"is not in injection_sites or labeled_sites or both_sites\")\n",
    "    \n",
    "# write the data into csv file\n",
    "data_frame.to_csv(fn, index=False, header=False, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # read string from txt file\n",
    "# with open('injection_labeled_sites.txt', 'r') as f:\n",
    "#     given_string = f.read()\n",
    "    \n",
    "# # separate string using \\n\n",
    "# list_of_sites = given_string.splitlines()\n",
    "\n",
    "# # remove empty strings\n",
    "# list_of_sites = [x for x in list_of_sites if x]\n",
    "\n",
    "# # find all injection sites as a list that appear as the next element of \"InjectionSite:\"\n",
    "# injection_site = []\n",
    "# for i in range(len(list_of_sites)):\n",
    "#     if list_of_sites[i] == 'InjectionSite:':\n",
    "#         injection_site.append(list_of_sites[i+1])\n",
    "        \n",
    "# # remove the duplicates in the inection_site\n",
    "# injection_site = list(dict.fromkeys(injection_site))\n",
    "        \n",
    "# # find all labeled sites as a list that appear as the next elements after \"LabeledSites:\" and before \"Injection:\" or end of the list\n",
    "# labeled_site = []\n",
    "# for i in range(len(list_of_sites)):\n",
    "#     if list_of_sites[i] == 'LabeledSites:':\n",
    "#         for j in range(i+1, len(list_of_sites)):\n",
    "#             if list_of_sites[j] == 'Injection:':\n",
    "#                 break\n",
    "#             else:\n",
    "#                 labeled_site.append(list_of_sites[j])\n",
    "\n",
    "# # remove \"R:\" and \"A:\" in the labeld list\n",
    "# for ele in labeled_site:\n",
    "#     if ele == 'R:':\n",
    "#         labeled_site.remove('R:')\n",
    "#     elif ele == 'A:':\n",
    "#         labeled_site.remove('A:')\n",
    "#     else:\n",
    "#         pass\n",
    "\n",
    "# # remove the duplicates in the labeled_site\n",
    "# labeled_site = list(dict.fromkeys(labeled_site))\n",
    "\n",
    "# # rank the labeled_site arphabetically\n",
    "# labeled_site.sort()\n",
    "\n",
    "# # merge injection_site and labeled_site\n",
    "# list_of_sites = injection_site + labeled_site\n",
    "\n",
    "# print(list_of_sites)\n",
    "# print(len(list_of_sites))\n",
    "# print(len(injection_site))\n",
    "# print(len(labeled_site))\n",
    "\n",
    "# # merge all elements in the list and seperate by \\n into a string and write back to txt file\n",
    "# with open('areas_to_map.txt', 'w') as f:\n",
    "#     f.write('\\n'.join(list_of_sites))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
