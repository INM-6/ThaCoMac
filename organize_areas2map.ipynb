{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_name = \"42_Cappe_2007\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./mapping/42_Cappe_2007.csv'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create mapping csv file from template\n",
    "fn_template = os.path.join('.', 'mapping', 'template4mapping.csv')\n",
    "fn_new = os.path.join('.', 'mapping', pdf_name + '.csv')\n",
    "shutil.copy(fn_template, fn_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from json file and parse json data\n",
    "fn = os.path.join('.', 'metadata_extraction', 'literature_metadata.json')\n",
    "\n",
    "with open(fn, 'r') as f:\n",
    "    data = f.read()\n",
    "    \n",
    "json_data = json.loads(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate the keys in the json data, find the element contains the pdf name\n",
    "flag_found = False\n",
    "\n",
    "for key in json_data.keys():\n",
    "    if pdf_name in key:\n",
    "        flag_found = True\n",
    "        article_data = json_data[key]\n",
    "        break\n",
    "    \n",
    "if flag_found == False:\n",
    "    raise Exception(\"CSV file with name \" + pdf_name + \" not found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read DOI_URL, Title, Injection_and_Labeling from article_data\n",
    "DOI_URL = article_data[\"Article_Info\"][\"DOI-URL\"]\n",
    "Title = article_data[\"Article_Info\"][\"Title\"]\n",
    "Injection_and_Labeling = article_data[\"Injection_and_Labeling\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sites: 28\n",
      "Number of injection sites: 2\n",
      "Number of labeled sites: 26\n"
     ]
    }
   ],
   "source": [
    "# Find all injection sites and labeled sites\n",
    "injection_sites = []\n",
    "labeled_sites = []\n",
    "\n",
    "for injection in Injection_and_Labeling:\n",
    "    injection_sites.append(injection[\"Injection\"][\"InjectionSite_by_Author\"])\n",
    "    for labeled_site in injection[\"LabeledSites\"]:\n",
    "        labeled_sites.append(labeled_site[\"LabeledSite_by_Author\"])\n",
    "\n",
    "# Remove the duplicates in injection_sites\n",
    "injection_sites = list(dict.fromkeys(injection_sites))\n",
    "    \n",
    "# Remove the duplicates in labeled_sites and rank the labeled_sites arphabetically\n",
    "labeled_sites = list(dict.fromkeys(labeled_sites))\n",
    "labeled_sites.sort()\n",
    "\n",
    "# Find sites that appear in both injection_sites and labeled_sites\n",
    "both_sites = list(set(injection_sites) & set(labeled_sites))\n",
    "\n",
    "# Remove sites that appear in injection_sites from labeled_sites\n",
    "for site in both_sites:\n",
    "    if site in labeled_sites:\n",
    "        labeled_sites.remove(site)\n",
    "        \n",
    "# Merge the injection_sites and labeled_sites\n",
    "list_of_sites = injection_sites + labeled_sites\n",
    "\n",
    "# Print the number of sites\n",
    "print(\"Number of sites:\", len(list_of_sites))\n",
    "print(\"Number of injection sites:\", len(injection_sites))\n",
    "print(\"Number of labeled sites:\", len(labeled_sites))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all elements in the list and seperate by \\n into a string and write back to txt file\n",
    "with open('areas_to_map.txt', 'w') as f:\n",
    "    f.write('\\n'.join(list_of_sites))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the data into csv file\n",
    "csv_columns = [\n",
    "    'Area name', \n",
    "    'Area name explained', \n",
    "    'Area type (Injection site/Labeled site/Both sites)', \n",
    "    'Relation (part of/same as/sum of)', \n",
    "    'Mapped area name', \n",
    "    'Mapping confidence (high/medium/low)', \n",
    "    'Mapping references', \n",
    "    'Mapped by (D/R/A)', \n",
    "    'Comment', \n",
    "    'Figures', \n",
    "    'PRs'\n",
    "    ]\n",
    "\n",
    "# Read data from csv file and parse csv data\n",
    "fn = os.path.join('.', 'mapping', pdf_name + '.csv')\n",
    "df = pd.read_csv(fn, header=None, index_col=None, sep=\"\\t\")\n",
    "\n",
    "df.columns = csv_columns\n",
    "\n",
    "# Fill in DOI_URL and Title\n",
    "df.iloc[0, 1] = DOI_URL\n",
    "df.iloc[1, 1] = Title\n",
    "\n",
    "# Fill in all columns in row 10 \"\"\n",
    "for i in range(len(df.columns)):\n",
    "    df.loc[10, i] = \"\"\n",
    "\n",
    "# Fill in InjectionSite and LabeledSite\n",
    "for i in range(len(list_of_sites)):\n",
    "    row_index = i + 11\n",
    "    \n",
    "    df.loc[row_index, 'Area name'] = list_of_sites[i]\n",
    "    \n",
    "    df.loc[row_index, 'Mapped by (D/R/A)'] = 'D'\n",
    "    \n",
    "    if list_of_sites[i] in both_sites:\n",
    "        df.loc[row_index, 'Area type (Injection site/Labeled site/Both sites)'] = 'Both sites'\n",
    "    elif list_of_sites[i] in injection_sites:\n",
    "        df.loc[row_index, 'Area type (Injection site/Labeled site/Both sites)'] = 'Injection site'\n",
    "    elif list_of_sites[i] in labeled_sites:\n",
    "        df.loc[row_index, 'Area type (Injection site/Labeled site/Both sites)'] = 'Labeled site'\n",
    "    else:\n",
    "        raise Exception(\"The site:\", site, \"is not in injection_sites or labeled_sites or both_sites\")\n",
    "    \n",
    "# Write back to csv file\n",
    "df.to_csv(fn, index=False, header=False, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # read string from txt file\n",
    "# with open('injection_labeled_sites.txt', 'r') as f:\n",
    "#     given_string = f.read()\n",
    "    \n",
    "# # separate string using \\n\n",
    "# list_of_sites = given_string.splitlines()\n",
    "\n",
    "# # remove empty strings\n",
    "# list_of_sites = [x for x in list_of_sites if x]\n",
    "\n",
    "# # find all injection sites as a list that appear as the next element of \"InjectionSite:\"\n",
    "# injection_site = []\n",
    "# for i in range(len(list_of_sites)):\n",
    "#     if list_of_sites[i] == 'InjectionSite:':\n",
    "#         injection_site.append(list_of_sites[i+1])\n",
    "        \n",
    "# # remove the duplicates in the inection_site\n",
    "# injection_site = list(dict.fromkeys(injection_site))\n",
    "        \n",
    "# # find all labeled sites as a list that appear as the next elements after \"LabeledSites:\" and before \"Injection:\" or end of the list\n",
    "# labeled_site = []\n",
    "# for i in range(len(list_of_sites)):\n",
    "#     if list_of_sites[i] == 'LabeledSites:':\n",
    "#         for j in range(i+1, len(list_of_sites)):\n",
    "#             if list_of_sites[j] == 'Injection:':\n",
    "#                 break\n",
    "#             else:\n",
    "#                 labeled_site.append(list_of_sites[j])\n",
    "\n",
    "# # remove \"R:\" and \"A:\" in the labeld list\n",
    "# for ele in labeled_site:\n",
    "#     if ele == 'R:':\n",
    "#         labeled_site.remove('R:')\n",
    "#     elif ele == 'A:':\n",
    "#         labeled_site.remove('A:')\n",
    "#     else:\n",
    "#         pass\n",
    "\n",
    "# # remove the duplicates in the labeled_site\n",
    "# labeled_site = list(dict.fromkeys(labeled_site))\n",
    "\n",
    "# # rank the labeled_site arphabetically\n",
    "# labeled_site.sort()\n",
    "\n",
    "# # merge injection_site and labeled_site\n",
    "# list_of_sites = injection_site + labeled_site\n",
    "\n",
    "# print(list_of_sites)\n",
    "# print(len(list_of_sites))\n",
    "# print(len(injection_site))\n",
    "# print(len(labeled_site))\n",
    "\n",
    "# # merge all elements in the list and seperate by \\n into a string and write back to txt file\n",
    "# with open('areas_to_map.txt', 'w') as f:\n",
    "#     f.write('\\n'.join(list_of_sites))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
