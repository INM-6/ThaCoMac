{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dea1cce5-4f07-4bd7-8ca3-5f6fa51254d0",
   "metadata": {},
   "source": [
    "# Keywords matching and relevance index ranking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5a61c5-f8c6-418a-b450-cdea0378ddab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from nltk import ngrams\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726b12c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import internal modules\n",
    "import file_path_management as fpath\n",
    "import public_library as plib\n",
    "import parameters as params\n",
    "import dataframe_columns as df_col"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489f0451",
   "metadata": {},
   "source": [
    "## Predefined fucntions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02fb81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relevance_index(counts_dict):\n",
    "    relevance_index = 0\n",
    "    for key in counts_dict.keys():\n",
    "        relevance_index += math.log(1+counts_dict[key]) * (params.ranking_kw_groups_weights[key])\n",
    "    return relevance_index\n",
    "# --------------------start of test code--------------------\n",
    "# keywords_count_or_fre = {}\n",
    "# index = calcul_related(keywords_count_or_fre, params.on_topic_kws_weights)\n",
    "# print(index)\n",
    "# ---------------------end of test code---------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edde53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_relevance_index(db_count_path, db_relevance_index_path, rank_by):\n",
    "    df = pd.read_csv(db_count_path, header=0, sep=\"\\t\")\n",
    "    if rank_by == 'tak':\n",
    "        column_name = '_COUNT_IN_TAK'\n",
    "    elif rank_by == '500':\n",
    "        column_name = '_COUNT_IN_500'\n",
    "    elif rank_by == 'full_text':\n",
    "        column_name = '_COUNT_IN_FULL_TEXT'\n",
    "        \n",
    "    count_dict = {}\n",
    "    for ind in df.index:\n",
    "        for key in params.ranking_kw_groups.keys():\n",
    "            value = df.at[ind, key+column_name]\n",
    "            if value != value:\n",
    "                value = 0\n",
    "            count_dict[key] = int(value)\n",
    "        # print(count_dict)\n",
    "\n",
    "        relev_index = relevance_index(count_dict)\n",
    "        \n",
    "        df.at[ind, \"RELEVANCE_INDEX\"] = relev_index\n",
    "\n",
    "        line_number_in_csv = ind + 1\n",
    "        print(\"Line number:\", line_number_in_csv, \" INDEX:\", int(df.at[ind, \"INDEX\"]))\n",
    "    \n",
    "    df.columns = df_col.db_ranked_columns\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    df.to_csv(db_relevance_index_path, header=True, index=False, sep=\"\\t\")\n",
    "    \n",
    "    print(\"Weighting and ranking the potentially related literature succeded!\")\n",
    "    print(\"Enjoy reading!\")\n",
    "# --------------------start of test code--------------------\n",
    "# input_path = fpath.poten_litera_db_kw_count\n",
    "# output_path = fpath.poten_litera_db_ranked\n",
    "# rank(input_path, output_path, params.ranking_params_weights)\n",
    "# ---------------------end of test code---------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_and_save(input_path):\n",
    "    # sort\n",
    "    df_to_rank = pd.read_csv(input_path, header=0, sep=\"\\t\")\n",
    "\n",
    "    df_to_rank.sort_values(by=['RELEVANCE_INDEX'], inplace=True, ascending=False)\n",
    "        \n",
    "    df_to_rank.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    df_to_rank.to_csv(input_path, header=True, index=False, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e562971",
   "metadata": {},
   "source": [
    "## Main program:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Calculate relevance index and rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_by = 'tak'\n",
    "rank_by = '500'\n",
    "rank_by = 'full_text'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = fpath.poten_litera_db_kw_count\n",
    "relevance_index_path = fpath.poten_litera_db_relevance_index\n",
    "# clear file\n",
    "plib.clear_file(relevance_index_path)\n",
    "\n",
    "compute_relevance_index(input_path, relevance_index_path, rank_by)\n",
    "\n",
    "if rank_by == 'tak':\n",
    "    # rank by tak    \n",
    "    rank_and_save(fpath.poten_litera_db_ranked_by_tak)\n",
    "elif rank_by == '500':\n",
    "    # rank by 500    \n",
    "    rank_and_save(fpath.poten_litera_db_ranked_by_500)\n",
    "elif rank_by == 'full_text':\n",
    "    # rank by full text\n",
    "    rank_and_save(fpath.poten_litera_db_ranked_by_full_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36685b74",
   "metadata": {},
   "source": [
    "### 3. Ranking results analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e384b1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the ranked database and obtain the relevance_index of YESs and NOs \n",
    "test_path = fpath.poten_litera_testing_set_1000_labeled\n",
    "df_test = pd.read_csv(test_path, header=0, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the counts of the keywords in the respective lists\n",
    "relevant_species = []\n",
    "relevant_other_species = []\n",
    "relevant_tc_ct = []\n",
    "relevant_thalam = []\n",
    "relevant_cortex = []\n",
    "relevant_inject = []\n",
    "relevant_method = []\n",
    "relevant_connectivity = []\n",
    "\n",
    "non_relevant_species = []\n",
    "non_relevant_other_species = []\n",
    "non_relevant_tc_ct = []\n",
    "non_relevant_thalam = []\n",
    "non_relevant_cortex = []\n",
    "non_relevant_inject = []\n",
    "non_relevant_method = []\n",
    "non_relevant_connectivity = []\n",
    "\n",
    "relvant_index_list = []\n",
    "relevant_relevance_index_list = []\n",
    "\n",
    "non_relevant_index_list = []\n",
    "non_relevant_relevance_index_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8aa55d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if rank_by == 'tak':\n",
    "    # rank by tak\n",
    "    df_db_ranked = pd.read_csv(fpath.poten_litera_db_ranked_by_tak, header=0, sep='\\t')\n",
    "    column_name_base = \"TAK\"\n",
    "elif rank_by == '500':\n",
    "    # rank by 500\n",
    "    df_db_ranked = pd.read_csv(fpath.poten_litera_db_ranked_by_500, header=0, sep='\\t')\n",
    "    column_name_base = \"500\"\n",
    "elif rank_by == 'full_text':\n",
    "    # rank by full text\n",
    "    df_db_ranked = pd.read_csv(fpath.poten_litera_db_ranked_by_full_text, header=0, sep='\\t')\n",
    "    column_name_base = \"FULL_TEXT\"\n",
    "\n",
    "for ind in df_test.index:\n",
    "    index = int(df_test.at[ind, \"INDEX\"])\n",
    "\n",
    "    if df_test.at[ind, \"RELEVANT?(Y/N/MB/NA)\"] == \"Y\":\n",
    "        relvant_index_list.append(index)\n",
    "        relevant_relevance_index_list.append(df_db_ranked.loc[df_db_ranked[\"INDEX\"].apply(int) == index, \"RELEVANCE_INDEX\"].values[0])\n",
    "        relevant_species.append(df_db_ranked.loc[df_db_ranked[\"INDEX\"].apply(int) == index, \"MACAQUE_COUNT_IN_\"+column_name_base].values[0])\n",
    "        relevant_other_species.append(df_db_ranked.loc[df_db_ranked[\"INDEX\"].apply(int) == index, \"OTHER_SPIECIES_COUNT_IN_\"+column_name_base].values[0])\n",
    "        relevant_tc_ct.append(df_db_ranked.loc[df_db_ranked[\"INDEX\"].apply(int) == index, \"TC_CT_COUNT_IN_\"+column_name_base].values[0])\n",
    "        relevant_thalam.append(df_db_ranked.loc[df_db_ranked[\"INDEX\"].apply(int) == index, \"THALAM_COUNT_IN_\"+column_name_base].values[0])\n",
    "        relevant_cortex.append(df_db_ranked.loc[df_db_ranked[\"INDEX\"].apply(int) == index, \"CORTEX_COUNT_IN_\"+column_name_base].values[0])\n",
    "        relevant_inject.append(df_db_ranked.loc[df_db_ranked[\"INDEX\"].apply(int) == index, \"INJECT_COUNT_IN_\"+column_name_base].values[0])\n",
    "        relevant_method.append(df_db_ranked.loc[df_db_ranked[\"INDEX\"].apply(int) == index, \"METHOD_COUNT_IN_\"+column_name_base].values[0])\n",
    "        relevant_connectivity.append(df_db_ranked.loc[df_db_ranked[\"INDEX\"].apply(int) == index, \"CONNECT_COUNT_IN_\"+column_name_base].values[0])\n",
    "    # elif df_db_ranked.loc[df_db_ranked[\"INDEX\"].apply(int) == index, \"LENGTH_TEXT\"].values[0] > 100:\n",
    "    else:\n",
    "        non_relevant_index_list.append(index)\n",
    "        non_relevant_relevance_index_list.append(df_db_ranked.loc[df_db_ranked[\"INDEX\"].apply(int) == index, \"RELEVANCE_INDEX\"].values[0])\n",
    "        non_relevant_species.append(df_db_ranked.loc[df_db_ranked[\"INDEX\"].apply(int) == index, \"MACAQUE_COUNT_IN_\"+column_name_base].values[0])\n",
    "        non_relevant_other_species.append(df_db_ranked.loc[df_db_ranked[\"INDEX\"].apply(int) == index, \"OTHER_SPIECIES_COUNT_IN_\"+column_name_base].values[0])\n",
    "        non_relevant_tc_ct.append(df_db_ranked.loc[df_db_ranked[\"INDEX\"].apply(int) == index, \"TC_CT_COUNT_IN_\"+column_name_base].values[0])\n",
    "        non_relevant_thalam.append(df_db_ranked.loc[df_db_ranked[\"INDEX\"].apply(int) == index, \"THALAM_COUNT_IN_\"+column_name_base].values[0])\n",
    "        non_relevant_cortex.append(df_db_ranked.loc[df_db_ranked[\"INDEX\"].apply(int) == index, \"CORTEX_COUNT_IN_\"+column_name_base].values[0])\n",
    "        non_relevant_inject.append(df_db_ranked.loc[df_db_ranked[\"INDEX\"].apply(int) == index, \"INJECT_COUNT_IN_\"+column_name_base].values[0])\n",
    "        non_relevant_method.append(df_db_ranked.loc[df_db_ranked[\"INDEX\"].apply(int) == index, \"METHOD_COUNT_IN_\"+column_name_base].values[0])\n",
    "        non_relevant_connectivity.append(df_db_ranked.loc[df_db_ranked[\"INDEX\"].apply(int) == index, \"CONNECT_COUNT_IN_\"+column_name_base].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the 8 dot plots of the species_related, tc_ct_related, thalam_related, cortex_related, method_related, connectivity_related of YESs and NOs of the test data set in 2 rows in the same figure\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "plt.subplot(4, 2, 1)\n",
    "plt.plot(relvant_index_list, relevant_species, 'ro', label=\"YES\")\n",
    "plt.plot(non_relevant_index_list, non_relevant_species, 'bo', label=\"NO\")\n",
    "plt.xlabel(\"Index\")\n",
    "plt.ylabel(\"Species Related\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(4, 2, 2)\n",
    "plt.plot(relvant_index_list, relevant_other_species, 'ro', label=\"YES\")\n",
    "plt.plot(non_relevant_index_list, non_relevant_other_species, 'bo', label=\"NO\")\n",
    "plt.xlabel(\"Index\")\n",
    "plt.ylabel(\"Other Species Related\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(4, 2, 3)\n",
    "plt.plot(relvant_index_list, relevant_tc_ct, 'ro', label=\"YES\")\n",
    "plt.plot(non_relevant_index_list, non_relevant_tc_ct, 'bo', label=\"NO\")\n",
    "plt.xlabel(\"Index\")\n",
    "plt.ylabel(\"TC_CT Related\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(4, 2, 4)\n",
    "plt.plot(relvant_index_list, relevant_thalam, 'ro', label=\"YES\")\n",
    "plt.plot(non_relevant_index_list, non_relevant_thalam, 'bo', label=\"NO\")\n",
    "plt.xlabel(\"Index\")\n",
    "plt.ylabel(\"Thalam Related\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(4, 2, 5)\n",
    "plt.plot(relvant_index_list, relevant_cortex, 'ro', label=\"YES\")\n",
    "plt.plot(non_relevant_index_list, non_relevant_cortex, 'bo', label=\"NO\")\n",
    "plt.xlabel(\"Index\")\n",
    "plt.ylabel(\"Cortex Related\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(4, 2, 6)\n",
    "plt.plot(relvant_index_list, relevant_cortex, 'ro', label=\"YES\")\n",
    "plt.plot(non_relevant_index_list, non_relevant_cortex, 'bo', label=\"NO\")\n",
    "plt.xlabel(\"Index\")\n",
    "plt.ylabel(\"Inject Related\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(4, 2, 7)\n",
    "plt.plot(relvant_index_list, relevant_method, 'ro', label=\"YES\")\n",
    "plt.plot(non_relevant_index_list, non_relevant_method, 'bo', label=\"NO\")\n",
    "plt.xlabel(\"Index\")\n",
    "plt.ylabel(\"Method Related\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(4, 2, 8)\n",
    "plt.plot(relvant_index_list, relevant_connectivity, 'ro', label=\"YES\")\n",
    "plt.plot(non_relevant_index_list, non_relevant_connectivity, 'bo', label=\"NO\")\n",
    "plt.xlabel(\"Index\")\n",
    "plt.ylabel(\"Connectivity Related\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49d5dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the dot plot of the relevance_index of YESs and NOs of the test data set\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(relvant_index_list, relevant_relevance_index_list, 'ro', label=\"YES\")\n",
    "plt.plot(non_relevant_index_list, non_relevant_relevance_index_list, 'bo', label=\"NO\")\n",
    "plt.xlabel(\"Index\")\n",
    "plt.ylabel(\"Relevance Index\")\n",
    "plt.legend()\n",
    "\n",
    "# add labels for the relevant index points\n",
    "for i, index in enumerate(relvant_index_list):\n",
    "    plt.text(index, relevant_relevance_index_list[i]+0.1, str(index), color='black', fontsize=10)\n",
    "\n",
    "# # add labels for the relevant index points\n",
    "# for i, index in enumerate(non_relevant_index_list):\n",
    "#     plt.text(index, non_relevant_relevance_index_list[i], str(index), color='black', fontsize=10)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_relevance_index_index = 3683"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(relvant_index)):\n",
    "    # print(relvant_index[i], relevant_relevance_index_list[i])\n",
    "    # print(relevant_relevance_index_list)\n",
    "# min_relev_index = min(relevant_relevance_index_list)\n",
    "\n",
    "for ind in df_db_ranked.index:\n",
    "    if df_db_ranked.at[ind, \"INDEX\"] == min_relevance_index_index:\n",
    "        min_relevance_index_ind = ind\n",
    "        break \n",
    "# print(min_relev_index_ind)\n",
    "\n",
    "min_relev_index_num = min_relevance_index_ind  + 1\n",
    "num = math.ceil(min_relev_index_num * 1.3)\n",
    "\n",
    "threshold_index = df_db_ranked.at[num-1, 'INDEX']\n",
    "print(f\"The index with the minimum relevance index: {min_relevance_index_index}\")\n",
    "print(f\"The number of articles with relevance index larger or equal than {min_relevance_index_index}: {min_relev_index_num}\")\n",
    "print(f\"The index of the article with the threshold relevance index: {threshold_index}\")\n",
    "print(f\"The number of articles to manually check is {num}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6260d21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_values_uniformly(data, n):\n",
    "    \"\"\"Pick up `n` values uniformly from `data`.\"\"\"\n",
    "    if n <= 0:\n",
    "        return []\n",
    "\n",
    "    # Determine the range of the data\n",
    "    min_val, max_val = min(data), max(data)\n",
    "\n",
    "    threshold = (max_val - min_val) / n / 2\n",
    "\n",
    "    # If n is 1, just return the midpoint\n",
    "    if n == 1:\n",
    "        return [(min_val + max_val) / 2]\n",
    "\n",
    "    # Calculate the interval size\n",
    "    interval = (max_val - min_val) / (n - 1)\n",
    "\n",
    "    # Get the uniform values\n",
    "    return [min_val + i * interval for i in range(n)], threshold\n",
    "\n",
    "# data = [1, 3, 5, 2, 8, 10, 2]\n",
    "n = 5\n",
    "density_display_index, thres = pick_values_uniformly(relevant_relevance_index_list + non_relevant_relevance_index_list, n)\n",
    "print(density_display_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73da3b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Printing the length of lists\n",
    "print(\"Numer of relevant literature:\", len(relevant_relevance_index_list))\n",
    "print(\"Number of not relevant literature:\", len(non_relevant_relevance_index_list))\n",
    "print()\n",
    "\n",
    "# Create a DataFrame for plotting\n",
    "df = pd.DataFrame({'Relevance Index': relevant_relevance_index_list + non_relevant_relevance_index_list, \n",
    "                   'Label': ['Relevant'] * len(relevant_relevance_index_list) + ['Not Relevant'] * len(non_relevant_relevance_index_list)})\n",
    "\n",
    "# Draw the violin plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = sns.violinplot(x='Label', y='Relevance Index', data=df, bw='scott', cut=0)\n",
    "\n",
    "relevance_indices = density_display_index  # Replace with your relevance indices\n",
    "\n",
    "threshold = thres  # Adjust this based on your desired range around the relevance index\n",
    "\n",
    "for index in relevance_indices:\n",
    "    ax.axhline(index, color='gray', linestyle='--')\n",
    "    \n",
    "    for i, label in enumerate(df['Label'].unique()):\n",
    "        # Filter data points close to the current relevance index\n",
    "        close_points = df[(df['Label'] == label) & (np.abs(df['Relevance Index'] - index) < threshold)]\n",
    "        density = len(close_points)\n",
    "        \n",
    "        ax.text(i, index + 0.1, str(density), ha='center', va='center', color='red', fontsize=9)  # adjust the vertical offset (0.1 here) as necessary\n",
    "\n",
    "plt.title('Distribution of Relevance Index')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79b8678",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "# Check the equality of variances\n",
    "var_relevant = np.var(relevant_relevance_index_list)\n",
    "var_non_relevant = np.var(non_relevant_relevance_index_list)\n",
    "print('Variance of relevant:', var_relevant)\n",
    "print('Variance of non-relevant:', var_non_relevant)\n",
    "print(var_relevant/var_non_relevant)\n",
    "# statistic, p_value = stats.levene(relevant_relevance_index_list, non_relevant_relevance_index_list)\n",
    "\n",
    "# # Print the results\n",
    "# print('Levene test statistic:', statistic)\n",
    "# print('p-value:', p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7fc9ccf",
   "metadata": {},
   "source": [
    "<h3> Next step: manually read papers and find all actually related literature </h3>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
