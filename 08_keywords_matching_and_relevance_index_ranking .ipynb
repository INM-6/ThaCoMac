{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dea1cce5-4f07-4bd7-8ca3-5f6fa51254d0",
   "metadata": {},
   "source": [
    "# Keywords matching and relevance index ranking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5a61c5-f8c6-418a-b450-cdea0378ddab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from nltk import ngrams\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726b12c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import internal modules\n",
    "import file_path_management as fpath\n",
    "import public_library as plib\n",
    "import parameters as params\n",
    "import dataframe_columns as df_col"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489f0451",
   "metadata": {},
   "source": [
    "## Predefined fucntions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(elem):\n",
    "    return math.log(1 + elem)\n",
    "# # --------------------start of test code--------------------\n",
    "# elem = 0\n",
    "# print(transform(10))\n",
    "# # ---------------------end of test code---------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02fb81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relevance_index(counts_dict):\n",
    "    relevance_index = 0\n",
    "    \n",
    "    for key in counts_dict.keys():\n",
    "        relevance_index += transform(counts_dict[key]) * (params.ranking_kw_groups_weights[key])\n",
    "    \n",
    "    return relevance_index\n",
    "# --------------------start of test code--------------------\n",
    "# keywords_count_or_fre = {}\n",
    "# index = calcul_related(keywords_count_or_fre, params.on_topic_kws_weights)\n",
    "# print(index)\n",
    "# ---------------------end of test code---------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edde53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_relevance_index(db_count_path, db_relevance_index_path, rank_by):\n",
    "    df = pd.read_csv(db_count_path, header=0, sep=\"\\t\")\n",
    "    \n",
    "    if rank_by == 'tak':\n",
    "        column_name = '_COUNT_IN_TAK'\n",
    "    elif rank_by == '500':\n",
    "        column_name = '_COUNT_IN_500'\n",
    "    elif rank_by == 'full_text':\n",
    "        column_name = '_COUNT_IN_FULL_TEXT'\n",
    "        \n",
    "    count_dict = {}\n",
    "    \n",
    "    for ind in df.index:\n",
    "        for key in params.ranking_kw_groups.keys():\n",
    "            # if key == 'INJECT' or 'METHOD':\n",
    "            #     value = df.at[ind, key+'_COUNT_IN_FULL_TEXT']\n",
    "            # else:\n",
    "            #     value = df.at[ind, key+column_name]\n",
    "            value = df.at[ind, key+column_name]\n",
    "            \n",
    "            if value != value:\n",
    "                value = 0\n",
    "            count_dict[key] = int(value)\n",
    "        # print(count_dict)\n",
    "\n",
    "        relev_index = relevance_index(count_dict)\n",
    "        \n",
    "        df.at[ind, \"RELEVANCE_INDEX\"] = relev_index\n",
    "\n",
    "        # line_number_in_csv = ind + 1\n",
    "        # print(\"Line number:\", line_number_in_csv, \" INDEX:\", int(df.at[ind, \"INDEX\"]))\n",
    "    \n",
    "    df.columns = df_col.db_ranked_columns\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    df.to_csv(db_relevance_index_path, header=True, index=False, sep=\"\\t\")\n",
    "    \n",
    "    # print(\"Weighting and ranking the potentially related literature succeded!\")\n",
    "    # print(\"Enjoy reading!\")\n",
    "# --------------------start of test code--------------------\n",
    "# input_path = fpath.poten_litera_db_kw_count\n",
    "# output_path = fpath.poten_litera_db_ranked\n",
    "# rank(input_path, output_path, params.ranking_params_weights)\n",
    "# ---------------------end of test code---------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_and_save(input_path, output_path):\n",
    "    plib.clear_file(output_path)\n",
    "    \n",
    "    # sort\n",
    "    df_to_rank = pd.read_csv(input_path, header=0, sep=\"\\t\")\n",
    "\n",
    "    # sort by relevance index\n",
    "    df_to_rank.sort_values(by=['RELEVANCE_INDEX'], ascending=False, inplace=True)\n",
    "        \n",
    "    df_to_rank.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    df_to_rank.to_csv(output_path, header=True, index=False, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e562971",
   "metadata": {},
   "source": [
    "## Main program:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Calculate relevance index and rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_by = 'tak'\n",
    "# rank_by = '500'\n",
    "# rank_by = 'full_text'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_path = fpath.poten_litera_db_kw_count\n",
    "# relevance_index_path = fpath.poten_litera_db_relevance_index\n",
    "# plib.clear_file(relevance_index_path)\n",
    "\n",
    "# # compute relevance index\n",
    "# compute_relevance_index(input_path, relevance_index_path, rank_by)\n",
    "\n",
    "# # rank\n",
    "# if rank_by == 'tak':\n",
    "#     # rank by tak    \n",
    "#     rank_and_save(relevance_index_path, fpath.poten_litera_db_ranked_by_tak)\n",
    "# elif rank_by == '500':\n",
    "#     # rank by 500    \n",
    "#     rank_and_save(relevance_index_path, fpath.poten_litera_db_ranked_by_500)\n",
    "# elif rank_by == 'full_text':\n",
    "#     # rank by full text\n",
    "#     rank_and_save(relevance_index_path, fpath.poten_litera_db_ranked_by_full_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36685b74",
   "metadata": {},
   "source": [
    "### 2. Ranking results analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e384b1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the labeled testing set\n",
    "test_path = fpath.poten_litera_testing_set_1000_labeled\n",
    "df_test = pd.read_csv(test_path, header=0, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize lists of the count of keywords in the respective lists\n",
    "\n",
    "# relevant group\n",
    "R_species = []\n",
    "R_other_species = []\n",
    "R_tc_ct = []\n",
    "R_thalam = []\n",
    "R_cortex = []\n",
    "R_inject = []\n",
    "R_method = []\n",
    "R_connectivity = []\n",
    "\n",
    "# index list of the relevant group\n",
    "R_index_list = []\n",
    "# relevance index list of the relevant group\n",
    "R_relevance_index_list = []\n",
    "\n",
    "# Irrelevant group\n",
    "IR_species = []\n",
    "IR_other_species = []\n",
    "IR_tc_ct = []\n",
    "IR_thalam = []\n",
    "IR_cortex = []\n",
    "IR_inject = []\n",
    "IR_method = []\n",
    "IR_connectivity = []\n",
    "\n",
    "# index list of the irrelevant group\n",
    "IR_index_list = []\n",
    "# relevance index list of the irrelevant group\n",
    "IR_relevance_index_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8aa55d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# record the count of keywords in the respective lists\n",
    "if rank_by == 'tak':\n",
    "    # rank by tak\n",
    "    df_db_ranked = pd.read_csv(fpath.poten_litera_db_ranked_by_tak, header=0, sep='\\t')\n",
    "    column_name_base = \"TAK\"\n",
    "elif rank_by == '500':\n",
    "    # rank by 500\n",
    "    df_db_ranked = pd.read_csv(fpath.poten_litera_db_ranked_by_500, header=0, sep='\\t')\n",
    "    column_name_base = \"500\"\n",
    "elif rank_by == 'full_text':\n",
    "    # rank by full_text\n",
    "    df_db_ranked = pd.read_csv(fpath.poten_litera_db_ranked_by_full_text, header=0, sep='\\t')\n",
    "    column_name_base = \"FULL_TEXT\"\n",
    "\n",
    "for ind in df_test.index:\n",
    "    index = int(df_test.at[ind, \"INDEX\"])\n",
    "\n",
    "    if df_test.at[ind, \"RELEVANT?(Y/N/MB/NA)\"] == \"Y\":\n",
    "        R_index_list.append(index)\n",
    "        R_relevance_index_list.append(df_db_ranked.loc[df_db_ranked[\"INDEX\"].apply(int) == index, \"RELEVANCE_INDEX\"].values[0])\n",
    "        \n",
    "        R_species.append(df_db_ranked.loc[df_db_ranked[\"INDEX\"].apply(int) == index, \"MACAQUE_COUNT_IN_\"+column_name_base].values[0])\n",
    "        R_other_species.append(df_db_ranked.loc[df_db_ranked[\"INDEX\"].apply(int) == index, \"OTHER_SPIECIES_COUNT_IN_\"+column_name_base].values[0])\n",
    "        R_tc_ct.append(df_db_ranked.loc[df_db_ranked[\"INDEX\"].apply(int) == index, \"TC_CT_COUNT_IN_\"+column_name_base].values[0])\n",
    "        R_thalam.append(df_db_ranked.loc[df_db_ranked[\"INDEX\"].apply(int) == index, \"THALAM_COUNT_IN_\"+column_name_base].values[0])\n",
    "        R_cortex.append(df_db_ranked.loc[df_db_ranked[\"INDEX\"].apply(int) == index, \"CORTEX_COUNT_IN_\"+column_name_base].values[0])\n",
    "        R_inject.append(df_db_ranked.loc[df_db_ranked[\"INDEX\"].apply(int) == index, \"INJECT_COUNT_IN_\"+column_name_base].values[0])\n",
    "        R_method.append(df_db_ranked.loc[df_db_ranked[\"INDEX\"].apply(int) == index, \"METHOD_COUNT_IN_\"+column_name_base].values[0])\n",
    "        R_connectivity.append(df_db_ranked.loc[df_db_ranked[\"INDEX\"].apply(int) == index, \"CONNECT_COUNT_IN_\"+column_name_base].values[0])\n",
    "    else:\n",
    "        IR_index_list.append(index)\n",
    "        IR_relevance_index_list.append(df_db_ranked.loc[df_db_ranked[\"INDEX\"].apply(int) == index, \"RELEVANCE_INDEX\"].values[0])\n",
    "        \n",
    "        IR_species.append(df_db_ranked.loc[df_db_ranked[\"INDEX\"].apply(int) == index, \"MACAQUE_COUNT_IN_\"+column_name_base].values[0])\n",
    "        IR_other_species.append(df_db_ranked.loc[df_db_ranked[\"INDEX\"].apply(int) == index, \"OTHER_SPIECIES_COUNT_IN_\"+column_name_base].values[0])\n",
    "        IR_tc_ct.append(df_db_ranked.loc[df_db_ranked[\"INDEX\"].apply(int) == index, \"TC_CT_COUNT_IN_\"+column_name_base].values[0])\n",
    "        IR_thalam.append(df_db_ranked.loc[df_db_ranked[\"INDEX\"].apply(int) == index, \"THALAM_COUNT_IN_\"+column_name_base].values[0])\n",
    "        IR_cortex.append(df_db_ranked.loc[df_db_ranked[\"INDEX\"].apply(int) == index, \"CORTEX_COUNT_IN_\"+column_name_base].values[0])\n",
    "        IR_inject.append(df_db_ranked.loc[df_db_ranked[\"INDEX\"].apply(int) == index, \"INJECT_COUNT_IN_\"+column_name_base].values[0])\n",
    "        IR_method.append(df_db_ranked.loc[df_db_ranked[\"INDEX\"].apply(int) == index, \"METHOD_COUNT_IN_\"+column_name_base].values[0])\n",
    "        IR_connectivity.append(df_db_ranked.loc[df_db_ranked[\"INDEX\"].apply(int) == index, \"CONNECT_COUNT_IN_\"+column_name_base].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# whether to transfer the counts using, for example, log function\n",
    "tranform = True\n",
    "# transform = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform the transformation if needed\n",
    "if tranform:\n",
    "    # relevant group\n",
    "    R_species = [transform(elem) for elem in R_species]\n",
    "    R_other_species = [transform(elem) for elem in R_other_species]\n",
    "    R_tc_ct = [transform(elem) for elem in R_tc_ct]\n",
    "    R_thalam = [transform(elem) for elem in R_thalam]\n",
    "    R_cortex = [transform(elem) for elem in R_cortex]\n",
    "    R_inject = [transform(elem) for elem in R_inject]\n",
    "    R_method = [transform(elem) for elem in R_method]\n",
    "    R_connectivity = [transform(elem) for elem in R_connectivity]\n",
    "\n",
    "    # irrelevant group\n",
    "    IR_species = [transform(elem) for elem in IR_species]\n",
    "    IR_other_species = [transform(elem) for elem in IR_other_species]\n",
    "    IR_tc_ct = [transform(elem) for elem in IR_tc_ct]\n",
    "    IR_thalam = [transform(elem) for elem in IR_thalam]\n",
    "    IR_cortex = [transform(elem) for elem in IR_cortex]\n",
    "    IR_inject = [transform(elem) for elem in IR_inject]\n",
    "    IR_method = [transform(elem) for elem in IR_method]\n",
    "    IR_connectivity = [transform(elem) for elem in IR_connectivity]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the 8 dot plots\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "plt.subplot(4, 2, 1)\n",
    "plt.plot(R_index_list, R_species, 'ro', label=\"YES\")\n",
    "plt.plot(IR_index_list, IR_species, 'bo', label=\"NO\")\n",
    "plt.xlabel(\"Index\")\n",
    "plt.ylabel(\"Species Related\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(4, 2, 2)\n",
    "plt.plot(R_index_list, R_other_species, 'ro', label=\"YES\")\n",
    "plt.plot(IR_index_list, IR_other_species, 'bo', label=\"NO\")\n",
    "plt.xlabel(\"Index\")\n",
    "plt.ylabel(\"Other Species Related\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(4, 2, 3)\n",
    "plt.plot(R_index_list, R_tc_ct, 'ro', label=\"YES\")\n",
    "plt.plot(IR_index_list, IR_tc_ct, 'bo', label=\"NO\")\n",
    "plt.xlabel(\"Index\")\n",
    "plt.ylabel(\"TC_CT Related\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(4, 2, 4)\n",
    "plt.plot(R_index_list, R_thalam, 'ro', label=\"YES\")\n",
    "plt.plot(IR_index_list, IR_thalam, 'bo', label=\"NO\")\n",
    "plt.xlabel(\"Index\")\n",
    "plt.ylabel(\"Thalam Related\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(4, 2, 5)\n",
    "plt.plot(R_index_list, R_cortex, 'ro', label=\"YES\")\n",
    "plt.plot(IR_index_list, IR_cortex, 'bo', label=\"NO\")\n",
    "plt.xlabel(\"Index\")\n",
    "plt.ylabel(\"Cortex Related\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(4, 2, 6)\n",
    "plt.plot(R_index_list, R_cortex, 'ro', label=\"YES\")\n",
    "plt.plot(IR_index_list, IR_cortex, 'bo', label=\"NO\")\n",
    "plt.xlabel(\"Index\")\n",
    "plt.ylabel(\"Inject Related\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(4, 2, 7)\n",
    "plt.plot(R_index_list, R_method, 'ro', label=\"YES\")\n",
    "plt.plot(IR_index_list, IR_method, 'bo', label=\"NO\")\n",
    "plt.xlabel(\"Index\")\n",
    "plt.ylabel(\"Method Related\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(4, 2, 8)\n",
    "plt.plot(R_index_list, R_connectivity, 'ro', label=\"YES\")\n",
    "plt.plot(IR_index_list, IR_connectivity, 'bo', label=\"NO\")\n",
    "plt.xlabel(\"Index\")\n",
    "plt.ylabel(\"Connectivity Related\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49d5dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the dot plot of the relevance_index of YESs and NOs of the test data set\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(R_index_list, R_relevance_index_list, 'ro', label=\"YES\")\n",
    "plt.plot(IR_index_list, IR_relevance_index_list, 'bo', label=\"NO\")\n",
    "plt.xlabel(\"Index\")\n",
    "plt.ylabel(\"Relevance Index\")\n",
    "plt.legend()\n",
    "\n",
    "# add labels for the relevant index points\n",
    "for i, index in enumerate(R_index_list):\n",
    "    plt.text(index, R_relevance_index_list[i]+0.1, str(index), color='black', fontsize=10)\n",
    "\n",
    "# # add labels for the relevant index points\n",
    "# for i, index in enumerate(IR_index_list):\n",
    "#     plt.text(index, IR_relevance_index_list[i], str(index), color='black', fontsize=10)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min_relevance_index_index = \n",
    "\n",
    "# for i in range(len(relvant_index_list)):\n",
    "#     print(relvant_index_list[i], relevant_relevance_index_list[i])\n",
    "# print(relevant_relevance_index_list)\n",
    "\n",
    "min_relevance_index_index = R_index_list[R_relevance_index_list.index(min(R_relevance_index_list))]\n",
    "\n",
    "for ind in df_db_ranked.index:\n",
    "    if df_db_ranked.at[ind, \"INDEX\"] == min_relevance_index_index:\n",
    "        min_relevance_index_ind = ind\n",
    "        break \n",
    "\n",
    "min_relev_index_num = min_relevance_index_ind  + 1\n",
    "num = math.ceil(min_relev_index_num * 1.2)\n",
    "threshold_index = df_db_ranked.at[num-1, 'INDEX']\n",
    "\n",
    "print(f\"The index with the minimum relevance index: {min_relevance_index_index}\")\n",
    "print(f\"The number of articles with relevance index larger or equal than that of {min_relevance_index_index}: {min_relev_index_num}\")\n",
    "print(f\"The index of the article with the threshold relevance index: {threshold_index}\")\n",
    "print(f\"The number of articles to manually check is {num}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6260d21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_values_uniformly(data, n):\n",
    "    \"\"\"Pick up `n` values uniformly from `data`.\"\"\"\n",
    "    if n < 1:\n",
    "        return []\n",
    "\n",
    "    # Determine the range of the data\n",
    "    min_val, max_val = min(data), max(data)\n",
    "\n",
    "    threshold = (max_val - min_val) / n / 2\n",
    "\n",
    "    # If n is 1, just return the midpoint\n",
    "    if n == 1:\n",
    "        return [(min_val + max_val) / 2]\n",
    "\n",
    "    # Calculate the interval size\n",
    "    interval = (max_val - min_val) / (n - 1)\n",
    "\n",
    "    # Get the uniform values\n",
    "    return [min_val + i * interval for i in range(n)], threshold\n",
    "\n",
    "# data = [1, 3, 5, 2, 8, 10, 2]\n",
    "n = 5\n",
    "density_display_index, thres = pick_values_uniformly(R_relevance_index_list + IR_relevance_index_list, n)\n",
    "# print(density_display_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73da3b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the distribution of the relevance group and the non-relevance group as violin plots\n",
    "\n",
    "# Printing the length of lists\n",
    "print(\"Numer of relevant literature:\", len(R_relevance_index_list))\n",
    "print(\"Number of not relevant literature:\", len(IR_relevance_index_list))\n",
    "print()\n",
    "\n",
    "# Create a DataFrame for plotting\n",
    "df = pd.DataFrame({'Relevance Index': R_relevance_index_list + IR_relevance_index_list, \n",
    "                   'Label': ['Relevant'] * len(R_relevance_index_list) + ['Not Relevant'] * len(IR_relevance_index_list)})\n",
    "\n",
    "# Draw the violin plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = sns.violinplot(x='Label', y='Relevance Index', data=df, bw='scott', cut=0)\n",
    "\n",
    "# relevance_indices = density_display_index  # Replace with your relevance indices\n",
    "\n",
    "# threshold = thres  # Adjust this based on your desired range around the relevance index\n",
    "\n",
    "# for index in relevance_indices:\n",
    "#     ax.axhline(index, color='gray', linestyle='--')\n",
    "    \n",
    "#     for i, label in enumerate(df['Label'].unique()):\n",
    "#         # Filter data points close to the current relevance index\n",
    "#         close_points = df[(df['Label'] == label) & (np.abs(df['Relevance Index'] - index) < threshold)]\n",
    "#         density = len(close_points)\n",
    "        \n",
    "#         ax.text(i, index + 0.1, str(density), ha='center', va='center', color='red', fontsize=9)  # adjust the vertical offset (0.1 here) as necessary\n",
    "\n",
    "plt.title('Distribution of Relevance Index')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79b8678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the equality of variances\n",
    "var_relevant = np.var(R_relevance_index_list)\n",
    "var_non_relevant = np.var(IR_relevance_index_list)\n",
    "print('Variance of RELEVANCE_INDEX of the relevant group:', var_relevant)\n",
    "print('Variance of RELEVANCE_INDEX of the non-relevant group:', var_non_relevant)\n",
    "print('Ratio of the above variance:', var_relevant/var_non_relevant)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Prepare the final list of articles to manually read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the DataFrame from a CSV file\n",
    "df = pd.read_csv(fpath.poten_litera_db_ranked_by_tak, header=0, sep='\\t')  # Replace with your CSV file path\n",
    "\n",
    "index_above_threshold = []\n",
    "index_below_threshold = []\n",
    "\n",
    "# flag of being relevant\n",
    "flag = True\n",
    "# Iterate through the DataFrame and add the index to the list\n",
    "for ind, row in df.iterrows():\n",
    "    index = int(row['INDEX'])\n",
    "    \n",
    "    if not flag and (index == min_relevance_index_index):\n",
    "        raise Exception(\"The index of the article with the threshold relevance index is not unique!\")\n",
    "    \n",
    "    if index == min_relevance_index_index:\n",
    "        index_above_threshold.append(index)\n",
    "        flag = False\n",
    "    else: \n",
    "        if flag:\n",
    "            index_above_threshold.append(index)\n",
    "        else:\n",
    "            index_below_threshold.append(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the index of the articles with 'inject' in the full text and articles without full text\n",
    "for article_index in index_below_threshold:\n",
    "    full_text_file_path = os.path.join(fpath.text_folder, str(article_index), '.text')\n",
    "    \n",
    "    # if the full text file exists\n",
    "    if os.path.exists(full_text_file_path):\n",
    "        with open(full_text_file_path, 'r', encoding='ascii') as file:\n",
    "            # Read the contents of the file\n",
    "            text = file.read()\n",
    "        text = plib.process_text(text, lower=True)\n",
    "        \n",
    "        if 'inject' in text or len(text.split() <= 2000):\n",
    "            index_above_threshold.append(article_index)\n",
    "    else:\n",
    "        index_above_threshold.append(article_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the index_above_threshold\n",
    "with open(fpath.article_list_to_manually_read, 'w') as file:\n",
    "    # Convert each number to string and join them with commas\n",
    "    numbers_str = ','.join(map(str, index_above_threshold))\n",
    "    \n",
    "    # Write the string to the file\n",
    "    file.write(numbers_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7fc9ccf",
   "metadata": {},
   "source": [
    "<h3> Next step: manually read papers and find all actually related literature </h3>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
