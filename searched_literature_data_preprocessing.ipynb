{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Searched literature data preprocessing </h2> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-08 00:29:15 Didis-MacBook-Pro.local metapub.config[12515] WARNING NCBI_API_KEY was not set.\n"
     ]
    }
   ],
   "source": [
    "# import internal .py modules\n",
    "import file_path_management as fpath\n",
    "import public_library as plib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import random\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Parameters: </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns of file: potential_related_literature.csv\n",
    "columns = [\"DOI\", \"PMID\", \"PMCID\", \"Title\", \"full_text_url\", \"full_text_source\", \"pdf_url\", \"pdf_source\"]\n",
    "# e.g., [\"10.1113/JP282626\", \"35851953\", \"PMC10087288\", \n",
    "#        \"Cortico-thalamocortical interactions for learning, memory and decision-making\",\n",
    "#        \"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10087288/\", \"PMC\",\n",
    "#        \"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10087288/pdf/TJP-601-25.pdf\", \"PMC\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Predefined fucntions: </h3> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_pubmed(source_path, output_path, start, end):\n",
    "    print(\"Starting preprocessing search results from PubMed...\")\n",
    "\n",
    "    df = pd.read_csv(source_path, sep=',')\n",
    "    df = df[[\"DOI\", \"PMID\", \"PMCID\", \"Title\"]]\n",
    "    \n",
    "    for ind in range(start, end):\n",
    "        # sleep to avoid to be blocked\n",
    "        time.sleep(random.randint(3, 5))\n",
    "        # if(ind%50 == 0):\n",
    "        #     time.sleep(random.randint(10,15)*10)\n",
    "        \n",
    "        # request the webpage\n",
    "        # the columns PMID, Title don't contain np.nan\n",
    "        pmid = str(df[\"PMID\"][ind]).strip()\n",
    "        url = \"https://pubmed.ncbi.nlm.nih.gov/\" + pmid + \"/\"\n",
    "        # proxies = plib.get_proxies()\n",
    "        soup = plib.request_webpage(url)\n",
    "        # print(soup)\n",
    "        \n",
    "        # get pmcid\n",
    "        if df[\"PMCID\"][ind] != df[\"PMCID\"][ind]: # PMCID is np.nan\n",
    "            try:\n",
    "                pmcid = soup.find_all(\"span\", {\"class\": \"identifier pmc\"})[0].find_all(\"a\", {\"class\": \"id-link\"})[0].get_text().strip()\n",
    "            except:\n",
    "                pmcid = np.nan\n",
    "        else: # PMCID is not np.nan\n",
    "            pmcid = str(df[\"PMCID\"][ind]).strip()\n",
    "        # print(pmcid)\n",
    "\n",
    "        # get doi\n",
    "        if df[\"DOI\"][ind] != df[\"DOI\"][ind]: # DOI is np.nan\n",
    "            try:\n",
    "                doi = soup.find_all(\"span\", {\"class\": \"identifier doi\"})[0].find_all(\"a\", {\"class\": \"id-link\"})[0].get_text().strip()\n",
    "            except:\n",
    "                doi  = np.nan\n",
    "        else: # DOI is not np.nan\n",
    "            doi = str(df[\"DOI\"][ind]).strip()\n",
    "        # print(doi)\n",
    "\n",
    "        # get full_text_url, full_text_source\n",
    "        if pmcid == pmcid: # pmcid is not np.nan\n",
    "            full_text_url = \"https://www.ncbi.nlm.nih.gov/pmc/articles/\" + pmcid + \"/\"\n",
    "            full_text_source = \"PMC\"\n",
    "        else: # pmcid is np.nan\n",
    "            # PMC does not include this paper\n",
    "            try:\n",
    "                full_text_url = soup.find_all(\"div\", {\"class\": \"full-text-links-list\"})[0].find_all(\"a\", {\"class\": \"link-item dialog-focus\"})[0][\"href\"].strip()\n",
    "                full_text_source = soup.find_all(\"div\", {\"class\": \"full-text-links-list\"})[0].find_all(\"a\", {\"class\": \"link-item dialog-focus\"})[0][\"data-ga-action\"].strip()\n",
    "            except:\n",
    "                full_text_url = np.nan\n",
    "                full_text_source = np.nan\n",
    "        # print(full_text_url)\n",
    "        # print(full_text_source)\n",
    "        \n",
    "        # get pdf_url, pdf_source\n",
    "        pdf_url = np.nan\n",
    "        pdf_source = np.nan\n",
    "                \n",
    "        columns = [\"DOI\", \"PMID\", \"PMCID\", \"Title\", \"full_text_url\", \"full_text_source\", \"pdf_url\", \"pdf_source\"]\n",
    "        row = {\n",
    "            \"DOI\": [doi],\n",
    "            \"PMID\": [pmid],\n",
    "            \"PMCID\": [pmcid],\n",
    "            \"Title\": [str(df[\"Title\"][ind]).strip()],\n",
    "            \"full_text_url\": [full_text_url],\n",
    "            \"full_text_source\": [full_text_source],\n",
    "            \"pdf_url\": [pdf_url],\n",
    "            \"pdf_source\": [pdf_source]\n",
    "        }\n",
    "        # print(row)\n",
    "\n",
    "        if not plib.add_row_to_csv(output_path, row, columns):\n",
    "            print(\"Error detected when adding a row to csv!\")\n",
    "        \n",
    "        print(ind)\n",
    "# --------------------start of test code--------------------\n",
    "# source_path = fpath.poten_litera_pubmed\n",
    "# output_path = fpath.poten_litera_pubmed_processed\n",
    "# # plib.clear_file(output_path)\n",
    "\n",
    "# df = pd.read_csv(source_path, sep=',')\n",
    "# print(df.shape)\n",
    "# df = df[[\"DOI\", \"PMID\", \"PMCID\", \"Title\"]]\n",
    "# print(df.head(3))\n",
    "# print(df.shape)\n",
    "\n",
    "# print(df[\"DOI\"].isnull().values.any())\n",
    "# print(df[\"PMID\"].isnull().values.any())\n",
    "# print(df[\"PMCID\"].isnull().values.any())\n",
    "# print(df[\"Title\"].isnull().values.any())\n",
    "# # True, False, True, Flase\n",
    "# # PMID, Title don't contain np.nan\n",
    "# # DOI, PMCID contain np.nan\n",
    "# # we need to fill in what are missing\n",
    "# ---------------------end of test code---------------------\n",
    "\n",
    "# --------------------start of test code--------------------\n",
    "# preprocess_pubmed(source_path, output_path, start, end)\n",
    "# ---------------------end of test code---------------------\n",
    "\n",
    "# --------------------start of test code--------------------\n",
    "# df = pd.read_csv(output_path, header=None, sep=',')\n",
    "# print(df.head(3))\n",
    "# ---------------------end of test code---------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_webofscience(source_path, output_path, start, end):\n",
    "    print(\"Starting preprocessing search results from Web of Science...\")\n",
    "    \n",
    "    df = pd.read_csv(source_path, sep=\";\")\n",
    "    df = df[[\"DOI\", \"Pubmed Id\", \"Article Title\"]]\n",
    "\n",
    "    for ind in range(start, end):\n",
    "        # sleep to avoid to be blocked\n",
    "        time.sleep(random.randint(3, 5))\n",
    "        # if(ind%50 == 0):\n",
    "        #     time.sleep(random.randint(10,15)*10)\n",
    "        \n",
    "        # the columns Article Title don't contain np.nan\n",
    "        # the columns DOI and PMID might contain np.nan\n",
    "        # get pmid, doi\n",
    "        if df[\"Pubmed Id\"][ind] != df[\"Pubmed Id\"][ind]: # Pubmed Id is np.nan\n",
    "            if df[\"DOI\"][ind] != df[\"DOI\"][ind]: # DOI is np.nan\n",
    "                doi = np.nan\n",
    "                pmid = np.nan\n",
    "            else: # DOI is not np.nan\n",
    "                doi = str(df[\"DOI\"][ind]).strip()\n",
    "                pmid = plib.doi2pmid(doi)\n",
    "        else: # Pubmed Id is not np.nan\n",
    "            pmid = str(int(df[\"Pubmed Id\"][ind])).strip()\n",
    "            if df[\"DOI\"][ind] != df[\"DOI\"][ind]: # DOI is not np.nan\n",
    "                doi = plib.pmid2doi(pmid)\n",
    "            else: # DOI is not np.nan\n",
    "                doi = str(df[\"DOI\"][ind]).strip()\n",
    "        \n",
    "        # get pmcid, full_text_url, full_text_source\n",
    "        if pmid != pmid: # pmid is np.nan\n",
    "            pmcid = np.nan\n",
    "            if doi != doi: # doi is np.nan\n",
    "                full_text_url = np.nan\n",
    "                full_text_source = np.nan\n",
    "            else:\n",
    "                full_text_url = \"https://doi.org/\" + str(doi).strip()\n",
    "                full_text_source = \"DOI\"\n",
    "        else: # pmid is not np.nan\n",
    "            # request the webpage\n",
    "            url = \"https://pubmed.ncbi.nlm.nih.gov/\" + pmid + \"/\"\n",
    "            # proxies = plib.get_proxies()\n",
    "            soup = plib.request_webpage(url)\n",
    "            # print(soup)\n",
    "\n",
    "            # get pmcid\n",
    "            try:\n",
    "                pmcid = soup.find_all(\"span\", {\"class\": \"identifier pmc\"})[0].find_all(\"a\", {\"class\": \"id-link\"})[0].get_text().strip()\n",
    "            except:\n",
    "                pmcid = np.nan\n",
    "            # print(pmcid)\n",
    "            \n",
    "            # get full_text_url, full_text_source\n",
    "            if pmcid == pmcid:\n",
    "                full_text_url = \"https://www.ncbi.nlm.nih.gov/pmc/articles/\" + pmcid + \"/\"\n",
    "                full_text_source = \"PMC\"\n",
    "            else:\n",
    "                try:\n",
    "                    full_text_url = soup.find_all(\"div\", {\"class\": \"full-text-links-list\"})[0].find_all(\"a\", {\"class\": \"link-item dialog-focus\"})[0][\"href\"].strip()\n",
    "                    full_text_source = soup.find_all(\"div\", {\"class\": \"full-text-links-list\"})[0].find_all(\"a\", {\"class\": \"link-item dialog-focus\"})[0][\"data-ga-action\"].strip()\n",
    "                except:\n",
    "                    full_text_url = np.nan\n",
    "                    full_text_source = np.nan\n",
    "        \n",
    "        # get pdf_url, pdf_source\n",
    "        pdf_url = np.nan\n",
    "        pdf_source = np.nan\n",
    "\n",
    "        columns = [\"DOI\", \"PMID\", \"PMCID\", \"Title\", \"full_text_url\", \"full_text_source\", \"pdf_url\", \"pdf_source\"]\n",
    "        row = {\n",
    "            \"DOI\": [doi],\n",
    "            \"PMID\": [pmid],\n",
    "            \"PMCID\": [pmcid],\n",
    "            \"Title\": [str(df[\"Article Title\"][ind]).strip()],\n",
    "            \"full_text_url\": [full_text_url],\n",
    "            \"full_text_source\": [full_text_source],\n",
    "            \"pdf_url\": [pdf_url],\n",
    "            \"pdf_source\": [pdf_source]\n",
    "        }\n",
    "        # print(row)\n",
    "\n",
    "        if not plib.add_row_to_csv(output_path, row, columns):\n",
    "            print(\"Error detected when adding a row to csv!\")\n",
    "        \n",
    "        print(ind)\n",
    "# --------------------start of test code--------------------\n",
    "# # source_path = fpath.poten_litera_wos\n",
    "# # output_path = fpath.poten_litera_wos_processed\n",
    "# plib.clear_file(output_path)\n",
    "\n",
    "# df = pd.read_csv(source_path, sep=';')\n",
    "# df = df[[\"DOI\", \"Pubmed Id\", \"Article Title\"]]\n",
    "# print(df.head(3))\n",
    "# print(df.shape)\n",
    "\n",
    "# print(df[\"DOI\"].isnull().values.any())\n",
    "# print(df[\"Pubmed Id\"].isnull().values.any())\n",
    "# print(df[\"Article Title\"].isnull().values.any())\n",
    "# # True, True, False\n",
    "# # Article Title don't contain np.nan\n",
    "# # DOI, Pubmed Id contain np.nan\n",
    "# # we need to fill in what are missing\n",
    "# ---------------------end of test code--------------------- \n",
    "\n",
    "# --------------------start of test code--------------------\n",
    "# preprocess_webofscience(source_path, output_path, 0, 10)\n",
    "# ---------------------end of test code--------------------- \n",
    "\n",
    "# --------------------start of test code--------------------\n",
    "# df = pd.read_csv(output_path, header=None, sep=';')\n",
    "# print(df.head(3))\n",
    "# ---------------------end of test code---------------------  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_eupmc(source_path, output_path, start, end):\n",
    "    print(\"Starting preprocessing search results from Europe PMC...\")\n",
    "\n",
    "    df = pd.read_csv(source_path, sep=\",\")\n",
    "    df = df[[\"SOURCE\", \"DOI\", \"EXTERNAL_ID\", \"PMCID\", \"TITLE\"]]\n",
    "\n",
    "    for ind in range(start, end):\n",
    "        # sleep to avoid to be blocked\n",
    "        time.sleep(random.randint(1, 3))\n",
    "        # if(ind%50 == 0):\n",
    "        #     time.sleep(random.randint(10,15)*10)\n",
    "\n",
    "        # get pmid, doi\n",
    "        # SOURCE = {'PMC', 'MED', 'ETH', 'PPR'}\n",
    "        if df[\"SOURCE\"][ind] != \"MED\": # SOURCE is not \"MED\" \n",
    "            if df[\"DOI\"][ind] != df[\"DOI\"][ind]: # doi is np.nan\n",
    "                doi = np.nan\n",
    "                pmid = np.nan\n",
    "            else:\n",
    "                doi = str(df[\"DOI\"][ind]).strip()\n",
    "                pmid = plib.doi2pmid(doi)\n",
    "        else: # SOURCE is \"MED\"\n",
    "            # get doi, pmid\n",
    "            if df[\"EXTERNAL_ID\"][ind] != df[\"EXTERNAL_ID\"][ind]: # EXTERNAL_ID is np.nan\n",
    "                if df[\"DOI\"][ind] != df[\"DOI\"][ind](): # DOI is np.nan\n",
    "                    doi = np.nan\n",
    "                    pmid = np.nan\n",
    "                else: # DOI is not np.nan\n",
    "                    doi = str(df[\"DOI\"][ind]).strip()\n",
    "                    pmid = plib.doi2pmid(doi)\n",
    "            else: # EXTERNAL_ID is not np.nan\n",
    "                pmid = str(df[\"EXTERNAL_ID\"][ind]).strip()\n",
    "                if df[\"DOI\"][ind] != df[\"DOI\"][ind]: # DOI is np.nan\n",
    "                    doi = plib.pmid2doi(pmid)\n",
    "                else: # DOI is not np.nan\n",
    "                    doi = str(df[\"DOI\"][ind]).strip()\n",
    "                \n",
    "        # get pmcid, full_text_url, full_text_source\n",
    "        if pmid != pmid: # pmid is np.nan\n",
    "            pmcid = df[\"PMCID\"][ind]\n",
    "            if pmcid == pmcid: # pmcid is np.nan\n",
    "                full_text_url = \"https://www.ncbi.nlm.nih.gov/pmc/articles/\" + pmcid + \"/\"\n",
    "                full_text_source = \"PMC\"\n",
    "            elif doi == doi: # doi is not np.nan\n",
    "                full_text_url = \"https://doi.org/\" + str(doi).strip()\n",
    "                full_text_source = \"DOI\"\n",
    "            else:\n",
    "                full_text_url = np.nan\n",
    "                full_text_source = np.nan\n",
    "        else: # pmid is not np.nan\n",
    "            # request the webpage\n",
    "            url = \"https://pubmed.ncbi.nlm.nih.gov/\" + pmid + \"/\"\n",
    "            # proxies = plib.get_proxies()\n",
    "            soup = plib.request_webpage(url)\n",
    "            # print(soup)\n",
    "\n",
    "            # get pmcid\n",
    "            try:\n",
    "                pmcid = soup.find_all(\"span\", {\"class\": \"identifier pmc\"})[0].find_all(\"a\", {\"class\": \"id-link\"})[0].get_text().strip()\n",
    "            except:\n",
    "                pmcid = np.nan\n",
    "            # print(pmcid)\n",
    "            \n",
    "            # get full_text_url, full_text_source\n",
    "            if pmcid == pmcid: # pmcid is not np.nan\n",
    "                full_text_url = \"https://www.ncbi.nlm.nih.gov/pmc/articles/\" + pmcid + \"/\"\n",
    "                full_text_source = \"PMC\"\n",
    "            else: # pmcid is not np.nan\n",
    "                try:\n",
    "                    full_text_url = soup.find_all(\"div\", {\"class\": \"full-text-links-list\"})[0].find_all(\"a\", {\"class\": \"link-item dialog-focus\"})[0][\"href\"].strip()\n",
    "                    full_text_source = soup.find_all(\"div\", {\"class\": \"full-text-links-list\"})[0].find_all(\"a\", {\"class\": \"link-item dialog-focus\"})[0][\"data-ga-action\"].strip()\n",
    "                except:\n",
    "                    full_text_url = np.nan\n",
    "                    full_text_source = np.nan\n",
    "        \n",
    "        # get pdf_url, pdf_source\n",
    "        pdf_url = np.nan\n",
    "        pdf_source = np.nan\n",
    "\n",
    "        columns = [\"DOI\", \"PMID\", \"PMCID\", \"Title\", \"full_text_url\", \"full_text_source\", \"pdf_url\", \"pdf_source\"]\n",
    "        row = {\n",
    "            \"DOI\": [doi],\n",
    "            \"PMID\": [pmid],\n",
    "            \"PMCID\": [pmcid],\n",
    "            \"Title\": [str(df[\"TITLE\"][ind]).strip()],\n",
    "            \"full_text_url\": [full_text_url],\n",
    "            \"full_text_source\": [full_text_source],\n",
    "            \"pdf_url\": [pdf_url],\n",
    "            \"pdf_source\": [pdf_source]\n",
    "        }\n",
    "        # print(row)\n",
    "\n",
    "        if not plib.add_row_to_csv(output_path, row, columns):\n",
    "            print(\"Error detected when adding a row to csv!\")\n",
    "        \n",
    "        print(ind)\n",
    "# --------------------start of test code--------------------\n",
    "# source_path = fpath.poten_litera_eupmc\n",
    "# output_path = fpath.poten_litera_eupmc_processed\n",
    "# # plib.clear_file(output_path)\n",
    "\n",
    "# df = pd.read_csv(source_path, sep=',')\n",
    "# df = df[[\"SOURCE\", \"DOI\", \"EXTERNAL_ID\", \"PMCID\", \"TITLE\"]]\n",
    "# print(df.head(3))\n",
    "# print(df.shape)\n",
    "\n",
    "# col_one_list = set(df['SOURCE'].tolist())\n",
    "# print(col_one_list)\n",
    "# # ['PMC', 'MED', 'ETH', 'PPR']\n",
    "\n",
    "# print(df[\"SOURCE\"].isnull().values.any())\n",
    "# print(df[\"DOI\"].isnull().values.any())\n",
    "# print(df[\"EXTERNAL_ID\"].isnull().values.any())\n",
    "# print(df[\"PMCID\"].isnull().values.any())\n",
    "# print(df[\"TITLE\"].isnull().values.any())\n",
    "# # False, True, False, True, False\n",
    "# # SOURCE, EXTERNAL_ID, Title don't contain np.nan\n",
    "# # DOI, PMCID contain np.nan\n",
    "# # we need to fill in what are missing\n",
    "# ---------------------end of test code---------------------\n",
    "\n",
    "# --------------------start of test code--------------------\n",
    "# preprocess_eupmc(source_path, output_path, 0, 10)\n",
    "# ---------------------end of test code---------------------\n",
    "\n",
    "# --------------------start of test code--------------------\n",
    "# df = pd.read_csv(output_path, header=None, sep=',')\n",
    "# print(df.head(3))\n",
    "# ---------------------end of test code---------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_google_shcolar_step1(source_path, output_path, start, end):\n",
    "    print(\"Starting merging search results from Google Scholar...\")\n",
    "\n",
    "    df = pd.read_csv(source_path, header=None, sep=',')\n",
    "    df.columns = [\"title\", \"url\", \"url_type\", \"full_text_url\", \"full_text_type\", \"full_text_source\"]\n",
    "\n",
    "    for ind in range(start, end):\n",
    "        # df[\"url_type\"][ind]: {'[CITATION][C]', '[PDF][PDF]', '[BOOK][B]', nan, '[HTML][HTML]'}\n",
    "        # we don't need citations and books, as they are not likely to include connecivity information\n",
    "        if (df[\"url_type\"][ind] == \"[CITATION][C]\") or (df[\"url_type\"][ind] == \"[BOOK][B]\"):\n",
    "            continue\n",
    "        \n",
    "        # if url or title doesn't exsit AND full_text_url doesn't exist\n",
    "        if (df[\"url\"][ind] != df[\"url\"][ind]) or (df[\"title\"][ind] != df[\"title\"][ind]):\n",
    "            continue\n",
    "        \n",
    "        # now every row has at least title and url, and the url_text = {\"[PDF][PDF]\", nan, \"[HTML][HTML]\"}\n",
    "        if df[\"url_type\"][ind] == \"[PDF][PDF]\":\n",
    "            # full_text_type = {'[HTML]', nan, '[PDF]', 'UB'}\n",
    "            if df[\"full_text_type\"][ind] == \"[HTML]\":\n",
    "                link = str(df[\"full_text_url\"][ind]).strip()\n",
    "                full_text_url = plib.get_final_redirected_url(link)\n",
    "                if full_text_url == full_text_url:\n",
    "                    full_text_source = full_text_url.split(\"://\")[1].split(\"/\")[0]\n",
    "                else:\n",
    "                    full_text_source = np.nan\n",
    "            else:\n",
    "                full_text_url = np.nan\n",
    "                full_text_source = np.nan\n",
    "            # get pdf_url, pdf_source\n",
    "            link = str(df[\"url\"][ind]).strip()\n",
    "            pdf_url = plib.get_final_redirected_url(link)\n",
    "            if pdf_url == pdf_url:\n",
    "                pdf_source = pdf_url.split(\"://\")[1].split(\"/\")[0]\n",
    "            else:\n",
    "                pdf_source = np.nan\n",
    "        else: # df[\"url_type\"][ind] == nan or '[HTML][HTML]'\n",
    "            link = str(df[\"url\"][ind]).strip()\n",
    "            full_text_url = plib.get_final_redirected_url(link)\n",
    "            if full_text_url == full_text_url:\n",
    "                full_text_source = full_text_url.split(\"://\")[1].split(\"/\")[0]\n",
    "            else:\n",
    "                full_text_source = np.nan\n",
    "            # get pdf_url, pdf_source\n",
    "            # full_text_type = {'[HTML]', nan, '[PDF]', 'UB'}\n",
    "            if df[\"full_text_type\"][ind] == \"[PDF]\":\n",
    "                link = str(df[\"full_text_url\"][ind]).strip()\n",
    "                pdf_url = plib.get_final_redirected_url(link)\n",
    "                if pdf_url == pdf_url:\n",
    "                    pdf_source = pdf_url.split(\"://\")[1].split(\"/\")[0]\n",
    "                else:\n",
    "                    pdf_source = np.nan\n",
    "            else:\n",
    "                pdf_url = np.nan\n",
    "                pdf_source = np.nan\n",
    "        \n",
    "        columns = [\"Title\", \"full_text_url\", \"full_text_source\", \"pdf_url\", \"pdf_source\"]\n",
    "        row = {\n",
    "            \"Title\": [str(df[\"title\"][ind]).strip()],\n",
    "            \"full_text_url\": [full_text_url],\n",
    "            \"full_text_source\": [full_text_source],\n",
    "            \"pdf_url\": [pdf_url],\n",
    "            \"pdf_source\": [pdf_source]\n",
    "        }\n",
    "        # print(row)\n",
    "\n",
    "        if not plib.add_row_to_csv(output_path, row, columns):\n",
    "            print(\"Error detected when adding a row to csv!\")\n",
    "        \n",
    "        print(ind)\n",
    "# --------------------start of test code--------------------\n",
    "# source_path = fpath.poten_litera_gs\n",
    "# output_path = fpath.poten_litera_gs_processed_step1\n",
    "# # plib.clear_file(output_path)\n",
    "\n",
    "# df = pd.read_csv(source_path, header=None, sep=',')\n",
    "# df.columns = [\"title\", \"url\", \"url_type\", \"full_text_url\", \"full_text_type\", \"full_text_source\"]\n",
    "# print(df.head(3))\n",
    "# print(df.head)\n",
    "\n",
    "# url_type = set(df['url_type'].tolist())\n",
    "# print(url_type)\n",
    "# # {'[CITATION][C]', '[PDF][PDF]', '[BOOK][B]', nan, '[HTML][HTML]'}\n",
    "# full_text_type = set(df['full_text_type'].tolist())\n",
    "# print(full_text_type)\n",
    "# # {nan, 'UB', '[HTML]', '[PDF]'}\n",
    "# full_text_source = set(df['full_text_source'].tolist())\n",
    "# print(full_text_source)\n",
    "# # {'ahajournals.org', 'lww.com', 'springer.com', 'academia.edu', 'plos.org', 'ieee.org', 'nature.com', \n",
    "# # 'mdpi.com', 'jpn.ca', 'uottawa.ca', nan, 'northwestern.edu', 'bmj.com', 'ekja.org', 'RWTH-Link', 'wiley.com', \n",
    "# # 'escholarship.org', 'nyu.edu', 'frontiersin.org', 'sciencedirect.com', 'eneuro.org', 'jneurosci.org', \n",
    "# # 'royalsocietypublishing.org', 'karger.com', 'harvard.edu', 'annualreviews.org', 'mcgill.ca', \n",
    "# # 'elifesciences.org', 'mirasmart.com', 'duke.edu', 'ucdavis.edu', 'physiology.org', 'cell.com', \n",
    "# # 'wustl.edu', 'epfl.ch', 'udc.es', 'psychiatryonline.org', 'jst.go.jp', 'core.ac.uk', 'rero.ch', \n",
    "# # 'zsp.com.pk', 'sagepub.com', 'europepmc.org', 'tandfonline.com', 'asahq.org', 'sonar.ch', 'koreamed.org', \n",
    "# # 'oup.com', 'science.org', 'scholarpedia.org', 'psu.edu', 'jordanbpeterson.com', 'pnas.org', 'uzh.ch', 'biorxiv.org', \n",
    "# # 'biomedcentral.com', 'umich.edu', 'ahuman.org', 'researchgate.net', 'ijpp.com', 'unav.edu', 'nih.gov', 'bu.edu'}\n",
    "# ---------------------end of test code---------------------\n",
    "\n",
    "# --------------------start of test code--------------------\n",
    "# # [\"title\", \"url\", \"url_type\", \"full_text_url\", \"full_text_type\", \"full_text_source\"]\n",
    "# print(df[\"title\"].isnull().any().any())\n",
    "# print(df[\"url\"].isnull().any().any())\n",
    "# print(df[\"url_type\"].isnull().any().any())\n",
    "# print(df[\"full_text_url\"].isnull().any().any())\n",
    "# print(df[\"full_text_type\"].isnull().any().any())\n",
    "# print(df[\"full_text_source\"].isnull().any().any())\n",
    "# # True, True, True, True, True, True\n",
    "# # title, url, url_type, full_text_url, full_text_type, full_text_source contain np.nan\n",
    "# # we need to fill in what are missing\n",
    "# ---------------------end of test code---------------------\n",
    "\n",
    "# --------------------start of test code--------------------\n",
    "# preprocess_google_shcolar_step1(source_path, output_path, 0, 1000)\n",
    "# ---------------------end of test code---------------------\n",
    "\n",
    "# --------------------start of test code--------------------\n",
    "# df = pd.read_csv(output_path, header=None, sep=',')\n",
    "# print(df.head(3))\n",
    "# ---------------------end of test code---------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting merging search results from Google Scholar...\n",
      "10.1152/jn.2001.85.1.219\n",
      "0\n",
      "nan\n",
      "['https://www.cabdirect.org/cabdirect/welcome/?target=%2fcabdirect%2fabstract%2f19522203025']\n",
      "1\n",
      "10.1016/j.neuroimage.2006.07.032\n",
      "2\n",
      "10.1523/JNEUROSCI.14-05-02485.1994\n",
      "3\n",
      "10.1002/cne.903130106\n",
      "4\n",
      "10.1038/372770a0\n",
      "5\n",
      "nan\n",
      "[nan]\n",
      "6\n",
      "10.1002/(SICI)1096-9861(19981019)400:2<271::AID-CNE8>3.0.CO;2-6\n",
      "7\n",
      "10.1002/(SICI)1096-9861(19960812)372:1<59::AID-CNE6>3.0.CO;2-L\n",
      "8\n",
      "10.1016/0165-0173(96)00003-3\n",
      "9\n",
      "10.1038/nn.4423\n",
      "10\n",
      "10.1002/cne.902570211\n",
      "11\n",
      "10.1002/cne.902620207\n",
      "12\n",
      "10.1002/cne.902440208\n",
      "13\n",
      "10.1007/s00429-022-02463-4\n",
      "14\n",
      "10.1016/0006-8993(77)90536-4\n",
      "15\n",
      "10.1007/BF00236173\n",
      "16\n",
      "10.1002/cne.902620303\n",
      "17\n",
      "10.1002/cne.902360304\n",
      "18\n",
      "10.1152/jn.1989.61.1.1\n",
      "19\n",
      "10.1016/S0168-0102(98)00021-2\n",
      "20\n",
      "10.1007/BF00250573\n",
      "21\n",
      "10.1002/cne.902520305\n",
      "22\n",
      "10.1002/cne.901950105\n",
      "23\n",
      "10.1007/BF00237252\n",
      "24\n",
      "10.1002/cne.903370102\n",
      "25\n",
      "10.1002/cne.902950212\n",
      "26\n",
      "10.1017/S0952523800004922\n",
      "27\n",
      "10.1016/0006-8993(76)90424-8\n",
      "28\n",
      "10.1007/BF00237670\n",
      "29\n",
      "10.1523/JNEUROSCI.2334-08.2008\n",
      "30\n",
      "10.1523/JNEUROSCI.0968-05.2005\n",
      "31\n",
      "10.1002/cne.902800311\n",
      "32\n",
      "10.1002/cne.902710402\n",
      "33\n",
      "10.1016/0891-0618(95)00050-H\n",
      "34\n",
      "nan\n",
      "['https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1252781/']\n",
      "35\n",
      "10.1002/cne.902560202\n",
      "36\n",
      "10.1016/0006-8993(76)90206-7\n",
      "37\n",
      "10.1002/cne.902990103\n",
      "38\n",
      "10.1002/cne.902270112\n",
      "39\n",
      "10.1002/cne.903440403\n",
      "40\n",
      "10.1017/S0952523800002406\n",
      "41\n",
      "10.1016/j.neuroscience.2007.02.033\n",
      "42\n",
      "10.1002/cne.902820107\n",
      "43\n",
      "nan\n",
      "['https://www.sciencedirect.com/science/article/pii/0306452288900061']\n",
      "44\n",
      "10.1002/cne.901710302\n",
      "45\n",
      "10.1002/cne.902890211\n",
      "46\n",
      "10.1093/cercor/bhn229\n",
      "47\n",
      "10.1002/cne.903120403\n",
      "48\n",
      "10.1007/s00429-021-02377-7\n",
      "49\n",
      "nan\n",
      "[nan]\n",
      "50\n",
      "nan\n",
      "['https://europepmc.org/article/med/8784824']\n",
      "51\n",
      "10.1002/cne.21440\n",
      "52\n",
      "10.1007/s00221-005-2361-3\n",
      "53\n",
      "10.1101/2022.02.03.479036\n",
      "54\n",
      "10.1002/cne.21155\n",
      "55\n",
      "10.1002/cne.901770409\n",
      "56\n",
      "10.1093/cercor/bhab073\n",
      "57\n",
      "10.1016/0006-8993(75)90930-0\n",
      "58\n",
      "10.1007/BF00231783\n",
      "59\n",
      "10.1002/cne.903140209\n",
      "60\n",
      "10.1046/j.1460-9568.1998.00246.x\n",
      "61\n",
      "10.1016/0006-8993(90)90339-D\n",
      "62\n",
      "10.1002/cne.901780302\n",
      "63\n",
      "10.1002/cne.901600306\n",
      "64\n",
      "10.1002/cne.21060\n",
      "65\n",
      "10.1093/cercor/bhn093\n",
      "66\n",
      "10.1111/ejn.13208\n",
      "67\n",
      "10.1002/(SICI)1096-9861(19990726)410:2<211::AID-CNE4>3.0.CO;2-X\n",
      "68\n",
      "10.1002/cne.23386\n",
      "69\n",
      "10.1007/BF00239019\n",
      "70\n",
      "10.1002/cne.902940314\n",
      "71\n",
      "nan\n",
      "['https://www.jneurosci.org/content/20/10/3884.short']\n",
      "72\n",
      "10.1523/JNEUROSCI.2815-12.2012\n",
      "73\n",
      "10.1002/cne.10499\n",
      "74\n",
      "10.1111/j.1460-9568.2007.05773.x\n",
      "75\n",
      "10.1016/0168-0102(92)90093-R\n",
      "76\n",
      "10.1016/0304-3940(81)90071-9\n",
      "77\n",
      "10.1002/cne.21647\n",
      "78\n",
      "10.1002/cne.21934\n",
      "79\n",
      "10.1016/j.jneumeth.2017.10.009\n",
      "80\n",
      "nan\n",
      "[nan]\n",
      "81\n",
      "10.1111/j.1460-9568.2005.03921.x\n",
      "82\n",
      "10.1007/s00429-008-0178-0\n",
      "83\n",
      "nan\n",
      "['https://europepmc.org/article/med/814157']\n",
      "84\n",
      "10.1002/cne.903350204\n",
      "85\n",
      "10.1002/cne.901990104\n",
      "86\n",
      "10.1007/s004290050204\n",
      "87\n",
      "10.1002/(SICI)1096-9861(19990621)409:1<131::AID-CNE10>3.0.CO;2-A\n",
      "88\n",
      "10.1007/s00429-020-02045-2\n",
      "89\n",
      "10.1002/cne.903530309\n",
      "90\n",
      "10.1073/pnas.0900714106\n",
      "91\n",
      "10.1016/j.conb.2003.10.014\n",
      "92\n",
      "10.1017/S1472928802000031\n",
      "93\n",
      "10.1016/0168-0102(96)01045-0\n",
      "94\n",
      "10.1016/S0079-6123(05)49013-5\n",
      "95\n",
      "10.1006/exnr.1993.1024\n",
      "96\n",
      "10.1002/cne.24283\n",
      "97\n",
      "10.1016/0304-3940(93)90180-S\n",
      "98\n",
      "10.1002/(SICI)1096-9861(19971006)386:4<601::AID-CNE6>3.0.CO;2-6\n",
      "99\n",
      "10.1523/JNEUROSCI.2069-15.2015\n",
      "100\n",
      "nan\n",
      "['https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2601459/']\n",
      "101\n",
      "nan\n",
      "['https://europepmc.org/article/med/9407703']\n",
      "102\n",
      "10.1037/h0044278\n",
      "103\n",
      "10.1002/cne.20240\n",
      "104\n",
      "10.1002/(SICI)1096-9861(19960916)373:2<271::AID-CNE9>3.0.CO;2-0\n",
      "105\n",
      "10.1093/cercor/10.3.220\n",
      "106\n",
      "10.1016/S0306-4522(99)00282-1\n",
      "107\n",
      "10.1002/(SICI)1096-9861(19960722)371:2<325::AID-CNE11>3.0.CO;2-R\n",
      "108\n",
      "10.1002/(SICI)1096-9861(19990705)409:3<369::AID-CNE3>3.0.CO;2-H\n",
      "109\n",
      "10.1111/ejn.14078\n",
      "110\n",
      "10.1002/cne.902770304\n",
      "111\n",
      "10.1016/0006-8993(76)90160-8\n",
      "112\n",
      "nan\n",
      "[nan]\n",
      "113\n",
      "10.1002/cne.902430310\n",
      "114\n",
      "10.1111/j.1460-9568.2005.04020.x\n",
      "115\n",
      "10.1007/s00429-011-0370-5\n",
      "116\n",
      "10.1017/S1472928802000304\n",
      "117\n",
      "10.1152/jn.00969.2003\n",
      "118\n",
      "10.1002/cne.24389\n",
      "119\n",
      "10.1002/cne.902990104\n",
      "120\n",
      "10.1002/cne.903570110\n",
      "121\n",
      "10.1007/s00429-015-0990-2\n",
      "122\n",
      "10.1016/j.conb.2009.05.007\n",
      "123\n",
      "10.1111/ejn.12389\n",
      "124\n",
      "10.1177/2398212819871205\n",
      "125\n",
      "10.1002/(SICI)1096-9861(19970317)379:3<313::AID-CNE1>3.0.CO;2-6\n",
      "126\n",
      "10.1038/s41598-017-10679-2\n",
      "127\n",
      "10.1016/S0306-4522(97)00634-9\n",
      "128\n",
      "10.1002/cne.21674\n",
      "129\n",
      "10.1016/S0028-3908(99)00130-6\n",
      "130\n",
      "10.1017/S1472928802000316\n",
      "131\n",
      "10.1002/(SICI)1096-9861(19971006)386:4<573::AID-CNE5>3.0.CO;2-%23\n",
      "132\n",
      "10.1002/cne.902940313\n",
      "133\n",
      "10.1007/s002210050584\n",
      "134\n",
      "10.1159/000100589\n",
      "135\n",
      "10.1007/BF00230949\n",
      "136\n",
      "10.1016/S0304-3940(01)02018-3\n",
      "137\n",
      "10.1002/(SICI)1096-9861(20000605)421:3<412::AID-CNE9>3.0.CO;2-Z\n",
      "138\n",
      "10.1111/j.1460-9568.2010.07390.x\n",
      "139\n",
      "nan\n",
      "['https://www.jstor.org/stable/82698']\n",
      "140\n",
      "10.1016/S0361-9230(02)00857-2\n",
      "141\n",
      "10.1016/0006-8993(80)90279-6\n",
      "142\n",
      "10.1016/S0306-4522(01)00021-5\n",
      "143\n",
      "10.1002/cne.21513\n",
      "144\n",
      "10.1002/cne.24134\n",
      "145\n",
      "10.1159/000315942\n",
      "146\n",
      "10.1016/0306-4522(94)90536-3\n",
      "147\n",
      "10.1002/cne.902370309\n",
      "148\n",
      "10.1159/000100200\n",
      "149\n",
      "10.1523/JNEUROSCI.3931-07.2007\n",
      "150\n",
      "10.1002/(SICI)1096-9861(19960805)371:4<513::AID-CNE2>3.0.CO;2-7\n",
      "151\n",
      "10.1016/0304-3940(94)90505-3\n",
      "152\n",
      "10.1016/j.brainres.2005.02.005\n",
      "153\n",
      "10.1098/rspb.1953.0054\n",
      "154\n",
      "10.1016/j.bandl.2012.10.001\n",
      "155\n",
      "10.1007/BF00237639\n",
      "156\n",
      "10.1016/S0306-4522(97)00581-2\n",
      "157\n",
      "10.1002/cne.901780103\n",
      "158\n",
      "10.1016/S0079-6123(08)62678-3\n",
      "159\n",
      "10.1016/S0006-8993(00)03013-4\n",
      "160\n",
      "10.1016/0014-4886(77)90112-1\n",
      "161\n",
      "10.1007/BF00238104\n",
      "162\n",
      "10.1152/jn.1949.12.2.85\n",
      "163\n",
      "10.1016/0006-8993(79)90914-4\n",
      "164\n",
      "10.1002/cne.902690111\n",
      "165\n",
      "10.1002/cne.902250105\n",
      "166\n",
      "nan\n",
      "[nan]\n",
      "167\n",
      "10.1016/0306-4522(91)90426-O\n",
      "168\n",
      "10.1002/(SICI)1096-9861(19960429)368:2<215::AID-CNE4>3.0.CO;2-6\n",
      "169\n",
      "10.1002/cne.901510302\n",
      "170\n",
      "10.1016/S0079-6123(05)49001-9\n",
      "171\n",
      "10.1002/mds.27921\n",
      "172\n",
      "10.3390/ijms24119643\n",
      "173\n",
      "10.1126/science.282.5391.1117\n",
      "174\n",
      "10.1016/0006-8993(94)91125-8\n",
      "175\n",
      "10.3109/08990229109144753\n",
      "176\n",
      "10.1002/cne.903450204\n",
      "177\n",
      "10.1016/j.neuroimage.2010.02.062\n",
      "178\n",
      "10.1523/JNEUROSCI.5266-07.2008\n",
      "179\n",
      "10.1001/archneur.1965.00470020003001\n",
      "180\n",
      "10.1016/S0306-4522(97)00549-6\n",
      "181\n",
      "10.1002/cne.901620302\n",
      "182\n",
      "10.1111/j.1749-6632.1999.tb09297.x\n",
      "183\n",
      "10.1089/brain.2013.0143\n",
      "184\n",
      "10.1002/cne.901470404\n",
      "185\n",
      "10.1016/S0028-3932(97)00042-0\n",
      "186\n",
      "10.1016/S0166-2236(00)01922-6\n",
      "187\n",
      "nan\n",
      "[nan]\n",
      "188\n",
      "10.1001/archneur.1982.00510180003001\n",
      "189\n",
      "10.1016/S0306-4522(03)00064-2\n",
      "190\n",
      "10.1016/0006-8993(79)90260-9\n",
      "191\n",
      "10.1093/brain/123.3.601\n",
      "192\n",
      "10.1016/j.brainresrev.2010.12.002\n",
      "193\n",
      "nan\n",
      "[nan]\n",
      "194\n",
      "10.1007/978-1-4684-5871-8_7\n",
      "195\n",
      "10.1002/cne.902220106\n",
      "196\n",
      "10.1152/jn.00729.2009\n",
      "197\n",
      "10.1016/0165-0173(89)90007-6\n",
      "198\n",
      "10.1016/S0006-8993(03)02548-4\n",
      "199\n",
      "10.1002/(SICI)1096-9861(19980427)394:1<118::AID-CNE9>3.0.CO;2-3\n",
      "200\n",
      "10.1016/0014-4886(69)90094-6\n",
      "201\n",
      "10.3389/fncir.2015.00079\n",
      "202\n",
      "10.1007/BF00523634\n",
      "203\n",
      "10.1002/cne.902420406\n",
      "204\n",
      "10.1038/199820a0\n",
      "205\n",
      "10.1007/BF00237265\n",
      "206\n",
      "10.1016/S0079-6123(08)62676-X\n",
      "207\n",
      "10.1002/cne.901980111\n",
      "208\n",
      "10.1016/j.neulet.2004.01.008\n",
      "209\n",
      "10.1016/0304-3940(95)11273-Y\n",
      "210\n",
      "10.1016/j.neulet.2013.02.007\n",
      "211\n",
      "10.1515/REVNEURO.2007.18.6.417\n",
      "212\n",
      "10.1002/cne.902970304\n",
      "213\n",
      "10.1038/s41593-017-0020-1\n",
      "214\n",
      "10.1006/taap.1995.1193\n",
      "215\n",
      "10.1093/cercor/2.3.217\n",
      "216\n",
      "10.1016/j.brainresbull.2008.09.013\n",
      "217\n",
      "10.1016/0304-3940(95)12056-A\n",
      "218\n",
      "10.1016/B978-0-08-017007-7.50009-4\n",
      "219\n",
      "10.1002/cne.22078\n",
      "220\n",
      "10.1002/cne.901440105\n",
      "221\n",
      "10.1007/PL00005713\n",
      "222\n",
      "10.1016/j.neuroscience.2009.04.034\n",
      "223\n",
      "10.1126/science.1114317\n",
      "224\n",
      "10.1093/cercor/13.1.15\n",
      "225\n",
      "10.1002/(SICI)1096-9861(19970526)382:1<89::AID-CNE6>3.0.CO;2-G\n",
      "226\n",
      "10.1016/0006-8993(78)91103-4\n",
      "227\n",
      "10.1007/978-1-4615-1235-6_7\n",
      "228\n",
      "10.1523/JNEUROSCI.1724-21.2021\n",
      "229\n",
      "10.1016/S0960-9822(00)00043-9\n",
      "230\n",
      "10.1007/BF00237587\n",
      "231\n",
      "10.1093/cercor/bhn228\n",
      "232\n",
      "10.1002/cne.902770209\n",
      "233\n",
      "10.1046/j.1460-9568.2000.00262.x\n",
      "234\n",
      "10.1523/JNEUROSCI.04-02-00539.1984\n",
      "235\n",
      "10.1002/(SICI)1096-9861(19981102)400:4<449::AID-CNE2>3.0.CO;2-A\n",
      "236\n",
      "nan\n",
      "['https://europepmc.org/article/med/8337932']\n",
      "237\n",
      "10.1002/cne.903350205\n",
      "238\n",
      "10.1002/cne.902400103\n",
      "239\n",
      "10.3389/fnsys.2015.00039\n",
      "240\n",
      "10.1038/nature07382\n",
      "241\n",
      "10.1523/JNEUROSCI.18-11-04216.1998\n",
      "242\n",
      "10.1523/JNEUROSCI.5511-05.2006\n",
      "243\n",
      "nan\n",
      "[nan]\n",
      "244\n",
      "10.1016/S0166-2236(99)01482-4\n",
      "245\n",
      "10.1002/cne.903350106\n",
      "246\n",
      "10.1016/S0079-6123(02)36031-X\n",
      "247\n",
      "nan\n",
      "[nan]\n",
      "248\n",
      "10.1016/B978-0-08-042274-9.50017-1\n",
      "249\n",
      "10.1016/0006-8993(77)90474-7\n",
      "250\n",
      "nan\n",
      "[nan]\n",
      "251\n",
      "10.1007/s00429-015-1091-y\n",
      "252\n",
      "10.1016/0006-8993(79)90240-3\n",
      "253\n",
      "10.1002/cne.903110402\n",
      "254\n",
      "10.1007/978-1-349-11597-6_12\n",
      "255\n",
      "10.1073/pnas.1008054107\n",
      "256\n",
      "10.1016/0306-4522(91)90151-D\n",
      "257\n",
      "10.1002/cne.902170307\n",
      "258\n",
      "10.1038/387281a0\n",
      "259\n",
      "10.1002/cne.901680204\n",
      "260\n",
      "10.1371/journal.pone.0000848\n",
      "261\n",
      "10.1176/appi.ajp.160.6.1100\n",
      "262\n",
      "10.1016/0165-0173(94)00007-C\n",
      "263\n",
      "10.1007/978-1-4899-0194-1_3\n",
      "264\n",
      "10.1016/B978-0-08-042274-9.50021-3\n",
      "265\n",
      "nan\n",
      "[nan]\n",
      "266\n",
      "10.1016/S0361-9230(96)00107-4\n",
      "267\n",
      "10.1016/0014-4886(70)90196-2\n",
      "268\n",
      "10.1002/cne.901680203\n",
      "269\n",
      "10.1046/j.1460-9568.1999.00672.x\n",
      "270\n",
      "10.1093/cercor/bhl067\n",
      "271\n",
      "10.1002/cne.902540403\n",
      "272\n",
      "10.1093/cercor/bhv063\n",
      "273\n",
      "10.1016/0306-4522(84)90163-5\n",
      "274\n",
      "10.1016/0306-4522(88)90339-9\n",
      "275\n",
      "10.1002/cne.901900406\n",
      "276\n",
      "10.1523/JNEUROSCI.11-09-02644.1991\n",
      "277\n",
      "10.1002/cne.902190405\n",
      "278\n",
      "10.1523/JNEUROSCI.4122-03.2004\n",
      "279\n",
      "10.1002/nbm.2789\n",
      "280\n",
      "nan\n",
      "[nan]\n",
      "281\n",
      "nan\n",
      "['https://www.taylorfrancis.com/chapters/edit/10.1201/9780203299296-13/thalamic-systems-diversity-cortical-areas-catherine-cusick']\n",
      "282\n",
      "10.1176/appi.ajp.158.9.1393\n",
      "283\n",
      "10.1002/cne.903630408\n",
      "284\n",
      "10.1002/cne.21672\n",
      "285\n",
      "10.1126/science.282.5391.1121\n",
      "286\n",
      "10.1073/pnas.0507729103\n",
      "287\n",
      "10.1016/0014-4886(76)90260-0\n",
      "288\n",
      "10.1002/cne.901690307\n",
      "289\n",
      "nan\n",
      "[nan]\n",
      "290\n",
      "10.1152/jn.1998.79.6.3143\n",
      "291\n",
      "10.1038/34584\n",
      "292\n",
      "10.1016/0165-0173(83)90014-0\n",
      "293\n",
      "nan\n",
      "['https://books.google.de/books?hl=en&lr=&id=udH6CAAAQBAJ&oi=fnd&pg=PA1&dq=(macaque+OR+macaca+OR+%22rhesus+monkey%22)+(thalamus+OR+thalamic+OR+thalamocortical+OR+%22thalamo-cortical%22)&ots=hL5iwoU5ku&sig=zvJbwP900K7w_YWsd1m9y-nbtaA&redir_esc=y']\n",
      "294\n",
      "10.1002/cne.903090302\n",
      "295\n",
      "10.1113/jphysiol.1990.sp018307\n",
      "296\n",
      "10.3171/jns.1997.86.1.0077\n",
      "297\n",
      "10.1002/cne.1340\n",
      "298\n",
      "10.1016/0306-4522(84)90166-0\n",
      "299\n",
      "10.1002/cne.903260308\n",
      "300\n",
      "10.1016/S0306-4522(00)00368-7\n",
      "301\n",
      "10.1002/cne.902420102\n",
      "302\n",
      "10.1152/jn.90810.2008\n",
      "303\n",
      "10.1016/j.neubiorev.2015.03.001\n",
      "304\n",
      "10.1016/0165-0173(79)90008-0\n",
      "305\n",
      "10.1073/pnas.79.19.6098\n",
      "306\n",
      "10.1016/0028-3908(85)90070-X\n",
      "307\n",
      "10.1159/000106279\n",
      "308\n",
      "10.1002/hipo.20276\n",
      "309\n",
      "10.1002/ana.1119\n",
      "310\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 125\u001b[0m\n\u001b[1;32m     80\u001b[0m plib\u001b[39m.\u001b[39mclear_file(output_path)\n\u001b[1;32m     81\u001b[0m \u001b[39m# ---------------------end of test code---------------------\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \n\u001b[1;32m     83\u001b[0m \u001b[39m# --------------------start of test code--------------------\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    123\u001b[0m \n\u001b[1;32m    124\u001b[0m \u001b[39m# --------------------start of test code--------------------\u001b[39;00m\n\u001b[0;32m--> 125\u001b[0m preprocess_google_shcolar_step2(source_path, output_path, \u001b[39m0\u001b[39;49m, \u001b[39m1000\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[8], line 12\u001b[0m, in \u001b[0;36mpreprocess_google_shcolar_step2\u001b[0;34m(source_path, output_path, start, end)\u001b[0m\n\u001b[1;32m     10\u001b[0m     url \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(df[\u001b[39m\"\u001b[39m\u001b[39mfull_text_url\u001b[39m\u001b[39m\"\u001b[39m][ind])\u001b[39m.\u001b[39mstrip()\n\u001b[1;32m     11\u001b[0m     source \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(df[\u001b[39m\"\u001b[39m\u001b[39mfull_text_source\u001b[39m\u001b[39m\"\u001b[39m][ind])\u001b[39m.\u001b[39mstrip()\n\u001b[0;32m---> 12\u001b[0m     doi \u001b[39m=\u001b[39m plib\u001b[39m.\u001b[39;49murl2doi(url)\n\u001b[1;32m     13\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     doi \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mnan\n",
      "File \u001b[0;32m~/myProjects/didihou_master_project/public_library.py:323\u001b[0m, in \u001b[0;36murl2doi\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mThe url given is np.nan\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    322\u001b[0m url \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(url)\u001b[39m.\u001b[39mstrip()\n\u001b[0;32m--> 323\u001b[0m info \u001b[39m=\u001b[39m plib\u001b[39m.\u001b[39;49mextract_info_from_webpage(url) \u001b[39m# dictionary\u001b[39;00m\n\u001b[1;32m    325\u001b[0m \u001b[39mif\u001b[39;00m info[\u001b[39m\"\u001b[39m\u001b[39mdoi\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m==\u001b[39m info[\u001b[39m\"\u001b[39m\u001b[39mdoi\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m    326\u001b[0m     \u001b[39mreturn\u001b[39;00m info[\u001b[39m\"\u001b[39m\u001b[39mdoi\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/myProjects/didihou_master_project/public_library.py:278\u001b[0m, in \u001b[0;36mextract_info_from_webpage\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mThe given url is np.nan\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    267\u001b[0m info \u001b[39m=\u001b[39m {\n\u001b[1;32m    268\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mdoi\u001b[39m\u001b[39m\"\u001b[39m: np\u001b[39m.\u001b[39mnan,\n\u001b[1;32m    269\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mpmid\u001b[39m\u001b[39m\"\u001b[39m: np\u001b[39m.\u001b[39mnan,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mpdf_link\u001b[39m\u001b[39m\"\u001b[39m: np\u001b[39m.\u001b[39mnan\n\u001b[1;32m    276\u001b[0m }\n\u001b[0;32m--> 278\u001b[0m url \u001b[39m=\u001b[39m plib\u001b[39m.\u001b[39;49mget_final_redirected_url(url)\n\u001b[1;32m    279\u001b[0m source \u001b[39m=\u001b[39m url\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m://\u001b[39m\u001b[39m\"\u001b[39m)[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m)[\u001b[39m0\u001b[39m]\n\u001b[1;32m    281\u001b[0m \u001b[39mfor\u001b[39;00m website \u001b[39min\u001b[39;00m plib\u001b[39m.\u001b[39mwebsites:\n",
      "File \u001b[0;32m~/myProjects/didihou_master_project/public_library.py:138\u001b[0m, in \u001b[0;36mget_final_redirected_url\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_final_redirected_url\u001b[39m(url):\n\u001b[0;32m--> 138\u001b[0m     response \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39;49mget(url, headers \u001b[39m=\u001b[39;49m plib\u001b[39m.\u001b[39;49mheaders)\n\u001b[1;32m    140\u001b[0m     \u001b[39mwhile\u001b[39;00m(response\u001b[39m.\u001b[39mstatus_code \u001b[39m!=\u001b[39m \u001b[39m200\u001b[39m):\n\u001b[1;32m    141\u001b[0m         \u001b[39mif\u001b[39;00m response\u001b[39m.\u001b[39mstatus_code \u001b[39m==\u001b[39m \u001b[39m403\u001b[39m: \u001b[39m# forbidden\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.10/site-packages/requests/api.py:73\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(url, params\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     63\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[39m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[39m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     \u001b[39mreturn\u001b[39;00m request(\u001b[39m\"\u001b[39;49m\u001b[39mget\u001b[39;49m\u001b[39m\"\u001b[39;49m, url, params\u001b[39m=\u001b[39;49mparams, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.10/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[39m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[39m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[39m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[39mwith\u001b[39;00m sessions\u001b[39m.\u001b[39mSession() \u001b[39mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[39mreturn\u001b[39;00m session\u001b[39m.\u001b[39;49mrequest(method\u001b[39m=\u001b[39;49mmethod, url\u001b[39m=\u001b[39;49murl, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.10/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(prep, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msend_kwargs)\n\u001b[1;32m    591\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.10/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    705\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.10/site-packages/requests/adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    483\u001b[0m     timeout \u001b[39m=\u001b[39m TimeoutSauce(connect\u001b[39m=\u001b[39mtimeout, read\u001b[39m=\u001b[39mtimeout)\n\u001b[1;32m    485\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 486\u001b[0m     resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[1;32m    487\u001b[0m         method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[1;32m    488\u001b[0m         url\u001b[39m=\u001b[39;49murl,\n\u001b[1;32m    489\u001b[0m         body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[1;32m    490\u001b[0m         headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    491\u001b[0m         redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    492\u001b[0m         assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    493\u001b[0m         preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    494\u001b[0m         decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    495\u001b[0m         retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[1;32m    496\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    497\u001b[0m         chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    498\u001b[0m     )\n\u001b[1;32m    500\u001b[0m \u001b[39mexcept\u001b[39;00m (ProtocolError, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m    501\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m(err, request\u001b[39m=\u001b[39mrequest)\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.10/site-packages/urllib3/connectionpool.py:714\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_proxy(conn)\n\u001b[1;32m    713\u001b[0m \u001b[39m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 714\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[1;32m    715\u001b[0m     conn,\n\u001b[1;32m    716\u001b[0m     method,\n\u001b[1;32m    717\u001b[0m     url,\n\u001b[1;32m    718\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[1;32m    719\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    720\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    721\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    722\u001b[0m )\n\u001b[1;32m    724\u001b[0m \u001b[39m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    725\u001b[0m \u001b[39m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    726\u001b[0m \u001b[39m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    727\u001b[0m \u001b[39m# mess.\u001b[39;00m\n\u001b[1;32m    728\u001b[0m response_conn \u001b[39m=\u001b[39m conn \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m release_conn \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.10/site-packages/urllib3/connectionpool.py:466\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    461\u001b[0m             httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39mgetresponse()\n\u001b[1;32m    462\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    463\u001b[0m             \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    464\u001b[0m             \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    465\u001b[0m             \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m--> 466\u001b[0m             six\u001b[39m.\u001b[39;49mraise_from(e, \u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    467\u001b[0m \u001b[39mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    468\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_timeout(err\u001b[39m=\u001b[39me, url\u001b[39m=\u001b[39murl, timeout_value\u001b[39m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.10/site-packages/urllib3/connectionpool.py:461\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    459\u001b[0m     \u001b[39m# Python 3\u001b[39;00m\n\u001b[1;32m    460\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 461\u001b[0m         httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[1;32m    462\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    463\u001b[0m         \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    464\u001b[0m         \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    465\u001b[0m         \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m    466\u001b[0m         six\u001b[39m.\u001b[39mraise_from(e, \u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.10/http/client.py:1375\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1373\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1374\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1375\u001b[0m         response\u001b[39m.\u001b[39;49mbegin()\n\u001b[1;32m   1376\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m:\n\u001b[1;32m   1377\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.10/http/client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[39m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 318\u001b[0m     version, status, reason \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_status()\n\u001b[1;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m status \u001b[39m!=\u001b[39m CONTINUE:\n\u001b[1;32m    320\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.10/http/client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_read_status\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 279\u001b[0m     line \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mreadline(_MAXLINE \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m), \u001b[39m\"\u001b[39m\u001b[39miso-8859-1\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    280\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(line) \u001b[39m>\u001b[39m _MAXLINE:\n\u001b[1;32m    281\u001b[0m         \u001b[39mraise\u001b[39;00m LineTooLong(\u001b[39m\"\u001b[39m\u001b[39mstatus line\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    706\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.10/ssl.py:1274\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1271\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1272\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m   1273\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[0;32m-> 1274\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nbytes, buffer)\n\u001b[1;32m   1275\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1276\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.10/ssl.py:1130\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1128\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1129\u001b[0m     \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1130\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m, buffer)\n\u001b[1;32m   1131\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1132\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def preprocess_google_shcolar_step2(source_path, output_path, start, end):\n",
    "    print(\"Starting merging search results from Google Scholar...\")\n",
    "\n",
    "    df = pd.read_csv(source_path, header=None, sep=',')\n",
    "    df.columns = [\"Title\", \"full_text_url\", \"full_text_source\", \"pdf_url\", \"pdf_source\"]\n",
    "\n",
    "    for ind in range(start, end):\n",
    "        # get doi from url\n",
    "        if df[\"full_text_url\"][ind] == df[\"full_text_url\"][ind]: # there's a full_text_url\n",
    "            url = str(df[\"full_text_url\"][ind]).strip()\n",
    "            source = str(df[\"full_text_source\"][ind]).strip()\n",
    "            doi = plib.url2doi(url)\n",
    "        else:\n",
    "            doi = np.nan\n",
    "        # # get pmid from DOI\n",
    "        # if doi == doi: # there's doi\n",
    "        #     pmid = plib.doi2pmid(doi)\n",
    "        # else: # doi not found\n",
    "        #     pmid = np.nan\n",
    "        # # get pmcid, full_text_url, full_text_source\n",
    "        # if pmid != pmid: # pmid is np.nan\n",
    "        #     pmcid = np.nan\n",
    "        #     if doi == doi: # doi is not np.nan\n",
    "        #         full_text_url = \"https://doi.org/\" + str(doi).strip()\n",
    "        #         full_text_source = \"DOI\"\n",
    "        #     else:\n",
    "        #         full_text_url = np.nan\n",
    "        #         full_text_source = np.nan\n",
    "        # else: # pmid is not np.nan\n",
    "        #     # request the webpage\n",
    "        #     url = \"https://pubmed.ncbi.nlm.nih.gov/\" + pmid + \"/\"\n",
    "        #     # proxies = plib.get_proxies()\n",
    "        #     soup = plib.request_webpage(url)\n",
    "        #     # print(soup)\n",
    "\n",
    "        #     # get pmcid\n",
    "        #     try:\n",
    "        #         pmcid = soup.find_all(\"span\", {\"class\": \"identifier pmc\"})[0].find_all(\"a\", {\"class\": \"id-link\"})[0].get_text().strip()\n",
    "        #     except:\n",
    "        #         pmcid = np.nan\n",
    "        #     # print(pmcid)\n",
    "            \n",
    "        #     # get full_text_url, full_text_source\n",
    "        #     if pmcid == pmcid: # pmcid is not np.nan\n",
    "        #         full_text_url = \"https://www.ncbi.nlm.nih.gov/pmc/articles/\" + pmcid + \"/\"\n",
    "        #         full_text_source = \"PMC\"\n",
    "        #     else: # pmcid is not np.nan\n",
    "        #         try:\n",
    "        #             full_text_url = soup.find_all(\"div\", {\"class\": \"full-text-links-list\"})[0].find_all(\"a\", {\"class\": \"link-item dialog-focus\"})[0][\"href\"].strip()\n",
    "        #             full_text_source = soup.find_all(\"div\", {\"class\": \"full-text-links-list\"})[0].find_all(\"a\", {\"class\": \"link-item dialog-focus\"})[0][\"data-ga-action\"].strip()\n",
    "        #         except:\n",
    "        #             full_text_url = np.nan\n",
    "        #             full_text_source = np.nan\n",
    "\n",
    "        columns = [\"DOI\", \"PMID\", \"PMCID\", \"Title\", \"full_text_url\", \"full_text_source\", \"pdf_url\", \"pdf_source\"]\n",
    "        pmid = np.nan\n",
    "        pmcid = np.nan\n",
    "        row = {\n",
    "            \"DOI\": [doi],\n",
    "            \"PMID\": [pmid],\n",
    "            \"PMCID\": [pmcid],\n",
    "            \"Title\": [df[\"Title\"][ind]],\n",
    "            \"full_text_url\": [df[\"full_text_url\"][ind]],\n",
    "            \"full_text_source\": [df[\"full_text_source\"][ind]],\n",
    "            \"pdf_url\": [df[\"pdf_url\"][ind]],\n",
    "            \"pdf_source\": [df[\"pdf_source\"][ind]]\n",
    "        }\n",
    "        # print(row)\n",
    "\n",
    "        if not plib.add_row_to_csv(output_path, row, columns):\n",
    "            print(\"Error detected when adding a row to csv!\")\n",
    "        \n",
    "        print(doi)\n",
    "        if doi != doi:\n",
    "            print([df[\"full_text_url\"][ind]])\n",
    "        print(ind)\n",
    "# --------------------start of test code--------------------\n",
    "source_path = fpath.poten_litera_gs_processed_step1\n",
    "output_path = fpath.poten_litera_gs_processed_step2\n",
    "plib.clear_file(output_path)\n",
    "# ---------------------end of test code---------------------\n",
    "\n",
    "# --------------------start of test code--------------------\n",
    "# df = pd.read_csv(source_path, header=None, sep=',')\n",
    "# df.columns = [\"Title\", \"full_text_url\", \"full_text_source\", \"pdf_url\", \"pdf_source\"]\n",
    "# print(df.head(3))\n",
    "# print(df.shape)\n",
    "# # # (905, 5)\n",
    "# ---------------------end of test code---------------------\n",
    "\n",
    "# --------------------start of test code--------------------\n",
    "# full_text_source = set(df['full_text_source'].tolist())\n",
    "# print(full_text_source)\n",
    "# # {'www.frontiersin.org', 'www.elibrary.ru', 'orca.cardiff.ac.uk', 'www.jneurosci.org', \n",
    "# # 'europepmc.org', 'www.theses.fr', 'www.biorxiv.org', 'submissions.mirasmart.com', \n",
    "# # 'royalsocietypublishing.org', 'www.science.org', 'thejns.org', \n",
    "# # 'escholarship.mcgill.ca', 'www.cambridge.org', 'movementdisorders.onlinelibrary.wiley.com', \n",
    "# # 'www.ahajournals.org', 'books.google.de', 'www.mdpi.com', 'www.sciencedirect.com', \n",
    "# # 'ieeexplore.ieee.org', 'academic.oup.com', 'www.pnas.org', 'physoc.onlinelibrary.wiley.com', \n",
    "# # 'www.jstage.jst.go.jp', 'wakespace.lib.wfu.edu', 'elibrary.ru', 'www.cabdirect.org', \n",
    "# # 'www.tandfonline.com', 'www.jpn.ca', 'jpet.aspetjournals.org', 'onlinelibrary.wiley.com', \n",
    "# # 'open.bu.edu', 'tbiomed.biomedcentral.com', 'www.liebertpub.com', 'journals.lww.com', \n",
    "# # 'agro.icm.edu.pl', 'ekja.org', 'analyticalsciencejournals.onlinelibrary.wiley.com', \n",
    "# # 'n.neurology.org', 'pubs.asahq.org', 'journals.sagepub.com', 'neuro.psychiatryonline.org', \n",
    "# # 'karger.com', 'nyaspubs.onlinelibrary.wiley.com', 'pure.mpg.de', 'elifesciences.org', \n",
    "# # 'link.springer.com', 'psycnet.apa.org', 'jnnp.bmj.com', 'www.degruyter.com', 'ajp.psychiatryonline.org', \n",
    "# # 'journals.physiology.org', 'www.nature.com', 'www.jstor.org', 'var.scholarpedia.org', 'www.eneuro.org', \n",
    "# # 'journals.plos.org', 'www.cell.com', 'www.ncbi.nlm.nih.gov', 'www.taylorfrancis.com', \n",
    "# # 'bmcneurosci.biomedcentral.com', nan, 'jamanetwork.com'}\n",
    "# ---------------------end of test code---------------------\n",
    "\n",
    "# --------------------start of test code--------------------\n",
    "# # [\"Title\", \"full_text_url\", \"full_text_source\", \"pdf_url\", \"pdf_source\"]\n",
    "# print(df[\"Title\"].isnull().any().any())\n",
    "# print(df[\"full_text_url\"].isnull().any().any())\n",
    "# print(df[\"full_text_source\"].isnull().any().any())\n",
    "# print(df[\"pdf_url\"].isnull().any().any())\n",
    "# print(df[\"pdf_source\"].isnull().any().any())\n",
    "# # False, True, True, True, True\n",
    "# # full_text_url, full_text_source, pdf_url, pdf_source contain np.nan\n",
    "# # we need to fill in what are missing\n",
    "# ---------------------end of test code---------------------\n",
    "\n",
    "# --------------------start of test code--------------------\n",
    "preprocess_google_shcolar_step2(source_path, output_path, 0, 1000)\n",
    "# ---------------------end of test code---------------------\n",
    "\n",
    "# --------------------start of test code--------------------\n",
    "# df = pd.read_csv(output_path, header=None, sep=',')\n",
    "# print(df.head(3))\n",
    "# ---------------------end of test code---------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_seed_paper_spanning(source_path, output_path):\n",
    "    print(\"Starting preprocessing search results from spanning citations of seed paper...\")\n",
    "    return True\n",
    "# --------------------start of test code--------------------\n",
    "# test code\n",
    "# ---------------------end of test code---------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_cocomac_paper(source_path, output_path):\n",
    "    print(\"Starting preprocessing search results from CoCoMac papers...\")\n",
    "    return True\n",
    "# --------------------start of test code--------------------\n",
    "# test code\n",
    "# ---------------------end of test code---------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure at least PMID and PMCID is present as two of the four identifiers, otherwise manually fill in\n",
    "def fill_in_elements(file_path):\n",
    "    # PMID -> PMCID\n",
    "    # done already\n",
    "    # PMCID -> PMID\n",
    "    # done already\n",
    "    # PMID -> DOI\n",
    "    df = pd.read_csv(file_path, sep = \",\")\n",
    "    for ind in df.index:\n",
    "        if (df[\"PMID\"][ind] == df[\"PMID\"][ind]) and (df[\"DOI\"][ind] != df[\"DOI\"][ind]):\n",
    "            pmid = df[\"PMID\"][ind]\n",
    "            url = \"https://pubmed.ncbi.nlm.nih.gov/\" + pmid + \"/\"\n",
    "            print(url)\n",
    "            response = requests.get(url, headers = plib.headers)\n",
    "            if response.status_code != 200:\n",
    "                raise Exception(\"Error when request webpages!\")\n",
    "            soup = BeautifulSoup(response.content, \"lxml\")\n",
    "            l = soup.find_all(\"a\", {\"class: id-link\"}, {\"data-ga-action\": \"DOI\"})\n",
    "            if(len(l) != 0):\n",
    "                # print(l[0].get_text().strip())\n",
    "                df.at[ind, \"DOI\"] = l[0].get_text().strip()\n",
    "            else:\n",
    "                df.at[ind, \"DOI\"] = np.nan\n",
    "    df.to_csv(fpath.poten_litera_csv, header = True, index = False)\n",
    "    print(\"All 3 identifiers: DOI, PMID, and PMCID filled in when possible.\")\n",
    "# --------------------start of test code--------------------\n",
    "# test code\n",
    "# ---------------------end of test code---------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplciations based on identifiers in the potential related literature\n",
    "def merge_and_remove_dupli(file_path):\n",
    "    df = pd.read_csv(file_path, sep = \",\")\n",
    "    print(len(df))\n",
    "    df = df.drop_duplicates(subset=['DOI'])\n",
    "    df = df.drop_duplicates(subset=['PMID'])\n",
    "    df = df.drop_duplicates(subset=['PMCID'])\n",
    "    print(len(df))\n",
    "    # plib.clear_file(fpath.poten_litera_csv)\n",
    "    # df.csv(fpath.poten_litera_csv, idnex = None)\n",
    "    print(\"Duplication in the potential related literature removed.\")\n",
    "    print(\"Found \" + len(df) + \" potential related literature in total.\")\n",
    "# --------------------start of test code--------------------\n",
    "# test code\n",
    "# ---------------------end of test code---------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Main program: </h3> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # preprocess search results from PubMed\n",
    "\n",
    "# source_path = fpath.poten_litera_pubmed\n",
    "# output_path = fpath.poten_litera_pubmed_processed\n",
    "\n",
    "# # clear the file\n",
    "# plib.clear_file(output_path)\n",
    "\n",
    "# # preprocess search results from PubMed\n",
    "# # 2606 results\n",
    "# preprocess_pubmed(source_path, output_path, columns, 2565, 2606)\n",
    "# print(\"preprocessing results from PubMed succeeded!\")\n",
    "# # print(\"Attention! Something went wrong when preprocessing results from PubMed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # clear the file\n",
    "# plib.clear_file(fpath.poten_litera_wos)\n",
    "\n",
    "# # combine the 2 files of search results from web of science\n",
    "# source_path_1 = fpath.poten_litera_wos_1\n",
    "# source_path_2 = fpath.poten_litera_wos_2\n",
    "# df_1 = pd.read_csv(source_path_1, sep=';')\n",
    "# df_2 = pd.read_csv(source_path_2, sep=';')\n",
    "# df_1.to_csv(fpath.poten_litera_wos, header=True, index=False, sep=\";\")\n",
    "# df_2.to_csv(fpath.poten_litera_wos, mode=\"a\", header=False, index=False, sep=\";\")\n",
    "# --------------------start of test code--------------------\n",
    "# df = pd.read_csv(fpath.poten_litera_wos, sep=';')\n",
    "# print(df.head(3))\n",
    "# print(df.shape)\n",
    "# (1976, 72)\n",
    "# ---------------------end of test code---------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # preprocess search results from Web of Science\n",
    "\n",
    "# source_path = fpath.poten_litera_wos\n",
    "# output_path = fpath.poten_litera_wos_processed\n",
    "\n",
    "# # clear the file\n",
    "# # plib.clear_file(output_path)\n",
    "\n",
    "# # preprocess search results from Web of Science\n",
    "# # 1976 results\n",
    "# preprocess_webofscience(source_path, output_path, columns, 0, 1976)\n",
    "# print(\"preprocessing results from Web of Science succeeded!\")\n",
    "# # print(\"Attention! Something went wrong when preprocessing results from Web of Science!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # preprocess search results from Europe PMC\n",
    "\n",
    "# source_path = fpath.poten_litera_eupmc\n",
    "# output_path = fpath.poten_litera_eupmc_processed\n",
    "\n",
    "# # clear the file\n",
    "# # plib.clear_file(output_path)\n",
    "\n",
    "# # preprocess search results from Europe PMC\n",
    "# preprocess_eupmc(source_path, output_path, columns, 0, 9140)\n",
    "# # 9140 results\n",
    "# print(\"preprocessing results from Europe PMC succeeded!\")\n",
    "# # print(\"Attention! Something went wrong when preprocessing results from Europe PMC!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # preprocess search results from Google Scholar step 1\n",
    "\n",
    "# source_path = fpath.poten_litera_gs\n",
    "# output_path = fpath.poten_litera_gs_processed_step1\n",
    "\n",
    "# # clear the file\n",
    "# # plib.clear_file(output_path)\n",
    "\n",
    "# # preprocess search results from Google Scholar\n",
    "# preprocess_google_shcolar_step1(source_path, output_path, 0, 1000)\n",
    "# # 905 results\n",
    "# print(\"step 1 of preprocessing results from Google Scholar succeeded!\")\n",
    "# # print(\"Attention! Something went wrong when preprocessing results from Google Scholar step 1!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # preprocess search results from Google Scholar step 2\n",
    "\n",
    "# source_path = fpath.poten_litera_gs_processed_step1\n",
    "# output_path = fpath.poten_litera_gs_processed_step2\n",
    "\n",
    "# # clear the file\n",
    "# # plib.clear_file(output_path)\n",
    "\n",
    "# # preprocess search results from Google Scholar\n",
    "# preprocess_google_shcolar_step2(source_path, output_path, 0, 905)\n",
    "# # 905 results\n",
    "# print(\"step 2 of preprocessing results from Google Scholar succeeded!\")\n",
    "# # print(\"Attention! Something went wrong when preprocessing results from Google Scholar step 2!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # preprocess search results from spanning citations of seed paper\n",
    "\n",
    "# preprocess_seed_paper_spanning(source_path, output_path, columns):\n",
    "# print(\"preprocessing results from spanning citations of seed papers succeeded!\")\n",
    "# # print(\"Attention! Something went wrong when preprocessing results from spanning citations of seed papers!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # preprocess search results from CoCoMac papers\n",
    "\n",
    "# preprocess_cocomac_paper(source_path, output_path, columns)\n",
    "# print(\"preprocessing results from CoCoMac papers succeeded!\")\n",
    "# # print(\"Attention! Something went wrong when preprocessing results from CoCoMac papers!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # fill in all identifiers in the columns when possible\n",
    "\n",
    "# file_path = fpath.poten_litera\n",
    "# fill_in_elements(file_path, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # merge all search results and remove duplication by identifiers\n",
    "\n",
    "# # identifier = [\"DOI\", \"PMID\", \"PMCID\"]\n",
    "# file_path = fpath.poten_litera\n",
    "# merge_and_remove_dupli(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Next step: automatic filtering </h3>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
