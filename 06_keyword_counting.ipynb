{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keyword counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "from nltk import ngrams\n",
    "from matplotlib import pyplot as plt\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-10 23:04:17 GM01X680 metapub.config[46856] WARNING NCBI_API_KEY was not set.\n"
     ]
    }
   ],
   "source": [
    "# import internal modules\n",
    "import file_path_management as fpath\n",
    "import public_library as plib\n",
    "import parameters as params\n",
    "import dataframe_columns as df_col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predefined fucntions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_word_from_text(text, keyword): \n",
    "    # if text == np.nan or text == \"\", raise error\n",
    "    if text != text or text == \"\":  \n",
    "        return 'NA'\n",
    "    \n",
    "    # process word\n",
    "    keyword = keyword.lower()\n",
    "\n",
    "    # process text\n",
    "    text = plib.process_text(text, lower=True)\n",
    "\n",
    "    # word tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # length of the keyword\n",
    "    len_word = len(keyword.split())\n",
    "    \n",
    "    # get the ngrams of length len_word from text\n",
    "    ng = list(ngrams(tokens, len_word))\n",
    "    words = [' '.join(gram) for gram in ng]\n",
    "    # print(words)\n",
    "\n",
    "    # count keyword\n",
    "    count = 0\n",
    "    if keyword in params.exact_match_kw_list:       # if word is in exact_match_kw_list, use exact match\n",
    "        for word in words:\n",
    "            if keyword == word:\n",
    "                count += 1\n",
    "    else:                                           # if word is not in exact_match_kw_list, use fuzzy match\n",
    "        count = text.count(keyword)\n",
    "    return count\n",
    "# --------------------Start of test code--------------------\n",
    "# # text = 'This all.6 apple 6i7s very_tasty？、 apple, 6i7s 2but-the banana this is not delicious at Is all.6'\n",
    "# # text = \"cat of the dopcate innervaton in innervation the macaque and human thalamus Miguel Ángel García-Cabezas,aBeatriz Rico,a,b Miguel Ángel Sánchez-González,aand Carmen Cavadaa,⁎ aDepartamento de Anatomía, Histología y Neurociencia, Facultad de Medicina, Universidad Autónoma de Madrid, C/Arzobispo Morcillo s/n, 28029 Madrid, Spain bInstituto de Neurociencias de Alicante, Universidad Miguel Hernández-CSIC, 03550 Sant Joan d ’Alacant, Spain Received 19 April 2006; revised 8 June 2006; accepted 11 July 2006 Available online 30 November 2006 We recently defined the thalamic dopaminergic system in primates; it arises from numerous dopaminergic cell groups and selectively targetsnumerous thalamic nuclei. Given the central position of the thalamus in subcortical and cortical interplay, and the functional relevance of dopamine neuromodulation in the brain, detailing dopamine dis-tribution in the thalamus should supply important information. Tothis end we performed immunohistochemistry for dopamine and the dopamine transporter in the thalamus of macaque monkeys and humans to generate maps, in the stereotaxic coronal plane, of thedistribution of dopaminergic axons. The dopamine innervation of the thalamus follows the same pattern in both species and is most dense in midline limbic nuclei, the mediodorsal and lateral posteriorassociation nuclei, and in the ventral lateral and ventral anteriormotor nuclei. This distribution suggests that thalamic dopamine has a prominent role in emotion, attention, cognition and complex somatosensory and visual processing, as well as in motor control.Most thalamic dopaminergic axons are thin and varicose and targetboth the neuropil and small blood vessels, suggesting that, besides neuronal modulation, thalamic dopamine may have a direct influence on microcirculation. The maps provided here should be a usefulreference in future experimental and neuroimaging studies aiming atclarifying the role of the thalamic dopaminergic system in health and in conditions involving brain dopamine, including Parkinson ’s disease, drug addiction and schizophrenia.© 2006 Elsevier Inc. All rights reserved. Keywords: Dopamine; Thalamus; Monkey; Human; Primate; Dopamine transporter; Parkinson; Schizophrenia; AddictionIntroduction The thalamus is made up of multiple nuclei relaying information from subcortical centers or from other cortices to the cerebral cortex (Sherman and Guillery, 2005 ), as well as the striatum, the nucleus accumbens and the amygdala ( Steriade et al., 1997 ). In addition to specific subcortical and cortical afferents, the primate thalamus receives axons containing the neuromodulators acetylcholine (Heckers et al., 1992 ), histamine ( Manning et al., 1996 ), serotonin (Morrison and Foote, 1986; Lavoie and Parent, 1991 ), and the catecholamines adrenaline ( Rico and Cavada, 1998a ), noradrenaline (Morrison and Foote, 1986; Ginsberg et al., 1993 ) and dopamine (Sánchez-González et al., 2005 ). Until recently, the existence of significant dopamine innervation in the primate thalamus has been largely ignored, probably becausedopamine innervation of the rodent thalamus is very scant(Groenewegen, 1988; Papadopoulos and Parnavelas, 1990 ). However, fragmentary data scattered through the literature endorse the presence of dopamine innervation in the primate thalamus.Postmortem biochemical studies showed the presence of dopamine in the thalamus of macaques ( Brown et al., 1979; Goldman-Rakic and Brown, 1981; Pifl et al., 1990, 1991 ) and human subjects ( Oke and Adams, 1987 ). Later, receptor binding and in situ hybridization analyses detected the presence of dopamine D2-like ( Joyce et al., 1991; Kessler et al., 1993; Hall et al., 1996; Langer et al., 1999;Rieck et al., 2004 ) and D3-like receptors ( Gurevich and Joyce, 1999 ) in several human thalamic nuclei. Positron emission tomography (PET) radioligand studies have also demonstratedthe presence of the dopamine transporter (DAT) ( Wang et al., 1995; Halldin et al., 1996; Helfenbein et al., 1999; Brownell et al., 2003 ) and of D2-like receptors ( Farde et al., 1997; Langer et al., 1999; Okubo et al., 1999; Brownell et al., 2003; Rieck et al., 2004 ) in the human and macaque thalamus. In the course of PET studies focusing on schizophrenia, D2- and D3-like radioligand binding was also found in the thalamus of control subjects ( Talvik et al., 2003; Yasuno et al., 2004 ). Finally, an immunohistochemical study using anti-DAT antibodies detected the presence of dopaminergic www.elsevier.com/locate/ynimg NeuroImage 34 (2007) 965 –984 ⁎Corresponding author. Fax: +34 91 497 53 15. E-mail address: carmen.cavada@uam.es (C. Cavada). Available online on ScienceDirect (www.sciencedirect.com). 1053-8119/$ - see front matter © 2006 Elsevier Inc. All rights reserved. doi:10.1016/j.neuroimage.2006.07.032\"\n",
    "# text = \"Effect ffect of effect ofs LGn) effect ofsLGns LGnCate Attentive  ca t Fixation in Macaque asThalamusss andc Cortexs D. B. BENDER AND M. YOUAKIM Department of Physiology and Biophysics, School of Medicine and Biomedical Sciences, University at Buffalo, State University of New York, Buffalo, New York 14214 Received 29 December 1999; accepted in final form 21 September 2000 Bender, D. B. and M. Youakim. Effect of attentive fixation in macaque thalamus and cortex. J Neurophysiol 85: 219234, 2001. Attentional modulation of neuronal responsiveness is common in many areas of visual cortex. We examined whether attentional modulation in the visual thalamus was quantitatively similar to that in cortex. Identical procedures and apparatus were used to compare attentional modulation of single neurons in seven different areas of the visual system: the lateral geniculate, three visual subdivisions of the pulvinar [inferior, lateral, dorsomedial part of lateral pulvinar (Pdm)], and three areas of extrastriate cortex representing early, intermediate, and late stages of cortical processing (V2, V4/PM, area 7a). A simple fixation task controlled transitions among three attentive states. The animal waited for a fixation point to appear (ready state), fixated the point until it dimmed (fixation state), and then waited idly to begin the next trial (idle state). Attentional modulation was estimated by flashing an identical, irrelevant stimulus in a neurons receptive field during each of the three states; the three responses defined a response vector whose deviation from the line of equal response in all three states (the main diagonal) indicated the character and magnitude of attentional modulation. Attentional modulation was present in all visual areas except the lateral geniculate, indicating that modulation was of central origin. Prevalence of modulation was modest (26%) in pulvinar, and increased from 21% in V2 to 43% in 7a. Modulation had a push-pull character (as many cells facilitated as suppressed) with respect to the fixation state in all areas except Pdm where all cells were suppressed during fixation. The absolute magnitude of attentional modulation, measured by the angle between response vector and main diagonal expressed as a percent of the maximum possible angle, differed among brain areas. Magnitude of modulation was modest in the pulvinar (1926%), and increased from 22% in V2 to 41% in 7a. However, average trial-to-trial variability of response, measured by the coefficient of variation, also increased across brain areas so that its difference among areas accounted for more than 90% of the difference in modulation magnitude among areas. We also measured attentional modulation by the ratio of cell discharge due to attention divided by discharge variability. The resulting signal-tonoise ratio of attention was small and constant, 1.3 6 10%, across all areas of pulvinar and cortex. We conclude that the pulvinar, but not the lateral geniculate, is as strongly affected by attentional state as any area of visual cortex we studied and that attentional modulation amplitude is closely tied to intrinsic variability of response. INTRODUCTION It is now clear that attention can affect the responsiveness of neurons throughout visual cortex. Visually responsive cortex includes a number of distinct areas beyond striate cortex, or V1. Beginning with V2, these extrastriate areas are organized into two partially segregated, roughly hierarchical systems (reviews in Felleman and Van Essen 1991; Maunsell and Newsome 1987; Ungerleider and Mishkin 1982; Van Essen 1985). One includes dorsally located areas such as V3A, MT, and MST and leads into area 7a in the inferior parietal lobule. The other includes more ventrally located areas such as V4 and TEO and leads into area TE in the temporal lobe. Recordings from single neurons in many of these areas show that neuronal excitability depends on the animals attentive state (reviews in Colby 1991; Desimone and Duncan 1995; Lock and Bender 1999; Maunsell 1995; Motter 1998). Typically the effect of attention is modest: a small increase or decrease in magnitude of response to a visual stimulus relative to a control condition. Such modulation can be found at virtually every level of the cortical hierarchy, including V1. A variety of behavioral paradigms have been used to manipulate attention, and these show that the prevalence and magnitude of attentional modulation can depend substantially on both the behavioral paradigm and the cortical area in which its effects are measured. Furthermore factors such as task difficulty, the extent to which a task engages the functions of an area, and whether multiple stimuli compete for attention all can affect the modulation (Luck et al. 1997; Motter 1993; Richmond and Sato 1987). To what extent does the thalamus contribute to, or participate in, the attentional modulation that is so widespread throughout visual cortex? Three thalamic nuclei are closely interrelated with visual cortex: the lateral geniculate nucleus, the pulvinar, and the reticular nucleus of the thalamus. All have been thought to be involved in one form of attention or another (e.g., Guillery et al. 1998; Koch and Ullman 1985; Olshausen et al. 1993). The lateral geniculate projects almost exclusively to V1 with little or no output to extrastriate cortex. Layer 6 of both extrastriate and striate cortex project back to the geniculate, potentially modulating transmission through it. The pulvinar has at least three distinct visual subdivisions. The inferior (PI) and lateral pulvinar (PL) contain two separate visuotopic maps (Bender 1981). PI is driven by input from V1 (Bender 1983) but also receives input from extrastriate cortex and the superior colliculus. It projects mainly to V2, V3, V3A, and MT. PL likewise receives input from V1 and extrastriate cortex, but may have a particular affinity\"\n",
    "# keyword = 'effect ofs L'\n",
    "# count = count_word_from_text(text, keyword)\n",
    "# print(count)\n",
    "# ---------------------End of test code---------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_kw_group_from_text(text, kw_group):\n",
    "    # if text == np.nan or text == \"\", raise error\n",
    "    if text != text or text == \"\":  \n",
    "        return 'NA'\n",
    "\n",
    "    # process the text\n",
    "    text = plib.process_text(text, lower=True)\n",
    "\n",
    "    # count the number of keywords\n",
    "    word_count = 0\n",
    "    for keyword in kw_group:\n",
    "        word_count += count_word_from_text(text, keyword)\n",
    "\n",
    "    return word_count\n",
    "# --------------------start of test code--------------------\n",
    "# # text = 'Virhesussiorhesuscat macaqua Cat Rhesus fRhesusor rhesus action: thalamic and cortical inputs to the macaque superior tract neural tracing, parietal lobule The dorsal visual stream, the cortical circuit that in the primate brain is mainly dedicated to the visual control of actions, is split into two routes, a lateral and a medial one, both involved in coding different aspects of sensorimotor control of actions. The lateral route, named \"lateral grasping network\", is mainly involved in the control of the distal part of prehension, namely grasping and manipulation. The medial route, named \"reach-to-grasp network\", is involved in the control of the full deployment of prehension act, from the direction of arm movement to the shaping of the hand according to the object to be grasped. In macaque monkeys, the reach-to-grasp network (the target of this review) includes areas of the superior parietal lobule (SPL) that hosts visual and somatosensory neurons well suited to control goal-directed limb movements toward stationary as well as moving objects. After a brief summary of the neuronal functional properties of these areas, we will analyze their cortical and thalamic inputs thanks to retrograde neuronal tracers separately injected into the SPL areas V6, V6A, PEc, and PE. These areas receive visual and somatosensory information distributed in a caudorostral, visuosomatic trend, and some of them are directly connected with the dorsal premotor cortex. This review is particularly focused on the origin and type of visual information reaching the SPL, and on the functional role this information can play in guiding limb interaction with objects in structured and dynamic environments. Area PEc; Area V6; Area V6A; Dorsal visual stream; Goal-directed arm movement; Sensorimotor integration.'\n",
    "# # text = \"rhesusSDistrirhesusbution rhesus of the dopamine innervation in the macaque and human thalamus Miguel Ángel García-Cabezas,aBeatriz Rico,a,b Miguel Ángel Sánchez-González,aand Carmen Cavadaa,⁎ aDepartamento de Anatomía, Histología y Neurociencia, Facultad de Medicina, Universidad Autónoma de Madrid, C/Arzobispo Morcillo s/n, 28029 Madrid, Spain bInstituto de Neurociencias de Alicante, Universidad Miguel Hernández-CSIC, 03550 Sant Joan d ’Alacant, Spain Received 19 April 2006; revised 8 June 2006; accepted 11 July 2006 Available online 30 November 2006 We recently defined the thalamic dopaminergic system in primates; it arises from numerous dopaminergic cell groups and selectively targetsnumerous thalamic nuclei. Given the central position of the thalamus in subcortical and cortical interplay, and the functional relevance of dopamine neuromodulation in the brain, detailing dopamine dis-tribution in the thalamus should supply important information. Tothis end we performed immunohistochemistry for dopamine and the dopamine transporter in the thalamus of macaque monkeys and humans to generate maps, in the stereotaxic coronal plane, of thedistribution of dopaminergic axons. The dopamine innervation of the thalamus follows the same pattern in both species and is most dense in midline limbic nuclei, the mediodorsal and lateral posteriorassociation nuclei, and in the ventral lateral and ventral anteriormotor nuclei. This distribution suggests that thalamic dopamine has a prominent role in emotion, attention, cognition and complex somatosensory and visual processing, as well as in motor control.Most thalamic dopaminergic axons are thin and varicose and targetboth the neuropil and small blood vessels, suggesting that, besides neuronal modulation, thalamic dopamine may have a direct influence on microcirculation. The maps provided here should be a usefulreference in future experimental and neuroimaging studies aiming atclarifying the role of the thalamic dopaminergic system in health and in conditions involving brain dopamine, including Parkinson ’s disease, drug addiction and schizophrenia.© 2006 Elsevier Inc. All rights reserved. Keywords: Dopamine; Thalamus; Monkey; Human; Primate; Dopamine transporter; Parkinson; Schizophrenia; AddictionIntroduction The thalamus is made up of multiple nuclei relaying information from subcortical centers or from other cortices to the cerebral cortex (Sherman and Guillery, 2005 ), as well as the striatum, the nucleus accumbens and the amygdala ( Steriade et al., 1997 ). In addition to specific subcortical and cortical afferents, the primate thalamus receives axons containing the neuromodulators acetylcholine (Heckers et al., 1992 ), histamine ( Manning et al., 1996 ), serotonin (Morrison and Foote, 1986; Lavoie and Parent, 1991 ), and the catecholamines adrenaline ( Rico and Cavada, 1998a ), noradrenaline (Morrison and Foote, 1986; Ginsberg et al., 1993 ) and dopamine (Sánchez-González et al., 2005 ). Until recently, the existence of significant dopamine innervation in the primate thalamus has been largely ignored, probably becausedopamine innervation of the rodent thalamus is very scant(Groenewegen, 1988; Papadopoulos and Parnavelas, 1990 ). However, fragmentary data scattered through the literature endorse the presence of dopamine innervation in the primate thalamus.Postmortem biochemical studies showed the presence of dopamine in the thalamus of macaques ( Brown et al., 1979; Goldman-Rakic and Brown, 1981; Pifl et al., 1990, 1991 ) and human subjects ( Oke and Adams, 1987 ). Later, receptor binding and in situ hybridization analyses detected the presence of dopamine D2-like ( Joyce et al., 1991; Kessler et al., 1993; Hall et al., 1996; Langer et al., 1999;Rieck et al., 2004 ) and D3-like receptors ( Gurevich and Joyce, 1999 ) in several human thalamic nuclei. Positron emission tomography (PET) radioligand studies have also demonstratedthe presence of the dopamine transporter (DAT) ( Wang et al., 1995; Halldin et al., 1996; Helfenbein et al., 1999; Brownell et al., 2003 ) and of D2-like receptors ( Farde et al., 1997; Langer et al., 1999; Okubo et al., 1999; Brownell et al., 2003; Rieck et al., 2004 ) in the human and macaque thalamus. In the course of PET studies focusing on schizophrenia, D2- and D3-like radioligand binding was also found in the thalamus of control subjects ( Talvik et al., 2003; Yasuno et al., 2004 ). Finally, an immunohistochemical study using anti-DAT antibodies detected the presence of dopaminergic www.elsevier.com/locate/ynimg NeuroImage 34 (2007) 965 –984 ⁎Corresponding author. Fax: +34 91 497 53 15. E-mail address: carmen.cavada@uam.es (C. Cavada). Available online on ScienceDirect (www.sciencedirect.com). 1053-8119/$ - see front matter © 2006 Elsevier Inc. All rights reserved. doi:10.1016/j.neuroimage.2006.07.032\"\n",
    "# text = \"Effect of cats Attentive Fixation in effect ofs Macaque Thalamus and Cortex D. B. BENDER AND M. YOUAKIM Department of Physiology and Biophysics, School of Medicine and Biomedical Sciences, University at Buffalo, State University of New York, Buffalo, New York 14214 Received 29 December 1999; accepted in final form 21 September 2000 Bender, D. B. and M. Youakim. Effect of attentive fixation in macaque thalamus and cortex. J Neurophysiol 85: 219234, 2001. Attentional modulation of neuronal responsiveness is common in many areas of visual cortex. We examined whether attentional modulation in the visual thalamus was quantitatively similar to that in cortex. Identical procedures and apparatus were used to compare attentional modulation of single neurons in seven different areas of the visual system: the lateral geniculate, three visual subdivisions of the pulvinar [inferior, lateral, dorsomedial part of lateral pulvinar (Pdm)], and three areas of extrastriate cortex representing early, intermediate, and late stages of cortical processing (V2, V4/PM, area 7a). A simple fixation task controlled transitions among three attentive states. The animal waited for a fixation point to appear (ready state), fixated the point until it dimmed (fixation state), and then waited idly to begin the next trial (idle state). Attentional modulation was estimated by flashing an identical, irrelevant stimulus in a neurons receptive field during each of the three states; the three responses defined a response vector whose deviation from the line of equal response in all three states (the main diagonal) indicated the character and magnitude of attentional modulation. Attentional modulation was present in all visual areas except the lateral geniculate, indicating that modulation was of central origin. Prevalence of modulation was modest (26%) in pulvinar, and increased from 21% in V2 to 43% in 7a. Modulation had a push-pull character (as many cells facilitated as suppressed) with respect to the fixation state in all areas except Pdm where all cells were suppressed during fixation. The absolute magnitude of attentional modulation, measured by the angle between response vector and main diagonal expressed as a percent of the maximum possible angle, differed among brain areas. Magnitude of modulation was modest in the pulvinar (1926%), and increased from 22% in V2 to 41% in 7a. However, average trial-to-trial variability of response, measured by the coefficient of variation, also increased across brain areas so that its difference among areas accounted for more than 90% of the difference in modulation magnitude among areas. We also measured attentional modulation by the ratio of cell discharge due to attention divided by discharge variability. The resulting signal-tonoise ratio of attention was small and constant, 1.3 6 10%, across all areas of pulvinar and cortex. We conclude that the pulvinar, but not the lateral geniculate, is as strongly affected by attentional state as any area of visual cortex we studied and that attentional modulation amplitude is closely tied to intrinsic variability of response. INTRODUCTION It is now clear that attention can affect the responsiveness of neurons throughout visual cortex. Visually responsive cortex includes a number of distinct areas beyond striate cortex,\"\n",
    "# kw_group = ['cat', 'macaque', 'macaca', 'effect of']\n",
    "# keywords_count = count_kw_group_from_text(text, kw_group)\n",
    "# print(keywords_count)\n",
    "# ---------------------end of test code---------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_sent(sent):\n",
    "    if not (sent.endswith('.') or sent.endswith('?') or sent.endswith('!')):\n",
    "        sent += '.'\n",
    "    \n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sent_from_text(text, kw_group):\n",
    "    if text != text or text == \"\":\n",
    "        return 'NA'\n",
    "    # preprocess text\n",
    "    text = plib.process_text(text, lower=True) \n",
    "    \n",
    "    sents = []\n",
    "\n",
    "    # sentence tokenize\n",
    "    all_sentences = sent_tokenize(text)\n",
    "\n",
    "    for sent in all_sentences:\n",
    "        # if the sentence has been added, continue\n",
    "        compl_sent = complete_sent(sent)\n",
    "        if compl_sent in sents:\n",
    "            continue\n",
    "        \n",
    "        # else, match and add\n",
    "        flag = False # this sentence is not matched yet\n",
    "\n",
    "        for keyword in kw_group:\n",
    "            keyword = keyword.lower()\n",
    "            # print(keyword)\n",
    "            \n",
    "            # match keyword\n",
    "            if keyword in params.exact_match_kw_list: # If the keyword is in exact match keyword list, use exact match\n",
    "                words = word_tokenize(compl_sent)\n",
    "                \n",
    "                for word in words:\n",
    "                    if word == keyword:\n",
    "                        sents.append(compl_sent)\n",
    "                        flag = True\n",
    "                        break\n",
    "                if flag:\n",
    "                    break\n",
    "            elif keyword in compl_sent: # If the keyword is not in exact match keyword list, use fuzzy match\n",
    "                sents.append(compl_sent)\n",
    "                break\n",
    "            else:\n",
    "                continue\n",
    "    \n",
    "    # convert set to string\n",
    "    sents_combined = ' '.join(sent for sent in sents)\n",
    "    sents_combined = sents_combined.strip()\n",
    "\n",
    "    return sents_combined\n",
    "# --------------------Start of test code--------------------\n",
    "# text = \"Effect of Attentive Fixation in macaque thalamus and Cortex. D. B. BENDER AND M. YOUAKIM Department of Physiology and Biophysics, School of Medicine and Biomedical Sciences, University at Buffalo, State University of New York, Buffalo, New York 14214 Received 29 December 1999; accepted in final form 21 September 2000 Bender, D. B. and M. Youakim. Effect of attentive fixation in macaque thalamus and cortex. J Neurophysiol 85: 219234, 2001. Attentional modulation of neuronal responsiveness is common in many areas of visual cortex. We examined whether attentional modulation in the visual thalamus was quantitatively similar to that in cortex. Identical procedures and apparatus were used to compare attentional modulation of single neurons in seven different areas of the visual system: the lateral geniculate, three visual subdivisions of the pulvinar [inferior, lateral, dorsomedial part of lateral pulvinar (Pdm)], and three areas of extrastriate cortex representing early, intermediate, and late stages of cortical processing (V2, V4/PM, area 7a). A simple fixation task controlled transitions among three attentive states. The animal waited for a fixation point to appear (ready state), fixated the point until it dimmed (fixation state), and then waited idly to begin the next trial (idle state). Attentional modulation was estimated by flashing an identical, irrelevant stimulus in a neurons receptive field during each of the three states; the three responses defined a response vector whose deviation from the line of equal response in all three states (the main diagonal) indicated the character and magnitude of attentional modulation. Attentional modulation was present in all visual areas except the lateral geniculate, indicating that modulation was of central origin. Prevalence of modulation was modest (26%) in pulvinar, and increased from 21% in V2 to 43% in 7a. Modulation had a push-pull character (as many cells facilitated as suppressed) with respect to the fixation state in all areas except Pdm where all cells were suppressed during fixation. The absolute magnitude of attentional modulation, measured by the angle between response vector and main diagonal expressed as a percent of the maximum possible angle, differed among brain areas. Magnitude of modulation was modest in the pulvinar (1926%), and increased from 22% in V2 to 41% in 7a. However, average trial-to-trial variability of response, measured by the coefficient of variation, also increased across brain areas so that its difference among areas accounted for more than 90% of the difference in modulation magnitude among areas. We also measured attentional modulation by the ratio of cell discharge due to attention divided by discharge variability. The resulting signal-tonoise ratio of attention was small and constant, 1.3 6 10%, across all areas of pulvinar and cortex. We conclude that the pulvinar, but not the lateral geniculate, is as strongly affected by attentional state as any area of visual cortex we studied and that attentional modulation amplitude is closely tied to intrinsic variability of response. INTRODUCTION It is now clear that attention can affect the responsiveness of neurons throughout visual cortex. Visually responsive cortex includes a number of distinct areas beyond striate cortex, or V1. Beginning with V2, these extrastriate areas are organized into two partially segregated, roughly hierarchical systems (reviews in Felleman and Van Essen 1991; Maunsell and Newsome 1987; Ungerleider and Mishkin 1982; Van Essen 1985). One includes dorsally located areas such as V3A, MT, and MST and leads into area 7a in the inferior parietal lobule. The other includes more ventrally located areas such as V4 and TEO and leads into area TE in the temporal lobe. Recordings from single neurons in many of these areas show that neuronal excitability depends on the animals attentive state (reviews in Colby 1991; Desimone and Duncan 1995; Lock and Bender 1999; Maunsell 1995; Motter 1998). Typically the effect of attention is modest: a small increase or decrease in magnitude of response to a visual stimulus relative to a control condition. Such modulation can be found at virtually every level of the cortical hierarchy, including V1. A variety of behavioral paradigms have been used to manipulate attention, and these show that the prevalence and magnitude of attentional modulation can depend substantially on both the behavioral paradigm and the cortical area in which its effects are measured. Furthermore factors such as task difficulty, the extent to which a task engages the functions of an area, and whether multiple stimuli compete for attention all can affect the modulation (Luck et al. 1997; Motter 1993; Richmond and Sato 1987). To what extent does the thalamus contribute to, or participate in, the attentional modulation that is so widespread throughout visual cortex? Three thalamic nuclei are closely interrelated with visual cortex: the lateral geniculate nucleus, the pulvinar, and the reticular nucleus of the thalamus. All have been thought to be involved in one form of attention or another (e.g., Guillery et al. 1998; Koch and Ullman 1985; Olshausen et al. 1993). The lateral geniculate projects almost exclusively to V1 with little or no output to extrastriate cortex. Layer 6 of both extrastriate and striate cortex project back to the geniculate, potentially modulating transmission through it. The pulvinar has at least three distinct visual subdivisions. The inferior (PI) and lateral pulvinar (PL) contain two separate visuotopic maps (Bender 1981). PI is driven by input from V1 (Bender 1983) but also receives input from extrastriate cortex and the superior colliculus. It projects mainly to V2, V3, V3A, and MT. PL likewise receives input from V1 and extrastriate cortex, but may have a particular affinity\"\n",
    "# kw_group = ['Cortex', 'Thalamus', 'Macaque']\n",
    "# sents = extract_sent_from_text(text, kw_group)\n",
    "# print(sents)\n",
    "# ---------------------End of test code---------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_texts(index, title, abstract, keywords):\n",
    "    txt_file_name = str(index) + \".txt\"\n",
    "    txt_path = os.path.join(fpath.text_folder, txt_file_name)\n",
    "    txt_500_path = os.path.join(fpath.processed_texts_of_length_500_folder, txt_file_name)\n",
    "    \n",
    "    text_tak = \"\"           # text from title, abstract, and keywords\n",
    "    text_500 = \"\"           # text from full text 500\n",
    "    text_full = \"\"          # text from full text\n",
    "\n",
    "    # from title, abstract, and keywords\n",
    "    # extract first 500 words from text_full and text_tak, if they are longer than 500 words\n",
    "    # if they are shorter than 500 words, expand them to 500 words by repeating them\n",
    "    if title == title:\n",
    "        text_tak = text_tak + title + \" \"\n",
    "    else:\n",
    "        pass  \n",
    "    if abstract == abstract:\n",
    "        text_tak = text_tak + abstract + \" \"\n",
    "    else:\n",
    "        pass\n",
    "    if keywords == keywords:\n",
    "        text_tak = text_tak + keywords + \" \"\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    text_tak = plib.process_text(text_tak, lower=True)\n",
    "        \n",
    "    if len(text_tak.split()) != 0:\n",
    "        text_tak = plib.process_text(text_tak, lower=True)\n",
    "        while len(text_tak.split()) < params.text_length_to_extract:\n",
    "            text_tak = text_tak + \" \" + text_tak\n",
    "        text_tak = ' '.join(text_tak.split()[:params.text_length_to_extract])\n",
    "        text_tak = plib.process_text(text_tak, lower=True)\n",
    "    else:\n",
    "        text_tak = \"\"\n",
    "    # print(text_tak)\n",
    "    # print(len(text_tak.split()))\n",
    "\n",
    "    # from limited length full text\n",
    "    if os.path.exists(txt_500_path):\n",
    "        with open(txt_500_path, \"r\", encoding='ascii') as f:\n",
    "            text_500 = f.read()\n",
    "    else:\n",
    "        pass\n",
    "        \n",
    "    if len(text_500.split()) != 0:\n",
    "        text_500 = plib.process_text(text_500, lower=True)\n",
    "        while len(text_500.split()) < params.text_length_to_extract:\n",
    "            text_500 = text_500 + \" \" + text_500\n",
    "        text_500 = ' '.join(text_500.split()[:params.text_length_to_extract])\n",
    "        text_500 = plib.process_text(text_500, lower=True)\n",
    "    else:\n",
    "        text_500 = \"\"\n",
    "    # print(text_500)\n",
    "    # print(len(text_500.split()))\n",
    "    \n",
    "    # from full text\n",
    "    if os.path.exists(txt_path):\n",
    "        with open(txt_path, \"r\", encoding='ascii') as f:\n",
    "            text_full = f.read()\n",
    "    else:\n",
    "        pass\n",
    "        \n",
    "    if len(text_full.split()) != 0:\n",
    "        text_full = plib.process_text(text_full, lower=True)\n",
    "    else:\n",
    "        text_full = \"\"\n",
    "    # print(text_full)\n",
    "    # print(len(text_full.split()))\n",
    "    \n",
    "    return text_tak, text_500, text_full\n",
    "# --------------------Start of test code--------------------\n",
    "# index = 0\n",
    "# title = \"hello\"\n",
    "# abstract = \"world\"\n",
    "# keywords =\"!\"\n",
    "# text_tak, text_500, text_full = get_texts(index, title, abstract, keywords)\n",
    "# ---------------------End of test code---------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sents_and_record(input_path, db_path, output_path, kept_copumns):\n",
    "    df_input = pd.read_csv(input_path, header=0, sep=',')\n",
    "\n",
    "    df_db = pd.read_csv(db_path, header=None, sep=',')\n",
    "    df_db.columns = df_col.db_columns\n",
    "    \n",
    "    df_output = df_input[kept_copumns]\n",
    "\n",
    "    for ind in df_input.index:\n",
    "        # get texts\n",
    "        index = int(df_input.at[ind, \"INDEX\"])\n",
    "        title = df_db.loc[df_db[\"INDEX\"].astype(int) == index, 'TITLE'].values[0]\n",
    "        abstract = df_db.loc[df_db[\"INDEX\"].astype(int) == index, 'ABSTRACT'].values[0]\n",
    "        keywords = df_db.loc[df_db[\"INDEX\"].astype(int) == index, 'KEYWORDS'].values[0]\n",
    "        text_tak, text_500, text_full = get_texts(index, title, abstract, keywords)\n",
    "\n",
    "        # text columns\n",
    "        text_column = df_col.text_columns_to_add\n",
    "        keys_list = list(params.ranking_kw_groups.keys())\n",
    "\n",
    "        # decide for the text\n",
    "        if text_full == text_full and text_full != \"\": # if full text is available, use full text\n",
    "            text = text_full\n",
    "        else: # otherwise, use tak (title + abstract + keywords)\n",
    "            text = text_tak\n",
    "\n",
    "        # extract sentences from text\n",
    "        text_list = []\n",
    "        for key in keys_list:\n",
    "            sents = extract_sent_from_text(text, params.ranking_kw_groups[key])\n",
    "            text_list.append(sents)\n",
    "        \n",
    "        # fill in column content\n",
    "        for i in range(len(text_column)): # add key value pair of ranking_kw_groups and values in text_group\n",
    "            key = text_column[i]\n",
    "            text_value = text_list[i]\n",
    "            df_output[key + \"_TEXT\"] = text_value\n",
    "\n",
    "        # csv columns\n",
    "        columns = kept_copumns + df_col.text_columns_to_add # add keyword group text\n",
    "        \n",
    "        # display the progress        \n",
    "        print(\"ind:\", ind, \"index:\", index)\n",
    "        print(\"\\n\")\n",
    "    \n",
    "    # read the csv file and reset index and add header\n",
    "    df_output.columns = columns\n",
    "    df_output.reset_index(drop=True, inplace=True)\n",
    "    df_output.to_csv(output_path, index=False, header=True, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_and_record(input_path, output_path, kept_columns):\n",
    "    # dataframe for input and output csv files\n",
    "    df_input = pd.read_csv(input_path, header=0, sep=\"\\t\")\n",
    "    df_output = df_input[kept_columns]\n",
    "    \n",
    "    # for ind in range(0, 10):\n",
    "    for ind in df_input.index:    \n",
    "        # get the texts\n",
    "        index = int(df_input.at[ind, \"INDEX\"])\n",
    "        title = df_input.at[ind, \"TITLE\"]\n",
    "        abstract = df_input.at[ind, \"ABSTRACT\"]\n",
    "        keywords = df_input.at[ind, \"KEYWORDS\"]\n",
    "        text_tak, text_500, text_full = get_texts(index, title, abstract, keywords)\n",
    "\n",
    "        # keys list of the ranking_kw_groups\n",
    "        keys_list = list(params.ranking_kw_groups.keys())\n",
    "\n",
    "        # count keywords from text_tak\n",
    "        count_list_tak = [0] * len(keys_list)\n",
    "        for i in range(len(count_list_tak)):\n",
    "            count_list_tak[i] = count_kw_group_from_text(text_tak, params.ranking_kw_groups[keys_list[i]])\n",
    "        # print(count_list_tak)\n",
    "        \n",
    "        # count keywords from text_500\n",
    "        count_list_500 = [0] * len(keys_list)\n",
    "        for i in range(len(count_list_500)):\n",
    "            count_list_500[i] = count_kw_group_from_text(text_500, params.ranking_kw_groups[keys_list[i]])\n",
    "        # print(count_list_500)\n",
    "\n",
    "        # count keywords from full text\n",
    "        count_list_full_text = [0] * len(keys_list)\n",
    "        for i in range(len(count_list_full_text)):\n",
    "            count_list_full_text[i] = count_kw_group_from_text(text_full, params.ranking_kw_groups[keys_list[i]])\n",
    "        # print(count_list_full_text)\n",
    "\n",
    "        # add key, value pair of keyword group counts\n",
    "        for i in range(len(keys_list)):\n",
    "            key = keys_list[i]\n",
    "            value = count_list_tak[i]\n",
    "            df_output.loc[ind, key+\"_COUNT_IN_TAK\"] = value\n",
    "            \n",
    "        for j in range(len(keys_list)):\n",
    "            key = keys_list[j]\n",
    "            value = count_list_500[j]\n",
    "            df_output.loc[ind, key+\"_COUNT_IN_500\"] = value\n",
    "\n",
    "        for k in range(len(keys_list)):\n",
    "            key = keys_list[k]\n",
    "            value = count_list_full_text[k]\n",
    "            df_output.loc[ind, key+\"_COUNT_IN_FULL_TEXT\"] = value\n",
    "        \n",
    "        # display the progress\n",
    "        line_number_in_csv = ind + 1\n",
    "        print(\"Line number:\", line_number_in_csv, \" INDEX:\", int(df_input.at[ind, \"INDEX\"]))\n",
    "    \n",
    "    # write the dataframe\n",
    "    df_output.columns = kept_columns + df_col.count_columns_to_add\n",
    "    df_output.reset_index(drop=True, inplace=True)\n",
    "    df_output.to_csv(output_path, index=False, header=True, sep='\\t')\n",
    "# --------------------start of test code--------------------\n",
    "# input_path = fpath.poten_litera_db\n",
    "# output_path = fpath.poten_litera_db_kw_count\n",
    "# kept_columns = df_col.index\n",
    "# count_and_record(input_path, output_path, kept_columns)\n",
    "# ---------------------end of test code---------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main program:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Distribution of text length of title + abstract + keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Distribution of text length of title + keywords + abstract\n",
    "# df = pd.read_csv(fpath.poten_litera_db, header=None, sep=',')\n",
    "# df.columns = df_col.db_columns\n",
    "\n",
    "# len_list = []\n",
    "\n",
    "# for ind in df.index:\n",
    "#     text = \"\"\n",
    "#     num_words = 0\n",
    "\n",
    "#     if df.at[ind, \"ABSTRACT\"] == df.at[ind, \"ABSTRACT\"]: # if abstract is available\n",
    "#         abstract = df.at[ind, \"ABSTRACT\"]\n",
    "#     else: # skip this article if abstract is not available\n",
    "#         continue\n",
    "#     if df.at[ind, \"TITLE\"] == df.at[ind, \"TITLE\"]:\n",
    "#         title = df.at[ind, \"TITLE\"]\n",
    "#     else:\n",
    "#         title = \"\"\n",
    "#     if df.at[ind, \"KEYWORDS\"] == df.at[ind, \"KEYWORDS\"]:\n",
    "#         keywords = df.at[ind, \"KEYWORDS\"]\n",
    "#     else:\n",
    "#         keywords = \"\"\n",
    "\n",
    "#     text = title + \" \" + abstract + \" \" + keywords\n",
    "    \n",
    "#     # process the text\n",
    "#     text = plib.process_text(text, lower=True)\n",
    "\n",
    "#     num_words = len(text.split())\n",
    "\n",
    "#     len_list.append(num_words)\n",
    "\n",
    "# # calculate the average and maximum number of words in the text\n",
    "# print(\"The number of articles considered:\", len(len_list))\n",
    "# print(\"Max of length:\", max(len_list))\n",
    "# print(\"Average length:\", np.mean(len_list))\n",
    "# print(\"Median length:\", np.median(len_list))\n",
    "# print(\"Std of length:\", np.std(len_list))\n",
    "\n",
    "# # sort the len_list and draw a histogram\n",
    "# len_list.sort()\n",
    "# plt.hist(len_list, bins=20)\n",
    "# plt.xlabel(\"Text legth of tak (title + abstract + keywords) text\")\n",
    "# plt.ylabel(\"Number of articles\")\n",
    "# plt.show()\n",
    "# # The number of articles considered: 9892\n",
    "# # Max of length: 1307\n",
    "# # Average length: 235.13121714516782\n",
    "# # Median length: 230.0\n",
    "# # Std of length: 79.72543466983504"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Extract sentences for the train_test_1000 set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Process the train_test_1000 set, extract sentences\n",
    "# input_path = fpath.poten_litera_testing_set_1000\n",
    "# db_path = fpath.poten_litera_db\n",
    "# output_path = fpath.poten_litera_testing_set_1000_text_extract\n",
    "# plib.clear_file(output_path)\n",
    "\n",
    "# extract_sents_and_record(input_path, db_path, output_path, kept_columns=df_col.train_test_1000_path_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read the db_final.csv and scan the rows and count the number of np.nans in the columns Macaque?(Y/N), Thalamus?(Y/N), Inject?(Y/N)\n",
    "# input_path = fpath.poten_litera_db_text_extract\n",
    "# df = pd.read_csv(input_path, header=0, sep=',')\n",
    "# df.columns = [\"INDEX\", \"DOI\", \"PMID\", \"PMCID\", \"FULL_TEXT_URL\", \"FULL_TEXT_SOURCE\", \"PDF_URL\", \"PDF_SOURCE\", \n",
    "#                \"TITLE\", \"ABSTRACT\", \"KEYWORDS\", \n",
    "#                \"SPIECIES_TEXT\", \"THALAM_TEXT\", \"INJECT_TEXT\", \n",
    "#                \"Macaque?(Y/N)\", \"Thalamus?(Y/N)\", \"Inject?(Y/N)\"]\n",
    "\n",
    "# macaque = 0\n",
    "# thalamus = 0\n",
    "# inject = 0\n",
    "\n",
    "# for ind in df.index:\n",
    "#     if df.at[ind, \"SPIECIES_TEXT\"] != df.at[ind, \"SPIECIES_TEXT\"]:\n",
    "#         macaque += 1\n",
    "#         print(\"No macaque in text!\")\n",
    "#         print(df.at[ind, \"INDEX\"])\n",
    "#         print(df.at[ind, \"FULL_TEXT_URL\"])\n",
    "#         print(\"\\n\")\n",
    "#     if df.at[ind, \"THALAM_TEXT\"] != df.at[ind, \"THALAM_TEXT\"]:\n",
    "#         thalamus += 1\n",
    "#         print(\"No thalamus in text!\")\n",
    "#         print(df.at[ind, \"INDEX\"])\n",
    "#         print(df.at[ind, \"FULL_TEXT_URL\"])\n",
    "#         print(\"\\n\")\n",
    "#     if df.at[ind, \"INJECT_TEXT\"] != df.at[ind, \"INJECT_TEXT\"]:\n",
    "#         inject += 1\n",
    "\n",
    "# print(\"Macaque:\", macaque)\n",
    "# print(\"Thalamus:\", thalamus)\n",
    "# print(\"Inject:\", inject)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Count keywords for the train_test_1000 set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read from poten_litera_db, count keywords, save to poten_litera_db_kw_count\n",
    "# input_path = fpath.poten_litera_testing_set_1000_text_extract\n",
    "# output_path = fpath.poten_litera_testing_set_1000_text_extract_and_count\n",
    "# plib.clear_file(output_path)\n",
    "\n",
    "# kept_columns = df_col.train_test_1000_path_columns\n",
    "# count_and_record(input_path, output_path, kept_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Keywords counting for the potential_related_literature_databse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_46856/3202169432.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_output.loc[ind, key+\"_COUNT_IN_TAK\"] = value\n",
      "/tmp/ipykernel_46856/3202169432.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_output.loc[ind, key+\"_COUNT_IN_TAK\"] = value\n",
      "/tmp/ipykernel_46856/3202169432.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_output.loc[ind, key+\"_COUNT_IN_TAK\"] = value\n",
      "/tmp/ipykernel_46856/3202169432.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_output.loc[ind, key+\"_COUNT_IN_TAK\"] = value\n",
      "/tmp/ipykernel_46856/3202169432.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_output.loc[ind, key+\"_COUNT_IN_TAK\"] = value\n",
      "/tmp/ipykernel_46856/3202169432.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_output.loc[ind, key+\"_COUNT_IN_TAK\"] = value\n",
      "/tmp/ipykernel_46856/3202169432.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_output.loc[ind, key+\"_COUNT_IN_TAK\"] = value\n",
      "/tmp/ipykernel_46856/3202169432.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_output.loc[ind, key+\"_COUNT_IN_TAK\"] = value\n",
      "/tmp/ipykernel_46856/3202169432.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_output.loc[ind, key+\"_COUNT_IN_500\"] = value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line number: 1  INDEX: 0\n",
      "Line number: 2  INDEX: 1\n",
      "Line number: 3  INDEX: 2\n",
      "Line number: 4  INDEX: 4\n",
      "Line number: 5  INDEX: 5\n",
      "Line number: 6  INDEX: 6\n",
      "Line number: 7  INDEX: 7\n",
      "Line number: 8  INDEX: 8\n",
      "Line number: 9  INDEX: 9\n",
      "Line number: 10  INDEX: 10\n"
     ]
    }
   ],
   "source": [
    "# Read from poten_litera_db, count keywords, save to poten_litera_db_kw_count\n",
    "input_path = fpath.poten_litera_db\n",
    "output_path = fpath.poten_litera_db_kw_count\n",
    "plib.clear_file(output_path)\n",
    "\n",
    "kept_columns = df_col.index\n",
    "count_and_record(input_path, output_path, kept_columns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
